{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-14일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"14일차\" style=\"position:relative;\">14일차<a href=\"#14%EC%9D%BC%EC%B0%A8\" aria-label=\"14일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>Pandas 맛보기를 했다. 이거로 Kaggle Titanic data로 전처리를 살짝(?) 해 봤다. 회사에서 sql로 데이터 클렌징 했던 때가 생각났다.</li>\n<li>다음주엔 이 결과물을 DL에 넣어서 돌려 보고, 그리고 tesorflow 1버전대, 2버전대로 그간 배운 걸 복습하며, legacy code나 최적화 등에 대해 실무에서 적용할 방법을 배울 예정이다.</li>\n<li>불시에 질문이 훅 들어 오니까, 기존 게시물들에 source code를 조금씩 보완하면서 총 복습 한 번 해야겠다. ...까먹는다.</li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>index<em>label</em>prediction_list - debugging  </li>\n<li>title_str - debugging  </li>\n</ul>\n<hr>\n<p>​</p>\n<h4 id=\"예제5\" style=\"position:relative;\">예제5<a href=\"#%EC%98%88%EC%A0%9C5\" aria-label=\"예제5 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>손실함수 최대 / 최소에 대응하는 실제 MNIST 데이터 확인<br>\n=> 은근히 실무 문제와 유사하다고.</p>\n<ul>\n<li><strong>min/max를 찾기 위해 epoch 별로 분리해야 한다.</strong><br>\n=> (35%) 39200 이하이면 그대로, 아니면 계산이 필요하다.  </li>\n</ul>\n<p>​cf. training/validation graph가 epoch 3 지나면 accuracy가 벌어진다<br>\n=> 여기처럼 20번 할 필요 없으니, epoch 3 미만으로 하자</p>\n<p>​</p>\n<h4 id=\"예제6\" style=\"position:relative;\">예제6<a href=\"#%EC%98%88%EC%A0%9C6\" aria-label=\"예제6 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>accuracy 메소드 내에서 정답, 오답에 대한 정보를 같이 저장하면 debugging 시 유용하다.\n=> 이 경우, list comprehension으로 index<em>label</em>prediction_list 한 줄로도 표현 가능하다.</p>\n<p>cf. <strong>ML, DL을 위한 파이썬</strong> : ★ slicing / list comprehension / lambda / numpy ... ★</p>\n<p>cf. NN에서 MNIST 같은 흑백이 1개 이상의 hidden layer 를 쓸 때, 정답률 92 ~ 96%이면 괜찮은 거고, color이면 정답률 70%이면 준수한 거다.<br>\n=> 99% 하려면 기존의 architecture로 안 된다 => \"CNN\"</p>\n<ul>\n<li>\n<p>강화학습에서도 list 표현이 잘 쓰인다.</p>\n<ul>\n<li>입력 : (x,y) 현재 상태 2개  </li>\n<li>정답 : 현재 상태의 action (r,l,d,up) 중 최대 4개까지<br>\n=> 4개로 두고 one-hot encoding을 취하면 된다.</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"예제7\" style=\"position:relative;\">예제7<a href=\"#%EC%98%88%EC%A0%9C7\" aria-label=\"예제7 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>plt.title 을 써서 여기 안에 이미지에 대한 정보를 쓴다.<br>\n단, int 값은 (str) 로 형변환 해서 써야 한다.\n​\ncf. np.random.randint => int 랜덤 출력</p>\n<p>★ title_str, 이 표현은 굉장히 자주 쓴다</p>\n<p>cf. <a href=\"https://sunghan-kim.github.io/ml/3min-dl-ch08/#81-%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94-%EA%B0%9C%EB%85%90\">auto encoder</a> : 인위적으로 노이즈를 제거하는 기술로, 입력을 그대로 출력으로 내보낸다.\n​\n압축|hidden|복원 구조이다.</p>\n<p>가운데만 잘라 보면, 가운데는 압축된 data info를 갖고 있다 볼 수 있다.<br>\n=> 원본을 몰라도 data를 쓸 수 있다.</p>\n<p>ex) '9 -> de noise 디노이즈 -> 압축 해제</p>\n<hr>\n<h3 id=\"1-pandas\" style=\"position:relative;\">1. Pandas<a href=\"#1-pandas\" aria-label=\"1 pandas permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>ML이 아닌, 데이터 분석(상관계수, 표준편차 등)에 대해 알아 보려면 pandas 공부를 해야 한다.</p>\n<p>cf. 책&#x3C;파이썬 라이브러리를 활용한 데이터 분석> by 김영근(pandas 핵심 멤버)</p>\n<ul>\n<li>데이터 분석은 데이터 학습 (패턴 분석) 위주여서 (분포/상관관계/공분산 등) current status 에 집중하기에, ML처럼 예측하는 건 덜 하다.</li>\n<li>\n<p>pandas ?  </p>\n<ul>\n<li>Dataframe : 2차원 배열, 테이블 형태이다.<br>\n행렬과 달리 문자형이 있다. 여러 데이터 타입을 가질 수 있다.<br>\n1개 이상의 series(열 하나)로 구성돼 있다. 인덱스와 행 번호가 따로 있다.  </li>\n</ul>\n</li>\n</ul>\n<p>cf. anaconda를 설치했다면, pandas는 기본적으로 설치돼 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"cmd\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-cmd line-numbers\"><code class=\"language-cmd\">&gt; pip list\npandas 0.23.0</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<ul>\n<li>\n<p>read_csv(…)  </p>\n<ul>\n<li>가장 자주 쓸 듯 싶다.  </li>\n<li>왼쪽에 0부터 인덱스이고, (자동으로) 파일 내용 맨 위는 열 이름으로 세팅된다.</li>\n</ul>\n</li>\n</ul>\n<p>df['Job'] => 열 데이터 추출 방법은 이외에도 많다.\n​</p>\n<ul>\n<li>\n<p>행 기준 추출  </p>\n<ul>\n<li>iloc 순수한 행 순서 슬라이싱  </li>\n<li>loc 인덱스 바꿀 수 있음\n=> 혼선에 주의할 것. <strong>기존 파이썬 slicing과 혼선이 없으려면 iloc를 쓸 것을 권장한다.</strong></li>\n</ul>\n</li>\n</ul>\n<p>df.iloc[ -1]\ndf.loc[-1] => err 발생 : KeyError: 'the label [-1] is not in the [index]'</p>\n<p>cf. NaN = null = missing data 결측치<br>\n=> 내버려두면 분석이 안 된다 ML에서 쓰려면 사전에 반드시 처리해야 한다</p>\n<ul>\n<li>null 체크 방법<br>\n.isnull.sum() => null 갯수 확인\n.value_counts() =>  데이터 분포를 확인할 수 있다.\n​</li>\n<li>null 있는 모든 행 제거<br>\ndf.dropna()<br>\n=> 데이터가 통으로 없어지는 단점이 있으니,\n=> fillna() 로 값을 변경하자.</li>\n<li>fillna()<br>\n() 안에 옵션으로 <strong>, inplace=True</strong> 설정해 줘야 실제 파일 내용이 교체된다.</li>\n</ul>\n<p>숫자 컬럼 빈 칸 채울 때, 강제로 보통 평균이나 중간값으로 채운다.<br>\n=> 오류가 발생할 수 있다만, 이 점은 감안해야 한다.</p>\n<p>ex. 0,0,0,100,100 => 평균 40 중간값 50</p>\n<ul>\n<li>열 추가 방법<br>\n만약, df<em>B의 data를 df</em>A의 새로운 컬럼으로 쓰고 싶다거나 하면?<br>\n=> 기존 컬럼이 있으면 새로 만들고, 없으면 overwrite 한다.\n<strong>= 많이 쓰는 테크닉</strong></li>\n<li>ML 관점에서 열 순서 바꿔야하는 이유?<br>\n정답 위치의 순서 조정 !</li>\n</ul>\n<hr>\n<h4 id=\"kaggle---titanic-data\" style=\"position:relative;\">Kaggle - Titanic Data<a href=\"#kaggle---titanic-data\" aria-label=\"kaggle   titanic data permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>numpy는 행렬이니, pandas로 string과 null에 대한 전처리 이후 numpy로 사용해야 한다.</p>\n<p>​pd.read_csv() => type : dataframe (df) 이다.<br>\n=> 여기 df에 df.values하면, type : numpy.ndarray  numpy이다...!<br>\n=> 열심히 전처리하고 마지막에 .values만 붙이면 바로 numpy 완성된다.</p>\n<ul>\n<li>Titanic data는 str 이 들어 있기 때문에 numpy.loadtxt 안 된다<br>\n=> pd.read_csv 로 불러오고 전처리해서 df.values 로 numpy 만들어 DL하는 순으로 진행 해야 한다.</li>\n<li>.head() : 앞에 5개가 나온다. (.head(2) 등 가능하다.)</li>\n<li>모든 입력 data 11개 가 생존에 기여하는가?<br>\n관련 없는 건 분석에 활용할 필요가 없다.<br>\n<strong>다만, 필요한 data가 null이면 fillna로 채워야 한다.</strong></li>\n<li>cabin 굳이 drop 안 하고 .values 했더니 행렬 element에 문자열이 들어감 => 사전에 숫자 변환 필요하다.\n=> 문자를 숫자로 바꿀 땐 규칙성만 있게 바꿔주면 된다.</li>\n</ul>\n<h4 id=\"-전처리부터-ml까지---정리\" style=\"position:relative;\">* 전처리부터 ML까지 - 정리<a href=\"#-%EC%A0%84%EC%B2%98%EB%A6%AC%EB%B6%80%ED%84%B0-ml%EA%B9%8C%EC%A7%80---%EC%A0%95%EB%A6%AC\" aria-label=\" 전처리부터 ml까지   정리 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>look through => isnull.sum missing 찾기 => 정답을 만들어내는 필요한 data만 적절한 값으로 교체 &#x26; 문자열 은 숫자열로 교체 => .values로 numpy 데이터 완성 => DL 적용</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#14%EC%9D%BC%EC%B0%A8\">14일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C5\">예제5</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C6\">예제6</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C7\">예제7</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#1-pandas\">1. Pandas</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#kaggle---titanic-data\">Kaggle - Titanic Data</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-14%EC%9D%BC%EC%B0%A8/#-%EC%A0%84%EC%B2%98%EB%A6%AC%EB%B6%80%ED%84%B0-ml%EA%B9%8C%EC%A7%80---%EC%A0%95%EB%A6%AC\">* 전처리부터 ML까지 - 정리</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 14일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-14일차/"}},"staticQueryHashes":["3159585216"]}