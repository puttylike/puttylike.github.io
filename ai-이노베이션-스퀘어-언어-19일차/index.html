<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style id="typography.js">html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:112.5%/1.44 'Fira Sans',sans-serif;box-sizing:border-box;overflow-y:scroll;}*{box-sizing:inherit;}*:before{box-sizing:inherit;}*:after{box-sizing:inherit;}body{color:hsla(0,0%,0%,0.8);font-family:'Fira Sans',sans-serif;font-weight:400;word-wrap:break-word;font-kerning:normal;-moz-font-feature-settings:"kern", "liga", "clig", "calt";-ms-font-feature-settings:"kern", "liga", "clig", "calt";-webkit-font-feature-settings:"kern", "liga", "clig", "calt";font-feature-settings:"kern", "liga", "clig", "calt";}img{max-width:100%;margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}h1{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:2.15rem;line-height:1.1;}h2{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.58293rem;line-height:1.1;}h3{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.35824rem;line-height:1.1;}h4{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1rem;line-height:1.1;}h5{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.85805rem;line-height:1.1;}h6{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.79482rem;line-height:1.1;}hgroup{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}ul{margin-left:1.44rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;list-style-position:outside;list-style-image:none;}ol{margin-left:1.44rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;list-style-position:outside;list-style-image:none;}dl{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}dd{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}p{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}figure{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}pre{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:0.85rem;line-height:1.44rem;}table{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:1rem;line-height:1.44rem;border-collapse:collapse;width:100%;}fieldset{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}blockquote{margin-left:0;margin-right:1.44rem;margin-top:0;padding-bottom:0;padding-left:1.17rem;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:1.16543rem;line-height:1.44rem;color:hsla(0,0%,0%,0.59);font-style:italic;border-left:0.27rem solid hsla(0,0%,0%,0.2);}form{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}noscript{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}iframe{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}hr{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:calc(1.08rem - 1px);background:hsla(0,0%,0%,0.2);border:none;height:1px;}address{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}b{font-weight:700;}strong{font-weight:700;}dt{font-weight:700;}th{font-weight:700;}li{margin-bottom:calc(1.08rem / 2);}ol li{padding-left:0;}ul li{padding-left:0;}li > ol{margin-left:1.44rem;margin-bottom:calc(1.08rem / 2);margin-top:calc(1.08rem / 2);}li > ul{margin-left:1.44rem;margin-bottom:calc(1.08rem / 2);margin-top:calc(1.08rem / 2);}blockquote *:last-child{margin-bottom:0;}li *:last-child{margin-bottom:0;}p *:last-child{margin-bottom:0;}li > p{margin-bottom:calc(1.08rem / 2);}code{font-size:0.85rem;line-height:1.44rem;}kbd{font-size:0.85rem;line-height:1.44rem;}samp{font-size:0.85rem;line-height:1.44rem;}abbr{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}acronym{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}abbr[title]{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;text-decoration:none;}thead{text-align:left;}td,th{text-align:left;border-bottom:1px solid hsla(0,0%,0%,0.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding-left:0.96rem;padding-right:0.96rem;padding-top:0.72rem;padding-bottom:calc(0.72rem - 1px);}th:first-child,td:first-child{padding-left:0;}th:last-child,td:last-child{padding-right:0;}a{color:#9f392b;}blockquote > :last-child{margin-bottom:0;}blockquote cite{font-size:1rem;line-height:1.44rem;color:hsla(0,0%,0%,0.8);font-weight:400;}blockquote cite:before{content:"— ";}@media only screen and (max-width:480px){blockquote{margin-left:-1.08rem;margin-right:0;padding-left:0.81rem;}}</style><style data-href="/styles.1eaa876ab1d442be3ba9.css" data-identity="gatsby-global-css">code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#f8f8f2;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;text-align:left;text-shadow:0 1px rgba(0,0,0,.3);white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}pre[class*=language-].line-numbers{counter-reset:linenumber;padding-left:3.8em;position:relative}pre[class*=language-].line-numbers>code{position:relative;white-space:inherit}.line-numbers .line-numbers-rows{border-right:1px solid #999;font-size:100%;left:-3.8em;letter-spacing:-1px;pointer-events:none;position:absolute;top:0;-webkit-user-select:none;-ms-user-select:none;user-select:none;width:3em}.line-numbers-rows>span{counter-increment:linenumber;display:block}.line-numbers-rows>span:before{color:#999;content:counter(linenumber);display:block;padding-right:.8em;text-align:right}</style><meta name="generator" content="Gatsby 3.13.0"/><style type="text/css">
    .custom-class.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .custom-class.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .custom-class svg,
    h2 .custom-class svg,
    h3 .custom-class svg,
    h4 .custom-class svg,
    h5 .custom-class svg,
    h6 .custom-class svg {
      visibility: hidden;
    }
    h1:hover .custom-class svg,
    h2:hover .custom-class svg,
    h3:hover .custom-class svg,
    h4:hover .custom-class svg,
    h5:hover .custom-class svg,
    h6:hover .custom-class svg,
    h1 .custom-class:focus svg,
    h2 .custom-class:focus svg,
    h3 .custom-class:focus svg,
    h4 .custom-class:focus svg,
    h5 .custom-class:focus svg,
    h6 .custom-class:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 100)
          }), 0)
        }
      }
    })
  </script><link href="//fonts.googleapis.com/css?family=Playfair+Display:700|Fira+Sans:400,400i,700,700i" rel="stylesheet" type="text/css"/><link as="script" rel="preload" href="/webpack-runtime-9d111699065b1154a31b.js"/><link as="script" rel="preload" href="/framework-24ad6bf468f69b85cc4b.js"/><link as="script" rel="preload" href="/app-b088d9e31d6ec271920e.js"/><link as="script" rel="preload" href="/commons-71b7b1d300b3ebc29573.js"/><link as="script" rel="preload" href="/e3fcc2076860498e4deed45a66207f3abfe77099-7463bcd7e6ea2ff920c3.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-33322b93090050d5fb1b.js"/><link as="fetch" rel="preload" href="/page-data/ai-이노베이션-스퀘어-언어-19일차/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3159585216.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="1x3051k">.css-1x3051k{margin:0 auto;max-width:720px;padding:2.88rem;padding-top:2.16rem;}</style><main class="css-1x3051k"><a href="/"><style data-emotion-css="i0b9uu">.css-i0b9uu{margin-bottom:2.88rem;display:inline-block;font-style:normal;}</style><h3 class="css-i0b9uu">Blog</h3></a><style data-emotion-css="146q31f">.css-146q31f{float:right;}</style><a class="css-146q31f" href="/about/">About</a><p class="css-146q31f"> / </p><a class="css-146q31f" href="/contact/">Contact</a><div class="sc-bdnxRM jIvSMM"><header class="sc-bdnxRM fzUdiI"><div font-size="24px" class="sc-bdnxRM eFFssn">AI 이노베이션 스퀘어 3기 언어반 19일차 후기</div><div color="#bbb" class="sc-bdnxRM jBinAJ"></div></header><style data-emotion-css="8xh4e7">.css-8xh4e7{line-height:30px;position:static;}</style><div class="sc-bdnxRM fzUdiI css-8xh4e7"><p>지금까지 배운 내용을 자연어 처리 관련된 내용 위주로 복습하는 시간을 가졌다.</p>
<hr>
<h3 id="19일차" style="position:relative;">19일차<a href="#19%EC%9D%BC%EC%B0%A8" aria-label="19일차 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h3>
<h4 id="파이썬-기초" style="position:relative;">파이썬 기초<a href="#%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EC%B4%88" aria-label="파이썬 기초 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<ul>
<li>nlp_study_001.ipynb</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 자연어 처리 : 음성 or 텍스트</span>
<span class="token comment"># IT에서 특히, 프로그래밍 언어에서는 텍스트 (text) -> 문자열 (string)</span>

<span class="token comment"># 문자열 연결</span>
a <span class="token operator">=</span> <span class="token string">"chicken"</span> <span class="token operator">+</span> <span class="token string">"man"</span>
a
<span class="token comment"># 'chickenman'</span>

<span class="token comment"># 문자열 slicing</span>
<span class="token comment"># 파이썬은 0-index programming Language</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># h</span>
<span class="token comment"># ickenman</span>
<span class="token comment"># ickenma</span>
<span class="token comment"># ickenm</span>

<span class="token comment"># 특정 문자나 문자열일 존재하는지 확인</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hi"</span> <span class="token keyword">in</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"zi"</span> <span class="token keyword">in</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"HI"</span> <span class="token keyword">in</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"HI"</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">in</span> a<span class="token punctuation">)</span>
<span class="token comment"># True</span>
<span class="token comment"># False</span>
<span class="token comment"># False</span>
<span class="token comment"># True</span>

<span class="token comment"># 특정 문자열로 문장이 시작되거나 끝나는지 확인</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"ch"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"cha"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">"man"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># True</span>
<span class="token comment"># False</span>
<span class="token comment"># True</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># chickenman</span>
<span class="token comment"># c</span>

<span class="token comment"># 파이썬에서 문자열은 immutable이다!</span>
<span class="token comment"># 즉, 변경이 불가하다!</span>
a<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"X"</span>
<span class="token comment"># TypeError: 'str' object does not support item assignment</span>
<span class="token comment"># ---------------------------------------------------------------------------</span>
<span class="token comment"># TypeError                                 Traceback (most recent call last)</span>
<span class="token comment"># ~\AppData\Local\Temp/ipykernel_5276/4011659896.py in &lt;module></span>
<span class="token comment">#       1 # 파이썬에서 문자열은 immutable이다!</span>
<span class="token comment">#       2 # 즉, 변경이 불가하다!</span>
<span class="token comment"># ----> 3 a[3] = "X"</span>
<span class="token comment">#</span>
<span class="token comment"># TypeError: 'str' object does not support item assignment</span>

tuple_example <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
tuple_example<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token number">2</span>

tuple_example<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">4</span>
<span class="token comment"># TypeError: 'tuple' object does not support item assignment</span>
<span class="token comment"># ---------------------------------------------------------------------------</span>
<span class="token comment"># TypeError                                 Traceback (most recent call last)</span>
<span class="token comment"># ~\AppData\Local\Temp/ipykernel_5276/464162708.py in &lt;module></span>
<span class="token comment"># ----> 1 tuple_example[1] = 4</span>
<span class="token comment">#</span>
<span class="token comment"># TypeError: 'tuple' object does not support item assignment</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">new_string <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"X"</span> <span class="token operator">+</span> a<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_string<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token comment"># chiXkenman</span>
<span class="token comment"># chickenman</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<ul>
<li><a href="https://ko.wikipedia.org/wiki/ASCII">https://ko.wikipedia.org/wiki/ASCII</a></li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 문자열을 나누어 보자!</span>
word_list <span class="token operator">=</span> <span class="token string">"I love to drive cars."</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># ['I', 'love', 'to', 'drive', 'cars.']</span>
<span class="token comment"># &lt;class 'list'></span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 문장의 끝에 있을 수 있는 개행문자를 제거</span>
return_at_end <span class="token operator">=</span> <span class="token string">'Hi there.\n'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>return_at_end<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Next line."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>return_at_end<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Next line."</span><span class="token punctuation">)</span>
<span class="token comment"># Hi there.</span>
<span class="token comment">#</span>
<span class="token comment"># Next line.</span>
<span class="token comment"># Hi there.</span>
<span class="token comment"># Next line.</span>

<span class="token comment"># 문자열의 특정 부분을 교체</span>
new_string <span class="token operator">=</span> <span class="token string">"I love tacos."</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"love"</span><span class="token punctuation">,</span> <span class="token string">"enjoy"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>new_string<span class="token punctuation">)</span>
<span class="token comment"># I enjoy tacos.</span>

<span class="token comment"># 파이썬에서는 ''든 ""든 모두 문자열로 처리</span>
<span class="token comment"># 통일이 되도록 사용</span>
<span class="token comment"># '''''' 이나 '"""""는 여러개 문자열을 보곤하기 위한 방법</span>
a <span class="token operator">=</span> <span class="token string">'bob'</span>
b <span class="token operator">=</span> <span class="token string">"tom"</span>
c <span class="token operator">=</span> <span class="token triple-quoted-string string">'''frank'''</span>
d <span class="token operator">=</span> <span class="token triple-quoted-string string">"""fran"""</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span>
<span class="token comment"># bob</span>
<span class="token comment"># tom</span>
<span class="token comment"># frank</span>
<span class="token comment"># fran</span>

<span class="token comment"># 이제 escape character가 필요한 시점</span>
<span class="token comment"># print('I can't believe it.')</span>
<span class="token comment"># SyntaxError: invalid syntax (Temp/ipykernel_5276/4124891155.py, line 2)</span>
<span class="token comment">#   File "C:\Users\Choi\AppData\Local\Temp/ipykernel_5276/4124891155.py", line 2</span>
<span class="token comment">#     print('I can't believe it.')</span>
<span class="token comment">#                  ^</span>
<span class="token comment"># SyntaxError: invalid syntax</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"I can't believe it."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'I can\'t believe it.'</span><span class="token punctuation">)</span>
<span class="token comment"># I can't believe it.</span>
<span class="token comment"># I can't believe it.</span>

<span class="token comment"># 문자열(string)은 문자(character)들의 모임</span>
<span class="token comment"># 문자열 immutable, 즉 변경이 불가하다!</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<h4 id="자연어-처리-기본-개념" style="position:relative;">자연어 처리 기본 개념<a href="#%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90" aria-label="자연어 처리 기본 개념 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<h5 id="nltk" style="position:relative;">NLTK<a href="#nltk" aria-label="nltk permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h5>
<h5 id="spacy" style="position:relative;">spaCy<a href="#spacy" aria-label="spacy permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h5>
<ul>
<li>nlp_study_002.ipynb</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 자연어 처리를 하고자 합니다.</span>
<span class="token comment"># 기본 개념</span>
<span class="token comment"># 문서 (document)는 문장 (sentence)들로 이루어 집니다.</span>
<span class="token comment"># 문장 (sentence)는 토큰 (token) 들로 이루어 집니다.</span>
<span class="token comment"># 불용어 (stop word)를 필터링 합니다.</span>

<span class="token comment"># 문서를 문장으로 나누기!</span>
<span class="token comment">## 1. 문장으로 나눌 때 ".", "?", "!" 을 많이 사용</span>
<span class="token comment">### 주의할 점은 "."일 경우! --> 예를 들어, Ph.D, Mr., 72.35</span>
<span class="token comment">## 2. regular expression (정규식) / .\n</span>
<span class="token comment">## 3. binary classifier</span>
<span class="token comment"># 우리는 단순하게 NLTK나 spaCy를 이용해서 편하게 문장으로 나눈다!</span>

<span class="token comment"># 문장을 토큰으로 나누기!</span>
<span class="token comment">## 1. 문장을 토큰으로 나눌 때, 단순히 " " (whitespace)로 나눌 수는 없다!</span>
<span class="token comment">### 단어의 축약형을 다루거나 분리 구두기호를 사용해야할 수도 있다</span>
<span class="token comment">## 2. 통계치나 룰 기반으로 나눌 수도 있다.</span>
<span class="token comment"># 우리는 단순하게 NLTK나 spaCy를 이용해서 편하게 토큰으로 나눈다!</span>

! pip install nltk
! pip install spaCy</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> nltk
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span>
<span class="token comment"># [nltk_data] Downloading package punkt to</span>
<span class="token comment"># [nltk_data]     C:\Users\Choi\AppData\Roaming\nltk_data...</span>
<span class="token comment"># [nltk_data]   Package punkt is already up-to-date!</span>
<span class="token comment"># True</span>

<span class="token comment"># 한국어의 경우 koNLTK (http://konltk.org/en/latest/index.html)</span>
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize

text1 <span class="token operator">=</span> <span class="token string">"The Checken danced because she loved disco."</span>
tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>text1<span class="token punctuation">)</span>
tokens
<span class="token comment"># ['The', 'Checken', 'danced', 'because', 'she', 'loved', 'disco', '.']</span>

text2 <span class="token operator">=</span> <span class="token string">"Mr. Smith loves tacos. He has a Ph.D in tacology."</span>
tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>text2<span class="token punctuation">)</span>
tokens
<span class="token comment"># ['Mr.',</span>
<span class="token comment">#  'Smith',</span>
<span class="token comment">#  'loves',</span>
<span class="token comment">#  'tacos',</span>
<span class="token comment">#  '.',</span>
<span class="token comment">#  'He',</span>
<span class="token comment">#  'has',</span>
<span class="token comment">#  'a',</span>
<span class="token comment">#  'Ph.D',</span>
<span class="token comment">#  'in',</span>
<span class="token comment">#  'tacology',</span>
<span class="token comment">#  '.']</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>spaCy에서도 동일하게 구현 가능하다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">from</span> spacy<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>en <span class="token keyword">import</span> English
parser <span class="token operator">=</span> English<span class="token punctuation">(</span><span class="token punctuation">)</span>
tokens <span class="token operator">=</span> parser<span class="token punctuation">(</span>text1<span class="token punctuation">)</span>
tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token<span class="token punctuation">.</span>orth_ <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> <span class="token keyword">not</span> token<span class="token punctuation">.</span>orth_<span class="token punctuation">.</span>isspace<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
tokens
<span class="token comment"># ['The', 'Checken', 'danced', 'because', 'she', 'loved', 'disco', '.']</span>

tokens <span class="token operator">=</span> parser<span class="token punctuation">(</span>text2<span class="token punctuation">)</span>
tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token<span class="token punctuation">.</span>orth_ <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> <span class="token keyword">not</span> token<span class="token punctuation">.</span>orth_<span class="token punctuation">.</span>isspace<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
tokens
<span class="token comment"># ['Mr.',</span>
<span class="token comment">#  'Smith',</span>
<span class="token comment">#  'loves',</span>
<span class="token comment">#  'tacos',</span>
<span class="token comment">#  '.',</span>
<span class="token comment">#  'He',</span>
<span class="token comment">#  'has',</span>
<span class="token comment">#  'a',</span>
<span class="token comment">#  'Ph',</span>
<span class="token comment">#  '.',</span>
<span class="token comment">#  'D',</span>
<span class="token comment">#  'in',</span>
<span class="token comment">#  'tacology',</span>
<span class="token comment">#  '.']</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># stop word (불용어 처리)</span>
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'stopwords'</span><span class="token punctuation">)</span>
<span class="token comment"># [nltk_data] Downloading package stopwords to</span>
<span class="token comment"># [nltk_data]     C:\Users\Choi\AppData\Roaming\nltk_data...</span>
<span class="token comment"># [nltk_data]   Package stopwords is already up-to-date!</span>
<span class="token comment"># True</span>

<span class="token keyword">import</span> nltk
english_stopwords <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>corpus<span class="token punctuation">.</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">"English"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>english_stopwords<span class="token punctuation">)</span>
<span class="token comment"># {'ain', "that'll", 'wouldn', 'too', 'are', 'so', 'between', 'those', 'can', "won't", 'ourselves', 'more', 'have', 'them', 'you', 've', 'm', 'hasn', 'himself', 'its', 'myself', 'mustn', "aren't", "needn't", 'own', 'down', 'few', 'where', 'his', 'that', 'ma', 'through', 'shan', 'with', "wouldn't", 'such', 'your', 'once', 'yourselves', 'or', 'while', 'off', 'there', 'herself', 'shouldn', 'above', 'how', 'who', 'for', 'theirs', 'o', 'when', 'ours', 'am', 'of', 'whom', 'does', 's', 'me', 'been', "you're", 'will', "wasn't", 'then', 'about', 'having', 'aren', 'over', 'before', 'only', 'again', 'themselves', "should've", 'haven', 'some', 'their', "hasn't", 'not', 'couldn', 't', "it's", 'which', 'same', "mustn't", 'to', "couldn't", 'further', "hadn't", 'she', 'into', 'him', 'i', 'is', 'were', 'both', 're', 'on', 'do', 'hers', 'had', 'didn', 'mightn', 'from', 'he', 'at', 'my', 'against', 'was', 'itself', 'an', 'in', 'under', 'any', 'if', 'up', 'out', 'most', "you'll", "didn't", 'll', 'the', 'don', 'wasn', 'why', 'we', 'nor', 'during', "weren't", 'below', 'but', 'than', 'won', 'has', 'each', 'be', 'very', 'doesn', "doesn't", 'isn', 'hadn', 'other', 'y', 'yourself', 'now', "don't", "you've", 'here', "isn't", 'because', 'should', "she's", 'what', 'this', 'no', "you'd", 'a', 'and', 'yours', 'just', 'weren', 'doing', 'after', 'her', 'all', 'did', 'needn', "shouldn't", 'they', "haven't", 'our', "mightn't", 'it', 'd', "shan't", 'being', 'by', 'as', 'these', 'until'}</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<ul>
<li>
<p><a href="https://home.cs.colorado.edu/~martin/slp2.html">https://home.cs.colorado.edu/~martin/slp2.html</a></p>
</li>
<li>
<p><a href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a></p>
</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize
text <span class="token operator">=</span> <span class="token string">"The chiken went to the house to humiliate the man."</span>
tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
content_tokens <span class="token operator">=</span> <span class="token punctuation">[</span> token <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> token<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> english_stopwords <span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>content_tokens<span class="token punctuation">)</span>
<span class="token comment"># ['The', 'chiken', 'went', 'to', 'the', 'house', 'to', 'humiliate', 'the', 'man', '.']</span>
<span class="token comment"># ['chiken', 'went', 'house', 'humiliate', 'man', '.']</span>
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 불용어(stopwords) : "the", "and", "it" 처럼 문장에서 의미를 크게 가지지 않는 단어</span>
<span class="token comment"># 라이브러리에 따라서 불용어 목록 유무가 다르고, 또한, 목록 자체도 다르다.</span>

<span class="token keyword">import</span> nltk
text <span class="token operator">=</span> <span class="token string">"Mr. Smith loves tacos. He has a Ph.D. in tacology. What time is it now?"</span>
tokenized_sentences <span class="token operator">=</span> nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">for</span> sent <span class="token keyword">in</span> tokenized_sentences<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Sentence"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sent <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
<span class="token comment"># Sentence</span>
<span class="token comment"># Mr. Smith loves tacos.</span>
<span class="token comment">#</span>
<span class="token comment"># Sentence</span>
<span class="token comment"># He has a Ph.D. in tacology.</span>
<span class="token comment">#</span>
<span class="token comment"># Sentence</span>
<span class="token comment"># What time is it now?</span>

<span class="token keyword">from</span> spacy<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>en <span class="token keyword">import</span> English
parser <span class="token operator">=</span> English<span class="token punctuation">(</span><span class="token punctuation">)</span>
tokens <span class="token operator">=</span> parser<span class="token punctuation">(</span>text1<span class="token punctuation">)</span>
<span class="token keyword">for</span> sent <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># The</span>
<span class="token comment"># Checken</span>
<span class="token comment"># danced</span>
<span class="token comment"># because</span>
<span class="token comment"># she</span>
<span class="token comment"># loved</span>
<span class="token comment"># disco</span>
<span class="token comment"># .</span>
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<ul>
<li>nlp_study_003.ipynb</li>
</ul>
<h4 id="-gensim--오늘-새로-배움" style="position:relative;">+ gensim  (오늘 새로 배움)<a href="#-gensim--%EC%98%A4%EB%8A%98-%EC%83%88%EB%A1%9C-%EB%B0%B0%EC%9B%80" aria-label=" gensim  오늘 새로 배움 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<ul>
<li><a href="https://radimrehurek.com/gensim/">https://radimrehurek.com/gensim/</a></li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 문서 -> 문장 -> 토큰 : 자연어 처리를 할 수 있는 데이터가 준비!</span>
<span class="token comment"># 자연어 처리를 하기 위한 최소한의 단위 (unit)가 준비가 되어 있는데...</span>
<span class="token comment"># 문제는 이 토큰이 숫자가 아니라 문자열이라는 것!</span>
<span class="token comment"># 사람은 문자를 인식할 수 있지만, 컴퓨터는 모든 것을 숫자로 처리!</span>
<span class="token comment"># 우리는 그래서 토큰을 숫자화 시키는 과정이 필요!</span>
<span class="token comment"># 문서나 단어를 벡터 (vector)로 변환!</span>
<span class="token comment"># 이런 벡터로 변환이 되면 단어들간의 거리를 비교할 수 있습니다</span>
<span class="token comment"># 즉, 이를 통해서 우리는 유사 문장이나 단어를 찾을 수 있습니다.</span>

! pip install gensim
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> gensim

<span class="token comment"># raw_documents = ['I love tacos.',</span>
<span class="token comment">#              'She ran with the chicken.',</span>
<span class="token comment">#              'I don’t choose to take a nap. The nap chooses me.',</span>
<span class="token comment">#             'That man is nice as pie with ice cream.',</span>
<span class="token comment">#             'This pizza is an affront to nature.'</span>
<span class="token comment"># ]</span>

<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize

<span class="token keyword">def</span> <span class="token function">get_tokens</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tokens

gen_docs <span class="token operator">=</span> <span class="token punctuation">[</span> get_tokens<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> raw_documents <span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gen_docs<span class="token punctuation">)</span>
<span class="token comment"># [['I', 'love', 'tacos', '.'], ['She', 'ran', 'with', 'the', 'chicken', '.'], ['I', 'don', '’', 't', 'choose', 'to', 'take', 'a', 'nap', '.', 'The', 'nap', 'chooses', 'me', '.'], ['That', 'man', 'is', 'nice', 'as', 'pie', 'with', 'ice', 'cream', '.'], ['This', 'pizza', 'is', 'an', 'affront', 'to', 'nature', '.']]    </span>

dictionary <span class="token operator">=</span> gensim<span class="token punctuation">.</span>corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>gen_docs<span class="token punctuation">)</span>
num_words <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"dictionary에 있는 단어의 수는 </span><span class="token interpolation"><span class="token punctuation">{</span>num_words<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">type</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token comment"># dictionary에 있는 단어의 수는 33 &lt;class 'gensim.corpora.dictionary.Dictionary'></span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span> word <span class="token keyword">in</span> dictionary<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> word<span class="token punctuation">)</span>
<span class="token comment"># 0 .</span>
<span class="token comment"># 1 I</span>
<span class="token comment"># 2 love</span>
<span class="token comment"># 3 tacos</span>
<span class="token comment"># 4 She</span>
<span class="token comment"># 5 chicken</span>
<span class="token comment"># 6 ran</span>
<span class="token comment"># 7 the</span>
<span class="token comment"># 8 with</span>
<span class="token comment"># 9 The</span>
<span class="token comment"># 10 a</span>
<span class="token comment"># 11 choose</span>
<span class="token comment"># 12 chooses</span>
<span class="token comment"># 13 don</span>
<span class="token comment"># 14 me</span>
<span class="token comment"># 15 nap</span>
<span class="token comment"># 16 t</span>
<span class="token comment"># 17 take</span>
<span class="token comment"># 18 to</span>
<span class="token comment"># 19 ’</span>
<span class="token comment"># 20 That</span>
<span class="token comment"># 21 as</span>
<span class="token comment"># 22 cream</span>
<span class="token comment"># 23 ice</span>
<span class="token comment"># 24 is</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment"># 28 This</span>
<span class="token comment"># 29 affront</span>
<span class="token comment"># 30 an</span>
<span class="token comment"># 31 nature</span>
<span class="token comment"># 32 pizza</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">.</span>id2token<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  
<span class="token comment"># the</span>
<span class="token comment"># the  </span>

<span class="token keyword">print</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">.</span>token2id<span class="token punctuation">[</span><span class="token string">"ran"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 6</span>

bow_doc <span class="token operator">=</span> dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"I"</span><span class="token punctuation">,</span> <span class="token string">"love"</span><span class="token punctuation">,</span> <span class="token string">"love"</span><span class="token punctuation">,</span> <span class="token string">"love"</span><span class="token punctuation">,</span> <span class="token string">"tacos"</span><span class="token punctuation">,</span> <span class="token string">"!"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>bow_doc<span class="token punctuation">)</span>
<span class="token comment"># [(1, 1), (2, 3), (3, 1)]</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># bag of words를 생성!</span>
<span class="token comment"># bag of words는 단어들의 빈도 (tf : term frequence)를 의미!</span>
<span class="token comment"># 순서는 의미가 없다! 왜? bag of words를 이루는 tuple이 단어의 인덱스를 가진다!</span>
<span class="token comment"># dictionary에 존재하는 단어들만 처리가 된다</span>

<span class="token comment"># bow_doc = dictionary.doc2bow("I',"love","love","love","tacos","."])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>bow_doc<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>bow_doc<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># [(1, 1), (2, 3), (3, 1)]</span>
<span class="token comment"># &lt;class 'list'></span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">corpus <span class="token operator">=</span> <span class="token punctuation">[</span> dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>gen_doc<span class="token punctuation">)</span> <span class="token keyword">for</span> gen_doc <span class="token keyword">in</span> gen_docs <span class="token punctuation">]</span>
corpus
<span class="token comment"># [[(0, 1), (1, 1), (2, 1), (3, 1)],</span>
<span class="token comment">#  [(0, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],</span>
<span class="token comment">#  [(0, 2),</span>
<span class="token comment">#   (1, 1),</span>
<span class="token comment">#   (9, 1),</span>
<span class="token comment">#   (10, 1),</span>
<span class="token comment">#   (11, 1),</span>
<span class="token comment">#   (12, 1),</span>
<span class="token comment">#   (13, 1),</span>
<span class="token comment">#   (14, 1),</span>
<span class="token comment">#   (15, 2),</span>
<span class="token comment">#   (16, 1),</span>
<span class="token comment">#   (17, 1),</span>
<span class="token comment">#   (18, 1),</span>
<span class="token comment">#   (19, 1)],</span>
<span class="token comment">#  [(0, 1),</span>
<span class="token comment">#   (8, 1),</span>
<span class="token comment">#   (20, 1),</span>
<span class="token comment">#   (21, 1),</span>
<span class="token comment">#   (22, 1),</span>
<span class="token comment">#   (23, 1),</span>
<span class="token comment">#   (24, 1),</span>
<span class="token comment">#   (25, 1),</span>
<span class="token comment">#   (26, 1),</span>
<span class="token comment">#   (27, 1)],</span>
<span class="token comment">#  [(0, 1), (18, 1), (24, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]]</span>

tf_idf <span class="token operator">=</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>TfidfModel<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf_idf<span class="token punctuation">)</span>
<span class="token comment"># TfidfModel(num_docs=5, num_nnz=41)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># .의 경우 Log_2(1) = 0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gen_docs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>corpus<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf_idf<span class="token punctuation">[</span>corpus<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># ['I', 'love', 'tacos', '.']</span>
<span class="token comment"># [(0, 1), (1, 1), (2, 1), (3, 1)]</span>
<span class="token comment"># [(1, 0.37344696513776354), (2, 0.6559486886294514), (3, 0.6559486886294514)]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>gen_docs<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>corpus<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf_idf<span class="token punctuation">[</span>corpus<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># ['That', 'man', 'is', 'nice', 'as', 'pie', 'with', 'ice', 'cream', '.']</span>
<span class="token comment"># [(0, 1), (8, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1)]</span>
<span class="token comment"># [(8, 0.20586276004251075), (20, 0.3615919262798405), (21, 0.3615919262798405), (22, 0.3615919262798405), (23, 0.3615919262798405), (24, 0.20586276004251075), (25, 0.3615919262798405), (26, 0.3615919262798405), (27, 0.3615919262798405)]</span>

bow <span class="token operator">=</span> dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"I"</span><span class="token punctuation">,</span> <span class="token string">"love"</span><span class="token punctuation">,</span> <span class="token string">"pizza"</span><span class="token punctuation">,</span> <span class="token string">"."</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>bow<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf_idf<span class="token punctuation">[</span>bow<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># [(0, 1), (1, 1), (2, 1), (32, 1)]</span>

query_doc <span class="token operator">=</span> <span class="token string">"chicken with tacos love"</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>query_doc<span class="token punctuation">)</span>
query_doc_bow <span class="token operator">=</span> dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>query_doc<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>query_doc_bow<span class="token punctuation">)</span>
<span class="token comment"># ['chicken', 'with', 'tacos', 'love']</span>
<span class="token comment"># [(2, 1), (3, 1), (5, 1), (8, 1)]</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># raw_documents = ['I love tacos.',</span>
<span class="token comment">#              'She ran with the chicken.',</span>
<span class="token comment">#              'I don’t choose to take a nap. The nap chooses me.',</span>
<span class="token comment">#             'That man is nice as pie with ice cream.',</span>
<span class="token comment">#             'This pizza is an affront to nature.'</span>
<span class="token comment"># ]</span>
<span class="token comment">#</span>
<span class="token comment"># 2 love</span>
<span class="token comment"># 3 tacos</span>
<span class="token comment"># 5 chicken</span>
<span class="token comment"># 8 with</span>

query_doc <span class="token operator">=</span> <span class="token string">"chicken with tacos love"</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>query_doc<span class="token punctuation">)</span>
query_doc_bow <span class="token operator">=</span> dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>query_doc<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>query_doc_bow<span class="token punctuation">)</span>
query_doc_tf_idf <span class="token operator">=</span> tf_idf<span class="token punctuation">[</span>query_doc_bow<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>query_doc_tf_idf<span class="token punctuation">)</span>
<span class="token comment"># ['chicken', 'with', 'tacos', 'love']</span>
<span class="token comment"># [(2, 1), (3, 1), (5, 1), (8, 1)]</span>
<span class="token comment"># [(2, 0.5484803253891997), (3, 0.5484803253891997), (5, 0.5484803253891997), (8, 0.31226270667960454)]</span>

sims <span class="token operator">=</span> gensim<span class="token punctuation">.</span>similarities<span class="token punctuation">.</span>Similarity<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">,</span> tf_idf<span class="token punctuation">[</span>corpus<span class="token punctuation">]</span><span class="token punctuation">,</span> num_features<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dictionary<span class="token punctuation">)</span><span class="token punctuation">)</span>
sims<span class="token punctuation">[</span>query_doc_tf_idf<span class="token punctuation">]</span>
<span class="token comment"># array([0.7195499 , 0.34925455, 0.        , 0.06428327, 0.        ],</span>
<span class="token comment">#       dtype=float32)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<h4 id="전이학습" style="position:relative;">전이학습<a href="#%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5" aria-label="전이학습 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<ul>
<li>
<p>nlp_study_004.ipynb</p>
</li>
<li>
<p><a href="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</a></p>
</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># transfer Learning (전이학습)</span>
<span class="token keyword">import</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>word2vec <span class="token keyword">as</span> word2vec
google_vec_file <span class="token operator">=</span> <span class="token string">"GoogleNews-vectors-negative300.bin"</span>
model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span>google_vec_file<span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model<span class="token punctuation">[</span><span class="token string">"mouse"</span><span class="token punctuation">]</span>
<span class="token comment"># array([ 2.40234375e-01,  2.51770020e-03, -1.01074219e-01,  1.31835938e-01,</span>
<span class="token comment">#        -3.44238281e-02,  6.83593750e-02, -7.51953125e-02, -1.28906250e-01,</span>
<span class="token comment">#         1.46484375e-01,  1.03027344e-01, -3.04687500e-01, -2.32421875e-01,</span>
<span class="token comment">#         1.66015625e-01, -1.60156250e-01, -1.14746094e-01, -5.51757812e-02,</span>
<span class="token comment">#         3.46679688e-02,  2.26562500e-01, -7.91015625e-02, -2.33398438e-01,</span>
<span class="token comment">#         1.70898438e-01, -9.61914062e-02, -9.37500000e-02,  1.78710938e-01,</span>
<span class="token comment">#        -1.83593750e-01,  1.25976562e-01,  1.20849609e-02,  1.42578125e-01,</span>
<span class="token comment">#         1.72851562e-01, -1.56250000e-02,  7.12890625e-02, -1.21093750e-01,</span>
<span class="token comment">#        -4.22363281e-02,  2.55859375e-01, -1.52343750e-01, -1.70898438e-02,</span>
<span class="token comment">#        -6.83593750e-02,  3.28125000e-01,  2.02148438e-01,  4.24804688e-02,</span>
<span class="token comment">#        -6.34765625e-02, -1.14746094e-02, -3.85742188e-02,  7.81250000e-02,</span>
<span class="token comment">#         1.75781250e-01, -8.30078125e-02,  8.83789062e-02,  1.29882812e-01,</span>
<span class="token comment">#         7.37304688e-02, -7.22656250e-02, -3.90625000e-01, -4.49218750e-02,</span>
<span class="token comment">#         1.28906250e-01, -4.39453125e-01, -4.76074219e-02, -4.15039062e-02,</span>
<span class="token comment">#        -1.04492188e-01, -3.28125000e-01,  4.41894531e-02,  4.70703125e-01,</span>
<span class="token comment">#        -3.49609375e-01,  2.81250000e-01,  1.39770508e-02,  2.73437500e-01,</span>
<span class="token comment">#        -3.51562500e-01, -1.25976562e-01,  1.70898438e-01,  1.84570312e-01,</span>
<span class="token comment">#        -3.02734375e-01,  1.98242188e-01,  2.85156250e-01,  1.53350830e-03,</span>
<span class="token comment">#         3.66210938e-02, -4.10156250e-01,  3.85742188e-02, -1.68945312e-01,</span>
<span class="token comment">#         7.32421875e-02, -1.32812500e-01,  7.86132812e-02, -1.56250000e-02,</span>
<span class="token comment">#        -2.16796875e-01,  2.83203125e-01,  2.81250000e-01,  5.22460938e-02,</span>
<span class="token comment">#        -2.07031250e-01,  3.26171875e-01, -4.44335938e-02,  2.09960938e-01,</span>
<span class="token comment">#        -7.32421875e-02,  9.91210938e-02, -9.08203125e-02, -2.97546387e-03,</span>
<span class="token comment">#        -5.31250000e-01, -7.12890625e-02,  3.85742188e-02,  6.44531250e-02,</span>
<span class="token comment">#         2.91015625e-01, -3.92578125e-01, -7.95898438e-02,  1.03515625e-01,</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#         1.73828125e-01,  1.12792969e-01, -1.72851562e-01,  8.30078125e-02,</span>
<span class="token comment">#         7.91015625e-02,  8.54492188e-02, -1.15722656e-01, -2.33398438e-01,</span>
<span class="token comment">#         1.37695312e-01,  6.34765625e-02, -2.42187500e-01,  2.44140625e-01,</span>
<span class="token comment">#        -1.07910156e-01, -4.00390625e-02,  5.00000000e-01,  3.39355469e-02,</span>
<span class="token comment">#        -9.13085938e-02,  3.14453125e-01, -2.87109375e-01,  2.50000000e-01],</span>
<span class="token comment">#       dtype=float32)</span>

model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">"mouse"</span><span class="token punctuation">)</span>
<span class="token comment"># [('Logitech_MX_Revolution', 0.6175230741500854),</span>
<span class="token comment">#  ('Razer_Mamba', 0.5994570851325989),</span>
<span class="token comment">#  ('mice', 0.5896884799003601),</span>
<span class="token comment">#  ('cordless_laser', 0.5652030110359192),</span>
<span class="token comment">#  ('VX_Nano', 0.5619357824325562),</span>
<span class="token comment">#  ('Logitech_MX###', 0.5604779124259949),</span>
<span class="token comment">#  ('keyboard_arrow_keys', 0.5545550584793091),</span>
<span class="token comment">#  ('Logitech_G9x', 0.5538491606712341),</span>
<span class="token comment">#  ('NOTE_TO_READERS_Hovering', 0.5520266890525818),</span>
<span class="token comment">#  ('Razer_Abyssus', 0.5489388108253479)]</span>

model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">"house"</span><span class="token punctuation">)</span>
<span class="token comment"># [('houses', 0.7072390913963318),</span>
<span class="token comment">#  ('bungalow', 0.6878559589385986),</span>
<span class="token comment">#  ('apartment', 0.6628996133804321),</span>
<span class="token comment">#  ('bedroom', 0.6496937274932861),</span>
<span class="token comment">#  ('townhouse', 0.6384080052375793),</span>
<span class="token comment">#  ('residence', 0.6198420524597168),</span>
<span class="token comment">#  ('mansion', 0.6058191657066345),</span>
<span class="token comment">#  ('farmhouse', 0.5857570171356201),</span>
<span class="token comment">#  ('duplex', 0.5757936239242554),</span>
<span class="token comment">#  ('appartment', 0.5690325498580933)]</span>

model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">"cat"</span><span class="token punctuation">,</span> <span class="token string">"dog"</span><span class="token punctuation">)</span>
<span class="token comment"># [('Tia_Dalma_Naomie_Harris', 0.2577422261238098),</span>
<span class="token comment">#  ('Mouseland', 0.2575077712535858),</span>
<span class="token comment">#  ('antennal', 0.25083598494529724),</span>
<span class="token comment">#  ('chironomid', 0.24755403399467468),</span>
<span class="token comment">#  ('floo', 0.2461230456829071),</span>
<span class="token comment">#  ('fiendish_plot', 0.2458873838186264),</span>
<span class="token comment">#  ('architraves', 0.2403106689453125),</span>
<span class="token comment">#  ('mouse', 0.23750734329223633),</span>
<span class="token comment">#  ('flitting', 0.23703250288963318),</span>
<span class="token comment">#  ('pipistrelles', 0.23694036900997162)]</span>

model<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">"bad"</span><span class="token punctuation">,</span> <span class="token string">"good"</span><span class="token punctuation">)</span>
<span class="token comment"># [('maniacal_killer', 0.3601454198360443),</span>
<span class="token comment">#  ('Bad', 0.34592676162719727),</span>
<span class="token comment">#  ('insuring_repackaged_subprime_mortgages', 0.3452882766723633),</span>
<span class="token comment">#  ('subprime_mortgage_debacle', 0.33132150769233704),</span>
<span class="token comment">#  ('hedge_fund_blowups', 0.32805106043815613),</span>
<span class="token comment">#  ('flimflams', 0.3191104233264923),</span>
<span class="token comment">#  ('Abu_Ghraibs', 0.3178219199180603),</span>
<span class="token comment">#  ('anti_semitic_tirade', 0.3143758177757263),</span>
<span class="token comment">#  ('Um_Mazin', 0.31121256947517395),</span>
<span class="token comment">#  ('lax_supervision', 0.3109944462776184)]</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<h4 id="문장-구조" style="position:relative;">문장 구조<a href="#%EB%AC%B8%EC%9E%A5-%EA%B5%AC%EC%A1%B0" aria-label="문장 구조 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<ul>
<li>nlp_study_005.ipynb</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">!python <span class="token operator">-</span>m spacy download en_core_web_sm

<span class="token comment"># The structure of text</span>
<span class="token keyword">import</span> spacy

nlp <span class="token operator">=</span> spacy<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"en_core_web_sm"</span><span class="token punctuation">)</span>

tokens <span class="token operator">=</span> parser<span class="token punctuation">(</span><span class="token string">"She ran"</span><span class="token punctuation">)</span>
tokens<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
<span class="token comment"># (She ran, spacy.tokens.doc.Doc, 2)</span>

tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tokens<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment"># (She, ran)</span>

<span class="token builtin">dir</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">dir</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># (['_',</span>
<span class="token comment">#   '__bytes__',</span>
<span class="token comment">#   '__class__',</span>
<span class="token comment">#   '__delattr__',</span>
<span class="token comment">#   '__dir__',</span>
<span class="token comment">#   '__doc__',</span>
<span class="token comment">#   '__eq__',</span>
<span class="token comment">#   '__format__',</span>
<span class="token comment">#   '__ge__',</span>
<span class="token comment">#   '__getattribute__',</span>
<span class="token comment">#   '__gt__',</span>
<span class="token comment">#   '__hash__',</span>
<span class="token comment">#   '__init__',</span>
<span class="token comment">#   '__init_subclass__',</span>
<span class="token comment">#   '__le__',</span>
<span class="token comment">#   '__len__',</span>
<span class="token comment">#   '__lt__',</span>
<span class="token comment">#   '__ne__',</span>
<span class="token comment">#   '__new__',</span>
<span class="token comment">#   '__pyx_vtable__',</span>
<span class="token comment">#   '__reduce__',</span>
<span class="token comment">#   '__reduce_ex__',</span>
<span class="token comment">#   '__repr__',</span>
<span class="token comment">#   '__setattr__',</span>
<span class="token comment">#   '__sizeof__',</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#   'text',</span>
<span class="token comment">#   'text_with_ws',</span>
<span class="token comment">#   'vector',</span>
<span class="token comment">#   'vector_norm',</span>
<span class="token comment">#   'vocab',</span>
<span class="token comment">#   'whitespace_'])</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_POS</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> parser<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{} : {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>token<span class="token punctuation">.</span>orth_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>pos_<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># print(f"{token.orth_} : {token.pos_}")</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>show_POS<span class="token punctuation">(</span><span class="token string">"She hit the wall."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># She : PRON</span>
<span class="token comment"># hit : VERB</span>
<span class="token comment"># the : DET</span>
<span class="token comment"># wall : NOUN</span>
<span class="token comment"># . : PUNCT</span>
<span class="token comment"># None      </span>

<span class="token keyword">def</span> <span class="token function">show_dep</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> token_parser<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{} : {} : {} : {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>token<span class="token punctuation">.</span>orth_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>pos_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>dep_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>head<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>show_dep<span class="token punctuation">(</span><span class="token string">"She hit the wall."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># She : PRON : nsubj : hit</span>
<span class="token comment"># hit : VERB : ROOT : hit</span>
<span class="token comment"># the : DET : det : wall</span>
<span class="token comment"># wall : NOUN : dobj : hit</span>
<span class="token comment"># . : PUNCT : punct : hit</span>
<span class="token comment"># None</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<ul>
<li>
<p><a href="https://cs.nyu.edu/grishman/jet/guide/PennPOS.html">https://cs.nyu.edu/grishman/jet/guide/PennPOS.html</a></p>
</li>
<li>
<p><a href="https://demos.explosion.ai/displacy/">https://demos.explosion.ai/displacy/</a> -> 시각적으로 보여줌</p>
</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_head_of_sentence</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> token_parser<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>token<span class="token punctuation">.</span>head<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>token<span class="token punctuation">.</span>head<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> token<span class="token punctuation">.</span>head <span class="token keyword">is</span> token<span class="token punctuation">:</span>
            <span class="token keyword">return</span> token
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>get_head_of_sentence<span class="token punctuation">(</span><span class="token string">"She hit the wall."</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># hit</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># hit</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># wall</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># hit</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># hit</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># None    </span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">show_ents</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Showing by token …"</span><span class="token punctuation">)</span>
  parsed <span class="token operator">=</span> token_parser<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
  <span class="token keyword">for</span> token <span class="token keyword">in</span> parsed<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>token<span class="token punctuation">.</span>orth_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>ent_type_<span class="token punctuation">)</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  

  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Just showing the entities …"</span><span class="token punctuation">)</span>
  entities <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>parsed<span class="token punctuation">.</span>ents<span class="token punctuation">)</span>
  <span class="token keyword">for</span> entity <span class="token keyword">in</span> entities<span class="token punctuation">:</span>
      <span class="token keyword">print</span><span class="token punctuation">(</span>entity<span class="token punctuation">.</span>label_<span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>t<span class="token punctuation">.</span>orth_ <span class="token keyword">for</span> t <span class="token keyword">in</span> entity<span class="token punctuation">)</span><span class="token punctuation">)</span>

show_ents<span class="token punctuation">(</span><span class="token string">"I went to New York City and spoke in French."</span><span class="token punctuation">)</span>  
<span class="token comment"># Showing by token …</span>
<span class="token comment"># I</span>
<span class="token comment"># went</span>
<span class="token comment"># to</span>
<span class="token comment"># New GPE</span>
<span class="token comment"># York GPE</span>
<span class="token comment"># City GPE</span>
<span class="token comment"># and</span>
<span class="token comment"># spoke</span>
<span class="token comment"># in</span>
<span class="token comment"># French LANGUAGE</span>
<span class="token comment"># .</span>
<span class="token comment">#</span>
<span class="token comment"># Just showing the entities …</span>
<span class="token comment"># GPE New York City</span>
<span class="token comment"># LANGUAGE French</span>

get_head_of_sentence<span class="token punctuation">(</span><span class="token string">"I went to New York City and spoke in French."</span><span class="token punctuation">)</span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># York</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># City</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># to</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># spoke</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># in</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span>
<span class="token comment"># went</span>
<span class="token comment"># &lt;class 'spacy.tokens.token.Token'></span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>entity는 중요하다. 문장의 의도를 파악해야 하기 때문.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># NLU : Natural Language Understanding</span>

show_ents<span class="token punctuation">(</span><span class="token string">"I paid $50 and 50 dollars on March 12, 2016"</span><span class="token punctuation">)</span>
<span class="token comment"># Showing by token …</span>
<span class="token comment"># I</span>
<span class="token comment"># paid</span>
<span class="token comment"># $</span>
<span class="token comment"># 50 MONEY</span>
<span class="token comment"># and</span>
<span class="token comment"># 50</span>
<span class="token comment"># dollars</span>
<span class="token comment"># on</span>
<span class="token comment"># March DATE</span>
<span class="token comment"># 12 DATE</span>
<span class="token comment"># , DATE</span>
<span class="token comment"># 2016 DATE</span>
<span class="token comment">#</span>
<span class="token comment"># Just showing the entities …</span>
<span class="token comment"># MONEY 50</span>
<span class="token comment"># DATE March 12 , 2016</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<ul>
<li>sentimentalanalysis.ipynb</li>
</ul>
<p>nlp_utils.py와 contractions.py를 제공받았다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># In this project we are supposed to predict the sentiment of a given text, And predict if the text is positive, negative or neutral in nature.</span>

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>cm <span class="token keyword">as</span> cm
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> rcParams
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> re
<span class="token keyword">import</span> nltk
<span class="token keyword">import</span> string
<span class="token keyword">import</span> nlp_utils
<span class="token keyword">import</span> collections
<span class="token keyword">import</span> contractions
<span class="token keyword">import</span> nlp_utils <span class="token keyword">as</span> nu
<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> stopwords
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> WordNetLemmatizer
<span class="token keyword">from</span> wordcloud <span class="token keyword">import</span> WordCloud<span class="token punctuation">,</span> STOPWORDS
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> word_tokenize<span class="token punctuation">,</span> sent_tokenize
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> PorterStemmer<span class="token punctuation">,</span> LancasterStemmer<span class="token punctuation">,</span> SnowballStemmer

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score

<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"TextAnalytics.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    text <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>

text
<span class="token comment"># '0,"One of the other reviewers has mentioned that after watching just 1 Oz episode you\'ll be hooked. They are right, as this is exactly what happened with me.&lt;br />&lt;br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br />&lt;br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br />&lt;br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn\'t dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn\'t mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn\'t say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who\'ll be sold out for a nickel, inmates who\'ll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side."\n1,"A wonderful little production. &lt;br />&lt;br ... (생략)    </span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 이번 단계는 text normalization : text를 standard form으로 변환해주는 단계</span>
<span class="token comment"># 예) goood or gud = good</span>
<span class="token comment"># 예) stopwords or stop-words or stop words = stopwords</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token comment"># (1319900, str)</span>

text <span class="token operator">=</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token comment"># (1000, list)</span>

corpus <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">,</span> corpus
<span class="token comment"># (1,</span>
<span class="token comment">#  list,</span>
<span class="token comment">#  [['0,"One of the other reviewers has mentioned that after watching just 1 Oz episode you\'ll be hooked. They are right, as this is exactly what happened with me.&lt;br />&lt;br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br />&lt;br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br />&lt;br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn\'t dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn\'t mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn\'t say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who\'ll be sold out for a nickel, inmates who\'ll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side."',</span>
<span class="token comment">#    '1,"A wonderful little production. &lt;br />&lt;br />The filming technique is very unassuming- very ... (생략)</span>

corpus <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> sent <span class="token keyword">in</span> text<span class="token punctuation">:</span>
    corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sent<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span>    
<span class="token comment"># 1 &lt;class 'list'></span>
<span class="token comment"># 1001 &lt;class 'list'></span>

corpus<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment"># ['0,"One of the other reviewers has mentioned that after watching just 1 Oz episode you\'ll be hooked. They are right, as this is exactly what happened with me.&lt;br />&lt;br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which ... (생략)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>corpus[1]는 실제로 tab으로 분리가 가능했다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">letters_only <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^a-zA-Z]"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span>

letters_only
<span class="token comment"># '      One of the other reviewers has mentioned that after watching just   Oz episode you  ll be hooked  They are right  as this is exactly what happened with me  br    br   The first thing that struck me about Oz was its brutality and unflinching scenes of violence  which set in right from the word GO  Trust me  this is not a show for the faint hearted or timid  This show pulls no punches with regards to drugs   ...(생략)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span></span></pre></div>
<p>문자만 나온다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> nltk
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'punkt'</span><span class="token punctuation">)</span>

letters_only <span class="token operator">=</span> letters_only<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>

token <span class="token operator">=</span> nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span>letters_only<span class="token punctuation">)</span>
<span class="token builtin">type</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span>
<span class="token comment"># (list, 1)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">num_dec_al</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> word<span class="token punctuation">.</span>isnumeric<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"XXXXXX"</span>
    <span class="token keyword">elif</span> word<span class="token punctuation">.</span>isdecimal<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"XXX..."</span>
    <span class="token keyword">elif</span> word<span class="token punctuation">.</span>isalpha<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> word
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"XXXAAA"</span>

<span class="token keyword">def</span> <span class="token function">clearn_nda</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> nlp_utils<span class="token punctuation">.</span>w_tokenization<span class="token punctuation">(</span>token<span class="token punctuation">)</span>
    map_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span>num_dec_al<span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>map_list<span class="token punctuation">)</span>

corpus_nda <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span>clearn_nda<span class="token punctuation">,</span> token<span class="token punctuation">)</span><span class="token punctuation">)</span>
corpus_nda

<span class="token comment"># ['one of the other reviewers has mentioned that after watching just oz episode you ll be hooked they are right as this is exactly what happened with me br br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word br br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an ex... (생략)</span>

<span class="token builtin">type</span><span class="token punctuation">(</span>corpus_nda<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>corpus_nda<span class="token punctuation">)</span>
<span class="token comment"># (list, 1)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>문자만 깔끔하게 나온다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># Contraction : 축약형</span>
<span class="token comment"># 축약형 제거</span>
<span class="token comment"># isn't => is not</span>
<span class="token comment"># I'm => I am</span>
<span class="token comment"># they're => they are</span>

conm <span class="token operator">=</span> contractions<span class="token punctuation">.</span>CONTRACTION_MAP

<span class="token keyword">def</span> <span class="token function">contraction_remove</span><span class="token punctuation">(</span>corpus_nda<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> conm<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        corpus_nda <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">,</span> corpus_nda<span class="token punctuation">)</span>
    <span class="token keyword">return</span> corpus_nda

special <span class="token operator">=</span> string<span class="token punctuation">.</span>punctuation
<span class="token keyword">def</span> <span class="token function">w_tokenization</span><span class="token punctuation">(</span>corpus_nda<span class="token punctuation">)</span><span class="token punctuation">:</span>
    corpus_nda <span class="token operator">=</span> corpus_nda<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    corpus_nda <span class="token operator">=</span> contraction_remove<span class="token punctuation">(</span>corpus_nda<span class="token punctuation">)</span>   

data <span class="token operator">=</span> <span class="token punctuation">[</span>corpus_nda<span class="token punctuation">]</span>
<span class="token keyword">for</span> sent <span class="token keyword">in</span> text<span class="token punctuation">:</span>
    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sent<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     

data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sent<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

df
<span class="token comment"># 0	1	2	3	4	5	6</span>
<span class="token comment"># 0	one of the other reviewers has mentioned that ...	None	None	None	None	None	None</span>
<span class="token comment"># 1	0,"One of the other reviewers has mentioned th...	None	None	None	None	None	None</span>
<span class="token comment"># 2	1,"A wonderful little production. &lt;br />&lt;br />...	None	None	None	None	None	None</span>
<span class="token comment"># 3	2,"I thought this was a wonderful way to spend...	None	None	None	None	None	None</span>
<span class="token comment"># 4	3,"Basically there's a family where a little b...	None	None	None	None	None	None</span>
<span class="token comment"># ...	...	...	...	...	...	...	...</span>
<span class="token comment"># 997	996,"I hated it. I hate self-aware pretentious...	None	None	None	None	None	None</span>
<span class="token comment"># 998	997,"I usually try to be professional and cons...	None	None	None	None	None	None</span>
<span class="token comment"># 999	998,"If you like me is going to see this in a ...	None	None	None	None	None	None</span>
<span class="token comment"># 1000	999,"This is like a zoology textbook, given th...	None	None	None	None	None	None</span>
<span class="token comment"># 1001	999,"This is like a zoology textbook, given th...	None	None	None	None	None	None</span>
<span class="token comment"># 1002 rows × 7 columns    </span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>텍스트 빼고 버린다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

df <span class="token operator">=</span> df<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">"Text"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>df<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>df<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token number">1000</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

df
<span class="token comment"># Text</span>
<span class="token comment"># 1	0,"One of the other reviewers has mentioned th...</span>
<span class="token comment"># 2	1,"A wonderful little production. &lt;br />&lt;br />...</span>
<span class="token comment"># 3	2,"I thought this was a wonderful way to spend...</span>
<span class="token comment"># 4	3,"Basically there's a family where a little b...</span>
<span class="token comment"># 5	4,"Petter Mattei's ""Love in the Time of Money...</span>
<span class="token comment"># ...	...</span>
<span class="token comment"># 996	995,"Nothing is sacred. Just ask Ernie Fosseli...</span>
<span class="token comment"># 997	996,"I hated it. I hate self-aware pretentious...</span>
<span class="token comment"># 998	997,"I usually try to be professional and cons...</span>
<span class="token comment"># 999	998,"If you like me is going to see this in a ...</span>
<span class="token comment"># 1000	999,"This is like a zoology textbook, given th...</span>
<span class="token comment"># 1000 rows × 1 columns</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\d+"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">",+"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"br+"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'"'</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"?"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"-"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"***"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"&lt;/>"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> regex<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

df
<span class="token comment"># Text</span>
<span class="token comment"># 1	One of the other reviewers has mentioned that ...</span>
<span class="token comment"># 2	A wonderful little production. &lt; />&lt; />The fil...</span>
<span class="token comment"># 3	I thought this was a wonderful way to spend ti...</span>
<span class="token comment"># 4	Basically theres a family where a little boy (...</span>
<span class="token comment"># 5	Petter Matteis Love in the Time of Money is a ...</span>
<span class="token comment"># ...	...</span>
<span class="token comment"># 996	Nothing is sacred. Just ask Ernie Fosselius. T...</span>
<span class="token comment"># 997	I hated it. I hate selfaware pretentious inani...</span>
<span class="token comment"># 998	I usually try to be professional and construct...</span>
<span class="token comment"># 999	If you like me is going to see this in a film ...</span>
<span class="token comment"># 1000	This is like a zoology textbook given that its...</span>
<span class="token comment"># 1000 rows × 1 columns</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">"["</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">"]"</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">"("</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">")"</span><span class="token punctuation">)</span>

df
<span class="token comment"># Text</span>
<span class="token comment"># 1	One of the other reviewers has mentioned that ...</span>
<span class="token comment"># 2	A wonderful little production. The filming tec...</span>
<span class="token comment"># 3	I thought this was a wonderful way to spend ti...</span>
<span class="token comment"># 4	Basically theres a family where a little boy (...</span>
<span class="token comment"># 5	Petter Matteis Love in the Time of Money is a ...</span>
<span class="token comment"># ...	...</span>
<span class="token comment"># 996	Nothing is sacred. Just ask Ernie Fosselius. T...</span>
<span class="token comment"># 997	I hated it. I hate selfaware pretentious inani...</span>
<span class="token comment"># 998	I usually try to be professional and construct...</span>
<span class="token comment"># 999	If you like me is going to see this in a film ...</span>
<span class="token comment"># 1000	This is like a zoology textbook given that its...</span>
<span class="token comment"># 1000 rows × 1 columns</span>

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'averaged_perceptron_tagger'</span><span class="token punctuation">)</span>
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'wordnet'</span><span class="token punctuation">)</span>
<span class="token comment"># [nltk_data] Downloading package averaged_perceptron_tagger to</span>
<span class="token comment"># [nltk_data]     C:\Users\Choi\AppData\Roaming\nltk_data...</span>
<span class="token comment"># [nltk_data]   Package averaged_perceptron_tagger is already up-to-</span>
<span class="token comment"># [nltk_data]       date!</span>
<span class="token comment"># [nltk_data] Downloading package wordnet to</span>
<span class="token comment"># [nltk_data]     C:\Users\Choi\AppData\Roaming\nltk_data...</span>
<span class="token comment"># [nltk_data]   Package wordnet is already up-to-date!</span>
<span class="token comment"># True</span>

df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>nu<span class="token punctuation">.</span>lemmatization_sentence<span class="token punctuation">)</span>

df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span>
<span class="token comment"># Text</span>
<span class="token comment"># 1	one of the other reviewer have mention that af...</span>
<span class="token comment"># 2	a wonderful little production the filming tech...</span>
<span class="token comment"># 3	i think this be a wonderful way to spend time ...</span>
<span class="token comment"># 4	basically theres a family where a little boy j...</span>
<span class="token comment"># 5	petter matteis love in the time of money be a ...</span>
<span class="token comment"># ...	...</span>
<span class="token comment"># 996	nothing be sacred just ask ernie fosselius the...</span>
<span class="token comment"># 997	i hat it i hate selfaware pretentious inanity ...</span>
<span class="token comment"># 998	i usually try to be professional and construct...</span>
<span class="token comment"># 999	if you like me be go to see this in a film his...</span>
<span class="token comment"># 1000	this be like a zoology textbook give that it d...</span>
<span class="token comment"># 1000 rows × 1 columns</span>

Text <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"Text"</span><span class="token punctuation">]</span>
<span class="token builtin">type</span><span class="token punctuation">(</span>Text<span class="token punctuation">)</span>
<span class="token comment"># pandas.core.series.Series</span>

token <span class="token operator">=</span> Text<span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token builtin">type</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">,</span> token<span class="token punctuation">.</span>shape
<span class="token comment"># (numpy.ndarray, (1000,))</span>

token
<span class="token comment"># array(['one of the other reviewer have mention that after watch just oz episode youll be hook they be right a this be exactly what happen with me.the first thing that strike me about oz be it utality and unflinching scene of violence which set in right from the word go trust me this be not a show for the faint hearted or timid this show pull no punch with regard to drug sex or violence it be hardcore in the classic use of the word.it be call oz a that be the nickname give to the oswald maximum security state penitentary it focus mainly on emerald city an experimental section of the prison where all the cell have glass front and face inwards so privacy be not high on the agenda em city be home to many .. aryan muslim gangstas latinos christian italian irish and more .... so scuffles death stare dodgy dealing and shady agreement be never far away.i would say the main appeal of the show be due to the fact that it go where other show wouldnt dare forget pretty picture paint for mainstream audience forget charm forget romance ... oz doesnt mess around the first episode i ever saw strike me a so nasty it be surreal i couldnt say i be ready for it but a i watch more i develop a taste for oz and get accustom to the high level of graphic violence not just violence but injustice crook guard wholl be sell out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmate be turn into prison bitch due to their lack of street skill or prison experience watch oz you may become comfortable with what be uncomfortable view .... thats if you can get in touch with your darker side',</span>
<span class="token comment">#        'a wonderful little production the filming technique be very unassuming very oldtimebbc fashion and give a comforting and sometimes discomforting sense of realism to the entire piece the actor be extremely well choose michael sheen not only have get all the polari but he have all the voice down pat too you can truly see the seamless edit guide by the reference to williams diary entry not only be it well worth the watching but it be a terrificly write and perform piece a masterful production about one of the great master of comedy and his life the realism really come home with the little thing the fantasy of the guard which rather than use the traditional dream technique remain solid then disappear it play on our knowledge and our sens particularly with the scene concern orton and halliwell and the set particularly of their flat with halliwells mural decorate every surface be terribly well do',</span>
<span class="token comment">#        'i think this be a wonderful way to spend time on a too ... (생략)</span>

token <span class="token operator">=</span> nltk<span class="token punctuation">.</span>sent_tokenize<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">)</span>

data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>token<span class="token punctuation">)</span>

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'stopwords'</span><span class="token punctuation">)</span>
<span class="token comment"># [nltk_data] Downloading package stopwords to</span>
<span class="token comment"># [nltk_data]     C:\Users\Choi\AppData\Roaming\nltk_data...</span>
<span class="token comment"># [nltk_data]   Package stopwords is already up-to-date!</span>
<span class="token comment"># True</span>

stop <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">"english"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

text <span class="token operator">=</span> data
text_tokens <span class="token operator">=</span> word_tokenize<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>

tokens_without_sw <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> text_tokens <span class="token keyword">if</span> <span class="token keyword">not</span> word <span class="token keyword">in</span> stop<span class="token punctuation">]</span>

stopwords <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">"english"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

wordcloud <span class="token operator">=</span> WordCloud<span class="token punctuation">(</span>stopwords <span class="token operator">=</span> stop<span class="token punctuation">,</span> background_color <span class="token operator">=</span> <span class="token string">"white"</span><span class="token punctuation">,</span> max_words <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>tokens_without_sw<span class="token punctuation">)</span><span class="token punctuation">)</span>

rcParams<span class="token punctuation">[</span><span class="token string">"figure.figsize"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wordcloud<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">tokens_without_sw
<span class="token comment"># ['[',</span>
<span class="token comment">#  '``',</span>
<span class="token comment">#  '[',</span>
<span class="token comment">#  "'one",</span>
<span class="token comment">#  'reviewer',</span>
<span class="token comment">#  'mention',</span>
<span class="token comment">#  'watch',</span>
<span class="token comment">#  'oz',</span>
<span class="token comment">#  'episode',</span>
<span class="token comment">#  'youll',</span>
<span class="token comment">#  'hook',</span>
<span class="token comment">#  'right',</span>
<span class="token comment">#  'exactly',</span>
<span class="token comment">#  'happen',</span>
<span class="token comment">#  'me.the',</span>
<span class="token comment">#  'first',</span>
<span class="token comment">#  'thing',</span>
<span class="token comment">#  'strike',</span>
<span class="token comment">#  'oz',</span>
<span class="token comment">#  'utality',</span>
<span class="token comment">#  'unflinching',</span>
<span class="token comment">#  'scene',</span>
<span class="token comment">#  'violence',</span>
<span class="token comment">#  'set',</span>
<span class="token comment">#  'right',</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#  'people',</span>
<span class="token comment">#  'enjoy',</span>
<span class="token comment">#  'kill',</span>
<span class="token comment">#  'mercs',</span>
<span class="token comment">#  'infiltrate',</span>
<span class="token comment">#  ...]</span>

<span class="token builtin">type</span><span class="token punctuation">(</span>tokens_without_sw<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>tokens_without_sw<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>tokens_without_sw<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># (list, str, str)</span>

tokens_without_sw <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>tokens_without_sw<span class="token punctuation">)</span><span class="token punctuation">)</span>

filtered_words <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> tokens_without_sw<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">]</span>
counted_words <span class="token operator">=</span> collections<span class="token punctuation">.</span>Counter<span class="token punctuation">(</span>filtered_words<span class="token punctuation">)</span>

<span class="token builtin">type</span><span class="token punctuation">(</span>counted_words<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># list</span>

words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
counts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> letter<span class="token punctuation">,</span> count <span class="token keyword">in</span> counted_words<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>letter<span class="token punctuation">)</span>
    counts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>count<span class="token punctuation">)</span>

counted_words<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token comment"># [("'movie',", 2019),</span>
<span class="token comment">#  ("'film',", 1773),</span>
<span class="token comment">#  ("'one',", 980),</span>
<span class="token comment">#  ("'make',", 888),</span>
<span class="token comment">#  ("'see',", 856),</span>
<span class="token comment">#  ("'like',", 828),</span>
<span class="token comment">#  ("'get',", 751),</span>
<span class="token comment">#  ("'good',", 644),</span>
<span class="token comment">#  ("'go',", 542),</span>
<span class="token comment">#  ("'watch',", 541),</span>
<span class="token comment">#  ("'time',", 533),</span>
<span class="token comment">#  ("'character',", 524),</span>
<span class="token comment">#  ("'even',", 510),</span>
<span class="token comment">#  ("'would',", 490),</span>
<span class="token comment">#  ("'bad',", 489),</span>
<span class="token comment">#  ("'think',", 471),</span>
<span class="token comment">#  ("'story',", 468),</span>
<span class="token comment">#  ("'really',", 452),</span>
<span class="token comment">#  ("'well',", 446),</span>
<span class="token comment">#  ("'scene',", 434),</span>
<span class="token comment">#  ("'much',", 392),</span>
<span class="token comment">#  ("'show',", 375),</span>
<span class="token comment">#  ("'great',", 375),</span>
<span class="token comment">#  ("'know',", 368),</span>
<span class="token comment">#  ("'take',", 361),</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#  ("'tell',", 148),</span>
<span class="token comment">#  ("'didnt',", 148),</span>
<span class="token comment">#  ('"\'this",', 146),</span>
<span class="token comment">#  ("'around',", 145),</span>
<span class="token comment">#  ("'comedy',", 145),</span>
<span class="token comment">#  ("'u',", 144)]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>counts<span class="token punctuation">)</span>
<span class="token comment"># ["'movie',", "'film',", "'one',", "'make',", "'see',", "'like',", "'get',", "'good',", "'go',", "'watch',"]</span>
<span class="token comment"># [2019, 1773, 980, 888, 856, 828, 751, 644, 542, 541]</span>

colors <span class="token operator">=</span> cm<span class="token punctuation">.</span>rainbow<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rcParams<span class="token punctuation">[</span><span class="token string">"figure.figsize"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Top words in the headlines vs their count"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Count"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Words"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>barh<span class="token punctuation">(</span>words<span class="token punctuation">,</span> counts<span class="token punctuation">,</span> color<span class="token operator">=</span>colors<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>d</p></div></div></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/ai-이노베이션-스퀘어-언어-19일차/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-55ff3df016f1bf520dc3.js"],"app":["/app-b088d9e31d6ec271920e.js"],"component---src-pages-about-js":["/component---src-pages-about-js-01b4957cf3a65784e9dc.js"],"component---src-pages-contact-js":["/component---src-pages-contact-js-47c9a9e86f5834f6d116.js"],"component---src-pages-index-js":["/component---src-pages-index-js-dbf9480c3ca0918d5a04.js"],"component---src-pages-my-files-js":["/component---src-pages-my-files-js-f04405e2ce36edc47b27.js"],"component---src-pages-tags-js":["/component---src-pages-tags-js-6eaa04bdf1ac86b2d473.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-33322b93090050d5fb1b.js"]};/*]]>*/</script><script src="/polyfill-55ff3df016f1bf520dc3.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-33322b93090050d5fb1b.js" async=""></script><script src="/e3fcc2076860498e4deed45a66207f3abfe77099-7463bcd7e6ea2ff920c3.js" async=""></script><script src="/commons-71b7b1d300b3ebc29573.js" async=""></script><script src="/app-b088d9e31d6ec271920e.js" async=""></script><script src="/framework-24ad6bf468f69b85cc4b.js" async=""></script><script src="/webpack-runtime-9d111699065b1154a31b.js" async=""></script></body></html>