{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-19일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"19일차\" style=\"position:relative;\">19일차<a href=\"#19%EC%9D%BC%EC%B0%A8\" aria-label=\"19일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>오후 4시 전, 시험을 봤다. 비대면이라 뭐... ㅎㅎ 사후평가는 주관식, 2차 사전평가는 강의 초반에 봤던 평가 문제랑 동일했다. 주관식이 좀 쫄린다.</li>\n<li>오늘은 TF 2.0으로 (mnist) 일반 NN과 CNN을 해봤다. 내일은 Next ai 로 마무리되는 듯. ㅎㅎㅠ <strong>빨리 고급 과정 열렸으면 좋겠다!</strong> 망할 코로나...</li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>python - slicing / list comprehension / lambda / numpy  </li>\n<li>a way to prevent overfitting</li>\n</ul>\n<hr>\n<h3 id=\"nn-mnist-example\" style=\"position:relative;\">NN (mnist example)<a href=\"#nn-mnist-example\" aria-label=\"nn mnist example permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>아키텍처 관점에서 ML에선 dense가 최소 1개, DL에선 최소 2개 있어야 한다.</li>\n<li>TF 2.0 에서 data 불러오는 interface로 load_data()를 쓰면 된다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span>t_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span>t_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<ul>\n<li>one hot encoding 대신 to_categorical을 쓰면 된다.\n10개 범위로 하라는 뜻이다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">t_train <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>cf. NN이라 SGD를 써봤다만, CNN에서는 Adam이 성능이 좋다. relu는 속도가 빠르기 때문에 쓴다.</p>\n<ul>\n<li>NN 입력층 데이터 타입은 vector라 Flatten를 써서 표현한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">input_layer <span class=\"token operator\">=</span> Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'input_layer'</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<hr>\n<h4 id=\"예제3-epoch-5번마다-accuracy-loss-출력하기\" style=\"position:relative;\">예제3. epoch 5번마다 accuracy, loss 출력하기<a href=\"#%EC%98%88%EC%A0%9C3-epoch-5%EB%B2%88%EB%A7%88%EB%8B%A4-accuracy-loss-%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0\" aria-label=\"예제3 epoch 5번마다 accuracy loss 출력하기 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>tf 2.0 model.fit 하면 모든 epoch에 대해 다 나오는데,<br>\n이렇게 다른 방식으로 출력되게 해야할 때가 있다.  </p>\n<p>원하는 만큼만 출력하려면?\n원본 model.fit 못 바꾸니까 return 값을 바꿔줘야 한다.</p>\n<hr>\n<h3 id=\"tf-20---cnn-basic-architecture\" style=\"position:relative;\">TF 2.0 - CNN Basic Architecture<a href=\"#tf-20---cnn-basic-architecture\" aria-label=\"tf 20   cnn basic architecture permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>CNN input은 tensor이다. feature 정보 유지를 위해서다.\n​\n숫자 5 - 가로,세로,색깔 = tensor => feature 유지</li>\n</ul>\n<p>vector 1줄로 펴햔하면 색깔 정보 날아가고 위치만 나타내게 된다.</p>\n<p>가운데 크게 적힌 숫자 5랑 구석에 작게 적힌 숫자 5 이미지는 일반 ML에선 다른 숫자로 인식된다.</p>\n<p>숫자5라는 건 5라는 위치가 중요한 게 아니라 5가 갖고 있는 feature가 중요한 거다.</p>\n<p>그래서 강제로 vector로 만들면 feature가 없어진다.</p>\n<ul>\n<li>TF 2.0 에서는 1 버전대와 다르게 conv2D I/O channel 없다. 2 버전 대에서는 내부적으로 계산해 준다.</li>\n</ul>\n<p>one-hot encoding 패스하려면 (내부적으로는 one-hot endoing으로 바꿔준다만) model.compile 시 sparse<em>categorical</em>crossentropy 를 쓰면 된다.\n​</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>Adam<span class=\"token punctuation\">(</span>lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<ul>\n<li>model.fit 할 때 Flatten으로 안 만들고 X를 tensor로 한다. tnesor로 안 하면 에러난다.</li>\n</ul>\n<hr>\n<h4 id=\"예제3-indexlabelprediction\" style=\"position:relative;\">예제3. index<em>label</em>prediction<a href=\"#%EC%98%88%EC%A0%9C3-indexlabelprediction\" aria-label=\"예제3 indexlabelprediction permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>predict type 확인 (type(return[0])) => flatten</p>\n<p>index<em>label</em>prediction => fit -> predict -> 비교</p>\n<p>2.0에서는 predict api 실행</p>\n<p>model.predict return은 numpy다</p>\n<p>cf. 1.0에서는 predicted_val 이라는 노드를 만들고 sess.run에서 실행했음</p>\n<p>cf. img label을 title 아닌 xlabel에 쓸 수도 있긴 하다.</p>\n<hr>\n<p>예제 4-1. 2conv 1 flatten</p>\n<p>예제 4-2. 2conv 1 flatten + index<em>label</em>prediction</p>\n<hr>\n<h4 id=\"예제7-dropout\" style=\"position:relative;\">예제7. dropout<a href=\"#%EC%98%88%EC%A0%9C7-dropout\" aria-label=\"예제7 dropout permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>ML의 가장 큰문제는 over fitting으로 w,b가 input에 과적합 된다는 의미이다.</p>\n<p>w,b가 미묘하게 변하니까 input에 맞춰지는 느낌이 드는데, 가끔씩 random하게 w,b 증감폭을 변화를 줄 수 없을까?</p>\n<p><strong>w에 0을 주면 데이터가 다음 계층으로 전달되지 않아 끊김 효과를 줄 수 있다.</strong></p>\n<p>random.choice로 구현해도 된다만, 복잡하다. TF 2.0에서는 Dropout이 있다.</p>\n<p>​</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 20% 비율로 dropout</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>위에 있는 512나 0.2 모두 hyper parameter이다.</p>\n<hr>\n<h4 id=\"★-how-to-prevent-overfitting-in-ml\" style=\"position:relative;\">★ how to prevent overfitting in ml<a href=\"#%E2%98%85-how-to-prevent-overfitting-in-ml\" aria-label=\"★ how to prevent overfitting in ml permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>(1) split data into train valid test<br>\n(2) apply dropout<br>\n(3) acquire many data the more, the better  </p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#19%EC%9D%BC%EC%B0%A8\">19일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#nn-mnist-example\">NN (mnist example)</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C3-epoch-5%EB%B2%88%EB%A7%88%EB%8B%A4-accuracy-loss-%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0\">예제3. epoch 5번마다 accuracy, loss 출력하기</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#tf-20---cnn-basic-architecture\">TF 2.0 - CNN Basic Architecture</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C3-indexlabelprediction\">예제3. index<em>label</em>prediction</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C7-dropout\">예제7. dropout</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-19%EC%9D%BC%EC%B0%A8/#%E2%98%85-how-to-prevent-overfitting-in-ml\">★ how to prevent overfitting in ml</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 19일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-19일차/"}},"staticQueryHashes":[]}