{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-언어-16일차/",
    "result": {"data":{"markdownRemark":{"html":"<p>어제에 이어서 트위터 고객 평가 data로 model들을 계속 만들었다.</p>\n<hr>\n<h3 id=\"16일차\" style=\"position:relative;\">16일차<a href=\"#16%EC%9D%BC%EC%B0%A8\" aria-label=\"16일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">embed_weights <span class=\"token operator\">=</span> model_1<span class=\"token punctuation\">.</span>get_layer<span class=\"token punctuation\">(</span><span class=\"token string\">\"embedding\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get_weights<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>embed_weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>embed_weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> embed_weights<span class=\"token punctuation\">.</span>shape\r\n<span class=\"token comment\"># (numpy.ndarray, 10000, (10000, 128))</span>\r\n\r\nembed_weights\r\n<span class=\"token comment\"># array([[ 0.02441995, -0.06279781,  0.04128185, ...,  0.03520636,</span>\r\n<span class=\"token comment\">#          0.04297884, -0.0170973 ],</span>\r\n<span class=\"token comment\">#        [ 0.0129386 ,  0.03923737, -0.00836712, ...,  0.04551996,</span>\r\n<span class=\"token comment\">#         -0.00842055, -0.03694591],</span>\r\n<span class=\"token comment\">#        [ 0.01061232,  0.02531289,  0.00599013, ..., -0.01777772,</span>\r\n<span class=\"token comment\">#         -0.00927421, -0.06235224],</span>\r\n<span class=\"token comment\">#        ...,</span>\r\n<span class=\"token comment\">#        [ 0.0364104 , -0.01097212,  0.02243933, ...,  0.01646514,</span>\r\n<span class=\"token comment\">#          0.04830614, -0.00770865],</span>\r\n<span class=\"token comment\">#        [ 0.0013702 , -0.08265006,  0.03457495, ...,  0.06102972,</span>\r\n<span class=\"token comment\">#          0.00560484, -0.02977291],</span>\r\n<span class=\"token comment\">#        [ 0.04698541, -0.0311483 ,  0.07246254, ...,  0.0667727 ,</span>\r\n<span class=\"token comment\">#          0.08143369, -0.11528556]], dtype=float32)</span>\r\n\r\n<span class=\"token keyword\">import</span> io\r\nout_v <span class=\"token operator\">=</span> io<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"embedding_vectors.tsv\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"w\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span>\r\nout_m <span class=\"token operator\">=</span> io<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"embedding_metadata.tsv\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"w\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">\"utf-8\"</span><span class=\"token punctuation\">)</span>    \r\n\r\n<span class=\"token keyword\">for</span> num<span class=\"token punctuation\">,</span> word <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>words_in_vocab<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">if</span> num <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\r\n        <span class=\"token keyword\">continue</span>\r\n    vec <span class=\"token operator\">=</span> embed_weights<span class=\"token punctuation\">[</span>num<span class=\"token punctuation\">]</span>\r\n    out_m<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>word <span class=\"token operator\">+</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span>\r\n    out_v<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string\">\"\\t\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> vec<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"\\n\"</span><span class=\"token punctuation\">)</span>\r\nout_v<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nout_m<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> embedding_vectors.tsv와 embedding_metadata.tsv가 생성된다.<br>\n아래 사이트에서 데이터 분포를 입체적으로(?) 조회해 볼 수 있다.</p>\n<ul>\n<li><a href=\"http://projector.tensorflow.org/\">http://projector.tensorflow.org/</a></li>\n</ul>\n<hr>\n<h4 id=\"model-2---lstm\" style=\"position:relative;\">Model 2 - LSTM<a href=\"#model-2---lstm\" aria-label=\"model 2   lstm permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Recurrent Neural Network (RNN)</li>\n</ul>\n<p>기본 개념 : 미래를 예측하기 위해 과거의 정보를 활용한다.<br>\n입력(x) -> 이전 입력을 기반으로 계산한다 -> 출력(y)<br>\n트위터와 같이 짧은 구절들을 다룰 때 유용<br>\n독해할 때 모르는 단어가 나올 때 이전 문맥을 통해 그 단어를 유추하라.</p>\n<p>Massive earthquake last week, no? (엄청난 지진이 있었다)<br>\nNo Massive earthquake last week. (지진이 없었다)</p>\n<ol>\n<li>one to one : 입력 1개, 출력도 1개</li>\n<li>one to many : 입력 1개, 출력은 many</li>\n<li>many to oe : 입력 many, 출력은 1개 (텍스트 분류)</li>\n<li>many to many : 입력 many, 출력도 many (기계 번역 이나 STT)</li>\n</ol>\n<p>RNN에서 계속 발전하는 개념들 : Long short-term memory cells (LSTMs), Gated recurrent units (GRUs), Bidirectional RNN</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> layers\r\n\r\ninputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> text_vectorizer<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> embedding<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\noutputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\nmodel_2 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"model_2_LSTM\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># (None, 15, 128)</span>\r\n<span class=\"token comment\"># (None, 64)</span>\r\n\r\nmodel_2<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_2<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_2_LSTM\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># input_3 (InputLayer)         [(None, 1)]               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># text_vectorization_1 (TextVe (None, 15)                0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># embedding (Embedding)        (None, 15, 128)           1280000   </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># lstm_1 (LSTM)                (None, 64)                49408     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_2 (Dense)              (None, 1)                 65        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 1,329,473</span>\r\n<span class=\"token comment\"># Trainable params: 1,329,473</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_2_history <span class=\"token operator\">=</span> model_2<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences<span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"LSTM\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/LSTM/20210912-100408</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 12s 38ms/step - loss: 0.2150 - accuracy: 0.9267 - val_loss: 0.5934 - val_accuracy: 0.7769</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 27ms/step - loss: 0.1554 - accuracy: 0.9410 - val_loss: 0.6043 - val_accuracy: 0.7808</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 28ms/step - loss: 0.1282 - accuracy: 0.9536 - val_loss: 0.6155 - val_accuracy: 0.7940</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 30ms/step - loss: 0.1052 - accuracy: 0.9600 - val_loss: 0.9067 - val_accuracy: 0.7782</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 29ms/step - loss: 0.0859 - accuracy: 0.9669 - val_loss: 1.0273 - val_accuracy: 0.7756</span>\r\n\r\nmodel_2_pred_probs <span class=\"token operator\">=</span> model_2<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_2_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_2_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[6.5871990e-01],</span>\r\n<span class=\"token comment\">#         [8.3456910e-01],</span>\r\n<span class=\"token comment\">#         [9.9978948e-01],</span>\r\n<span class=\"token comment\">#         [5.8812916e-02],</span>\r\n<span class=\"token comment\">#         [4.7102571e-04],</span>\r\n<span class=\"token comment\">#         [9.9940670e-01],</span>\r\n<span class=\"token comment\">#         [9.5771265e-01],</span>\r\n<span class=\"token comment\">#         [9.9987233e-01],</span>\r\n<span class=\"token comment\">#         [9.9978209e-01],</span>\r\n<span class=\"token comment\">#         [8.8991135e-01]], dtype=float32))</span>\r\n\r\nmodel_2_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_2_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_2_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)></span>\r\n\r\nmodel_2_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_2_pred<span class=\"token punctuation\">)</span>\r\nmodel_2_results\r\n<span class=\"token comment\"># {'accuracy': 77.55905511811024,</span>\r\n<span class=\"token comment\">#  'precision': 0.7752546169990229,</span>\r\n<span class=\"token comment\">#  'recall': 0.7755905511811023,</span>\r\n<span class=\"token comment\">#  'f1': 0.77525982237961}</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_2_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([False, False, False, False])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> model_1과 비교해 봤을 때 성능이 그다지 향상되지는 않았다.</p>\n<hr>\n<h4 id=\"model_3--gru\" style=\"position:relative;\">model_3 : GRU<a href=\"#model_3--gru\" aria-label=\"model_3  gru permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> layers\r\n\r\ninputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> text_vectorizer<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> embedding<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>GRU<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\noutputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\nmodel_3 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"model_3_GRU\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># (None, 15, 128)</span>\r\n<span class=\"token comment\"># (None, 64)</span>\r\nmodel_3<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\nmodel_3<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_3_GRU\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># input_5 (InputLayer)         [(None, 1)]               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># text_vectorization_1 (TextVe (None, 15)                0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># embedding (Embedding)        (None, 15, 128)           1280000   </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># gru_1 (GRU)                  (None, 64)                37248     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_4 (Dense)              (None, 1)                 65        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 1,317,313</span>\r\n<span class=\"token comment\"># Trainable params: 1,317,313</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_3_history <span class=\"token operator\">=</span> model_3<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences<span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"GRU\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/GRU/20210912-101258</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 11s 34ms/step - loss: 0.1606 - accuracy: 0.9317 - val_loss: 0.7235 - val_accuracy: 0.7848</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 30ms/step - loss: 0.0808 - accuracy: 0.9699 - val_loss: 0.9037 - val_accuracy: 0.7822</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 30ms/step - loss: 0.0696 - accuracy: 0.9724 - val_loss: 0.9787 - val_accuracy: 0.7756</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 28ms/step - loss: 0.0615 - accuracy: 0.9743 - val_loss: 1.1011 - val_accuracy: 0.7782</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 28ms/step - loss: 0.0549 - accuracy: 0.9762 - val_loss: 1.1759 - val_accuracy: 0.7743</span>\r\n\r\nmodel_3_pred_probs <span class=\"token operator\">=</span> model_3<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_3_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_3_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[9.2551112e-04],</span>\r\n<span class=\"token comment\">#         [8.9427662e-01],</span>\r\n<span class=\"token comment\">#         [9.9989712e-01],</span>\r\n<span class=\"token comment\">#         [7.0461214e-02],</span>\r\n<span class=\"token comment\">#         [1.2276595e-04],</span>\r\n<span class=\"token comment\">#         [9.9959743e-01],</span>\r\n<span class=\"token comment\">#         [9.3868709e-01],</span>\r\n<span class=\"token comment\">#         [9.9995911e-01],</span>\r\n<span class=\"token comment\">#         [9.9990690e-01],</span>\r\n<span class=\"token comment\">#         [9.7822285e-01]], dtype=float32))</span>\r\n\r\nmodel_3_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_3_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_3_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)></span>\r\n\r\nmodel_3_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_3_pred<span class=\"token punctuation\">)</span>\r\nmodel_3_results\r\n<span class=\"token comment\"># {'accuracy': 77.42782152230971,</span>\r\n<span class=\"token comment\">#  'precision': 0.7762579677540307,</span>\r\n<span class=\"token comment\">#  'recall': 0.7742782152230971,</span>\r\n<span class=\"token comment\">#  'f1': 0.7721023076072874}</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_3_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([False, False, False, False])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> 이 경우도 성능이 그다지 향상되지는 않았다.</p>\n<hr>\n<h4 id=\"model-4--bidirectional-rnn\" style=\"position:relative;\">Model 4 : Bidirectional RNN<a href=\"#model-4--bidirectional-rnn\" aria-label=\"model 4  bidirectional rnn permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> layers\r\n\r\ninputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> text_vectorizer<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> embedding<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Bidirectional<span class=\"token punctuation\">(</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\noutputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\nmodel_4 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"model_4_Bidirectional\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># (None, 15, 128)</span>\r\n<span class=\"token comment\"># (None, 128)</span>\r\n\r\nmodel_4<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\nmodel_4<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_4_Bidirectional\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># input_7 (InputLayer)         [(None, 1)]               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># text_vectorization_1 (TextVe (None, 15)                0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># embedding (Embedding)        (None, 15, 128)           1280000   </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># bidirectional_1 (Bidirection (None, 128)               98816     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_6 (Dense)              (None, 1)                 129       </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 1,378,945</span>\r\n<span class=\"token comment\"># Trainable params: 1,378,945</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_4_history <span class=\"token operator\">=</span> model_4<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences<span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"bidirectional_RNN\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210912-104904</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 17s 48ms/step - loss: 0.1045 - accuracy: 0.9711 - val_loss: 1.0078 - val_accuracy: 0.7756</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 7s 33ms/step - loss: 0.0539 - accuracy: 0.9778 - val_loss: 1.2574 - val_accuracy: 0.7717</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 7s 34ms/step - loss: 0.0475 - accuracy: 0.9777 - val_loss: 1.2968 - val_accuracy: 0.7756</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 7s 35ms/step - loss: 0.0400 - accuracy: 0.9806 - val_loss: 1.4944 - val_accuracy: 0.7690</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 7s 33ms/step - loss: 0.0372 - accuracy: 0.9818 - val_loss: 1.5423 - val_accuracy: 0.7756</span>\r\n\r\nmodel_4_pred_probs <span class=\"token operator\">=</span> model_4<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_4_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_4_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[1.6641915e-03],</span>\r\n<span class=\"token comment\">#         [8.5940766e-01],</span>\r\n<span class=\"token comment\">#         [9.9998564e-01],</span>\r\n<span class=\"token comment\">#         [1.6693383e-01],</span>\r\n<span class=\"token comment\">#         [1.4821673e-05],</span>\r\n<span class=\"token comment\">#         [9.9992836e-01],</span>\r\n<span class=\"token comment\">#         [7.8986180e-01],</span>\r\n<span class=\"token comment\">#         [9.9999452e-01],</span>\r\n<span class=\"token comment\">#         [9.9999142e-01],</span>\r\n<span class=\"token comment\">#         [9.9973786e-01]], dtype=float32))</span>\r\n\r\nmodel_4_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_4_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_4_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)></span>\r\n\r\nmodel_4_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_4_pred<span class=\"token punctuation\">)</span>\r\nmodel_4_results\r\n<span class=\"token comment\"># {'accuracy': 77.55905511811024,</span>\r\n<span class=\"token comment\">#  'precision': 0.776326889347514,</span>\r\n<span class=\"token comment\">#  'recall': 0.7755905511811023,</span>\r\n<span class=\"token comment\">#  'f1': 0.7740902496040959}</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_4_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([False, False, False, False])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> 이 경우도 성능이 그닥...</p>\n<hr>\n<ul>\n<li>CNN (convolutional neural network) for text</li>\n</ul>\n<p>Computer Vision에서와 Natural Language Processing 에서의 CNN의 큰 차이점<br>\n=> 데이터 shape : 이미지는 보통 2차원 (높이와 너비) / 텍스트 즉, sequence는 1차원 (문자열)<br>\n일반적인 CNN 구조로 분석하는 과정<br>\n입력 -> 토큰화 -> 임베딩 -> 계층 -> 출력</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">embedding_test <span class=\"token operator\">=</span> embedding<span class=\"token punctuation\">(</span>text_vectorizer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"this is a test sentence\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>embedding_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> embedding_test\r\n<span class=\"token comment\"># (tensorflow.python.framework.ops.EagerTensor,</span>\r\n<span class=\"token comment\">#  &lt;tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[[ 0.04252062, -0.02539751, -0.02426873, ...,  0.02397382,</span>\r\n<span class=\"token comment\">#            0.001921  , -0.04230837],</span>\r\n<span class=\"token comment\">#          [-0.00081541, -0.0518087 , -0.01305428, ..., -0.04206811,</span>\r\n<span class=\"token comment\">#           -0.0067993 ,  0.00641394],</span>\r\n<span class=\"token comment\">#          [ 0.0450912 , -0.00063127, -0.03917043, ..., -0.00462016,</span>\r\n<span class=\"token comment\">#            0.00657265, -0.05303364],</span>\r\n<span class=\"token comment\">#          ...,</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055],</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055],</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055]]], dtype=float32)>)</span>\r\n\r\nconv_1d <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv1D<span class=\"token punctuation\">(</span>filters <span class=\"token operator\">=</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span>\r\nconv_1d_output <span class=\"token operator\">=</span> conv_1d<span class=\"token punctuation\">(</span>embedding_test<span class=\"token punctuation\">)</span>\r\nmax_pool <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>GlobalMaxPool1D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nmax_pool_output <span class=\"token operator\">=</span> max_pool<span class=\"token punctuation\">(</span>conv_1d_output<span class=\"token punctuation\">)</span>\r\nembedding_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> conv_1d_output<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> max_pool_output<span class=\"token punctuation\">.</span>shape\r\n<span class=\"token comment\"># (TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))</span>\r\n\r\nembedding_test<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> conv_1d_output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> max_pool_output<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># (&lt;tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[[ 0.04252062, -0.02539751, -0.02426873, ...,  0.02397382,</span>\r\n<span class=\"token comment\">#            0.001921  , -0.04230837],</span>\r\n<span class=\"token comment\">#          [-0.00081541, -0.0518087 , -0.01305428, ..., -0.04206811,</span>\r\n<span class=\"token comment\">#           -0.0067993 ,  0.00641394],</span>\r\n<span class=\"token comment\">#          [ 0.0450912 , -0.00063127, -0.03917043, ..., -0.00462016,</span>\r\n<span class=\"token comment\">#            0.00657265, -0.05303364],</span>\r\n<span class=\"token comment\">#          ...,</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055],</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055],</span>\r\n<span class=\"token comment\">#          [ 0.00042643, -0.06319568,  0.02213277, ...,  0.02335543,</span>\r\n<span class=\"token comment\">#            0.00935763, -0.02332055]]], dtype=float32)>,</span>\r\n<span class=\"token comment\">#  &lt;tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[[0.00267857, 0.        , 0.01693252, 0.03482042, 0.        ,</span>\r\n<span class=\"token comment\">#           0.        , 0.        , 0.        , 0.0376947 , 0.        ,</span>\r\n<span class=\"token comment\">#           0.        , 0.        , 0.        , 0.01203379, 0.02839085,</span>\r\n<span class=\"token comment\">#           0.        , 0.        , 0.03415176, 0.04861318, 0.02150694,</span>\r\n<span class=\"token comment\">#           0.        , 0.04171642, 0.01254863, 0.        , 0.        ,</span>\r\n<span class=\"token comment\">#           0.04056332, 0.01060622, 0.        , 0.        , 0.05781285,</span>\r\n<span class=\"token comment\">#           0.        , 0.        ],</span>\r\n<span class=\"token comment\">#          [0.        , 0.0546919 , 0.        , 0.00716206, 0.03570403,</span>\r\n<span class=\"token comment\">#           0.03994653, 0.        , 0.        , 0.02648068, 0.        ,</span>\r\n<span class=\"token comment\">#           0.        , 0.        , 0.0768393 , 0.        , 0.05795742,</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\">#          0.04864911, 0.04532517, 0.02421129, 0.11344301, 0.        ,</span>\r\n<span class=\"token comment\">#          0.01024379, 0.00168121, 0.0768393 , 0.01203379, 0.05795742,</span>\r\n<span class=\"token comment\">#          0.01303112, 0.04229069, 0.07315857, 0.04861318, 0.02398032,</span>\r\n<span class=\"token comment\">#          0.01835689, 0.04171642, 0.02130709, 0.02824164, 0.04885374,</span>\r\n<span class=\"token comment\">#          0.06892696, 0.02053308, 0.02834856, 0.05791294, 0.05781285,</span>\r\n<span class=\"token comment\">#          0.01266707, 0.03704225]], dtype=float32)>)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h4 id=\"model-5--cnn-for-text\" style=\"position:relative;\">Model 5 : CNN for text<a href=\"#model-5--cnn-for-text\" aria-label=\"model 5  cnn for text permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> layers\r\n\r\ninputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span><span class=\"token string\">\"string\"</span><span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> text_vectorizer<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> embedding<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Conv1D<span class=\"token punctuation\">(</span>filters<span class=\"token operator\">=</span> <span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>GlobalMaxPooling1D<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\n\r\noutputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\r\nmodel_5 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token punctuation\">,</span> outputs<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"model_5_Conv1D\"</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel_5<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_5<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_5_Conv1D\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># input_9 (InputLayer)         [(None, 1)]               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># text_vectorization_1 (TextVe (None, 15)                0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># embedding (Embedding)        (None, 15, 128)           1280000   </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># conv1d_4 (Conv1D)            (None, 11, 32)            20512     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># global_max_pooling1d_2 (Glob (None, 32)                0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_7 (Dense)              (None, 1)                 33        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 1,300,545</span>\r\n<span class=\"token comment\"># Trainable params: 1,300,545</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_5_history <span class=\"token operator\">=</span> model_5<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences<span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"Conv!D\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/Conv!D/20210912-111031</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 7s 26ms/step - loss: 0.1317 - accuracy: 0.9609 - val_loss: 0.8793 - val_accuracy: 0.7703</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 6s 26ms/step - loss: 0.0760 - accuracy: 0.9708 - val_loss: 1.0154 - val_accuracy: 0.7690</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 5s 24ms/step - loss: 0.0603 - accuracy: 0.9772 - val_loss: 1.0964 - val_accuracy: 0.7664</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 5s 25ms/step - loss: 0.0548 - accuracy: 0.9774 - val_loss: 1.1559 - val_accuracy: 0.7703</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 5s 25ms/step - loss: 0.0500 - accuracy: 0.9790 - val_loss: 1.2066 - val_accuracy: 0.7559</span>\r\n\r\nmodel_5_pred_probs <span class=\"token operator\">=</span> model_5<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_5_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_5_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[3.0160478e-01],</span>\r\n<span class=\"token comment\">#         [8.4077436e-01],</span>\r\n<span class=\"token comment\">#         [9.9985731e-01],</span>\r\n<span class=\"token comment\">#         [6.2881947e-02],</span>\r\n<span class=\"token comment\">#         [2.7723851e-07],</span>\r\n<span class=\"token comment\">#         [9.9824810e-01],</span>\r\n<span class=\"token comment\">#         [9.8587906e-01],</span>\r\n<span class=\"token comment\">#         [9.9998528e-01],</span>\r\n<span class=\"token comment\">#         [9.9999940e-01],</span>\r\n<span class=\"token comment\">#         [9.3655288e-01]], dtype=float32))</span>\r\n\r\nmodel_5_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_5_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_5_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)></span>\r\n\r\nmodel_5_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_5_pred<span class=\"token punctuation\">)</span>\r\nmodel_5_results\r\n<span class=\"token comment\"># {'accuracy': 75.59055118110236,</span>\r\n<span class=\"token comment\">#  'precision': 0.7556483058194802,</span>\r\n<span class=\"token comment\">#  'recall': 0.7559055118110236,</span>\r\n<span class=\"token comment\">#  'f1': 0.7548850741589771}</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_5_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([False, False, False, False])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h4 id=\"전이학습\" style=\"position:relative;\">전이학습<a href=\"#%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5\" aria-label=\"전이학습 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Pretrained (사전에 학습된) 모델을 사용하는 방법 (Transfer Learning)</li>\n</ul>\n<p>Model 0 ~ 5 : 우리가 직접 계층을 만들고 학습을 시켰습니다.<br>\n이제 Transfer Learning을 하려고 합니다 : 남들이 잘 만들어 놓은 딥러닝 모델을 사용할 수 있다!<br>\n어떤 특정한 패턴을 잘 찾는 모델을 사용해서 우리의 패턴을 찾도록 우리의 데이터셋을 적용해 보는 것!</p>\n<ul>\n<li>\n<p><a href=\"https://tfhub.dev/\">https://tfhub.dev/</a></p>\n</li>\n<li>\n<p><a href=\"https://tfhub.dev/google/universal-sentence-encoder/4\">https://tfhub.dev/google/universal-sentence-encoder/4</a></p>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">!pip install tensorflow_hub\r\n\r\n<span class=\"token keyword\">import</span> tensorflow_hub <span class=\"token keyword\">as</span> hub\r\n\r\nembed <span class=\"token operator\">=</span> hub<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://tfhub.dev/google/universal-sentence-encoder/4\"</span><span class=\"token punctuation\">)</span>\r\n\r\nembed_samples <span class=\"token operator\">=</span> embed<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\r\n    sample_sentence<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"I love tensorflow\"</span>\r\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>embed_samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> embed_samples<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> embed_samples\r\n<span class=\"token comment\"># (tensorflow.python.framework.ops.EagerTensor,</span>\r\n<span class=\"token comment\">#  TensorShape([2, 512]),</span>\r\n<span class=\"token comment\">#  &lt;tf.Tensor: shape=(2, 512), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[ 0.02870051, -0.08200636,  0.00167592, ...,  0.08094522,</span>\r\n<span class=\"token comment\">#          -0.03057687, -0.07465769],</span>\r\n<span class=\"token comment\">#         [ 0.05399963, -0.06587098, -0.0325466 , ...,  0.07745957,</span>\r\n<span class=\"token comment\">#          -0.03356914, -0.07428339]], dtype=float32)>)</span>\r\n\r\nembed_samples<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(512,), dtype=float32, numpy=</span>\r\n<span class=\"token comment\"># array([ 2.87005138e-02, -8.20063576e-02,  1.67591951e-03, -6.29723743e-02,</span>\r\n<span class=\"token comment\">#        -5.94823249e-03, -6.60873652e-02, -1.49239087e-02, -8.33780039e-03,</span>\r\n<span class=\"token comment\">#        -1.61214557e-03,  5.89855537e-02, -8.23733769e-03,  6.82732984e-02,</span>\r\n<span class=\"token comment\">#         4.32460010e-02,  7.28044361e-02, -8.85271188e-03,  8.36922377e-02,</span>\r\n<span class=\"token comment\">#        -3.29507217e-02, -6.93115219e-02,  1.36621920e-02, -7.07764179e-02,</span>\r\n<span class=\"token comment\">#         1.26073183e-02, -1.29402680e-02,  1.71631072e-02,  6.34478405e-02,</span>\r\n<span class=\"token comment\">#         2.51658205e-02,  6.55161068e-02,  3.75401322e-03,  5.42810187e-03,</span>\r\n<span class=\"token comment\">#        -4.23406325e-02, -9.79195070e-03, -2.03657988e-02, -9.50593781e-03,</span>\r\n<span class=\"token comment\">#        -2.82775331e-02,  4.20983285e-02, -6.17572293e-02, -3.33484672e-02,</span>\r\n<span class=\"token comment\">#         2.01067850e-02, -3.91414873e-02,  3.26501438e-03,  6.12112656e-02,</span>\r\n<span class=\"token comment\">#         4.58306074e-02,  7.03842491e-02,  1.22698788e-02,  6.15011156e-02,</span>\r\n<span class=\"token comment\">#         7.46965408e-02,  5.17273694e-02, -7.19774142e-02,  2.00994499e-02,</span>\r\n<span class=\"token comment\">#         3.15649360e-02,  6.94024861e-02, -5.54270335e-02,  2.68307906e-02,</span>\r\n<span class=\"token comment\">#         1.79841630e-02,  2.33209189e-02, -6.31777272e-02, -7.28214830e-02,</span>\r\n<span class=\"token comment\">#         8.14229343e-03,  6.53353110e-02,  5.37140621e-03, -1.79564487e-03,</span>\r\n<span class=\"token comment\">#        -7.94499964e-02, -2.31544375e-02,  3.11290231e-02,  5.21864519e-02,</span>\r\n<span class=\"token comment\">#        -1.67474188e-02, -6.44604564e-02, -5.32154180e-02,  6.31395578e-02,</span>\r\n<span class=\"token comment\">#        -7.42241815e-02,  3.82056274e-02, -3.45411785e-02, -5.27812541e-02,</span>\r\n<span class=\"token comment\">#        -5.40169477e-02,  9.57573205e-03,  3.78779359e-02, -2.87087131e-02,</span>\r\n<span class=\"token comment\">#         1.66132860e-02,  7.31827319e-02,  7.48905689e-02,  6.62557259e-02,</span>\r\n<span class=\"token comment\">#        -6.80465177e-02, -4.89107817e-02, -3.98343801e-03,  3.67775336e-02,</span>\r\n<span class=\"token comment\">#         2.17164606e-02, -2.72174701e-02, -3.91182676e-02, -7.55342841e-02,</span>\r\n<span class=\"token comment\">#         5.83799779e-02, -5.59141161e-03, -3.38194482e-02, -1.19012250e-02,</span>\r\n<span class=\"token comment\">#         2.60011069e-02,  6.86209798e-02, -1.82106066e-02,  6.15679994e-02,</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\">#        -3.81032377e-02,  5.23234494e-02,  4.81504053e-02, -5.08250622e-03,</span>\r\n<span class=\"token comment\">#        -2.98013650e-02, -3.96329304e-03,  2.27974430e-02, -1.86423156e-02,</span>\r\n<span class=\"token comment\">#         1.73301157e-02,  5.39917126e-02, -4.51219566e-02,  4.03046682e-02,</span>\r\n<span class=\"token comment\">#        -5.14215678e-02,  5.43060130e-04, -1.16383275e-02, -4.99991067e-02,</span>\r\n<span class=\"token comment\">#        -2.13429593e-02,  8.09452161e-02, -3.05768680e-02, -7.46576935e-02],</span>\r\n<span class=\"token comment\">#       dtype=float32)></span>\r\n\r\nembed_samples<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(512,), dtype=float32, numpy=</span>\r\n<span class=\"token comment\"># array([ 0.05399963, -0.06587098, -0.0325466 , -0.05942421,  0.00796421,</span>\r\n<span class=\"token comment\">#        -0.06761236, -0.06450988, -0.00275826,  0.00963328,  0.07514845,</span>\r\n<span class=\"token comment\">#        -0.01024037,  0.05769585,  0.04131395,  0.07075669, -0.02744581,</span>\r\n<span class=\"token comment\">#         0.08019906, -0.00697868, -0.06508593, -0.0198644 , -0.05492524,</span>\r\n<span class=\"token comment\">#        -0.0015816 , -0.00790866,  0.04948949,  0.05202747,  0.05732505,</span>\r\n<span class=\"token comment\">#         0.07194926, -0.0433432 , -0.02204051, -0.04422427, -0.02802072,</span>\r\n<span class=\"token comment\">#         0.02626313, -0.01090786, -0.00098569,  0.00480488, -0.05516029,</span>\r\n<span class=\"token comment\">#        -0.04715879, -0.010956  , -0.03169326, -0.01418679,  0.04703688,</span>\r\n<span class=\"token comment\">#         0.0453217 ,  0.0646871 , -0.02817039,  0.02899569,  0.03581711,</span>\r\n<span class=\"token comment\">#         0.07334174, -0.06419893, -0.01024343,  0.06866936,  0.06951907,</span>\r\n<span class=\"token comment\">#        -0.06022416, -0.06350277, -0.01747772,  0.02848996, -0.06284875,</span>\r\n<span class=\"token comment\">#        -0.06632752,  0.02705294,  0.072338  ,  0.02619733,  0.00573052,</span>\r\n<span class=\"token comment\">#        -0.07897921, -0.03160058, -0.02693138,  0.04681822, -0.01862349,</span>\r\n<span class=\"token comment\">#         0.0026347 , -0.0615541 ,  0.05306088, -0.06506991,  0.03198497,</span>\r\n<span class=\"token comment\">#        -0.02506078, -0.04198156, -0.04990286,  0.04860829,  0.02608881,</span>\r\n<span class=\"token comment\">#        -0.03703955,  0.03899394,  0.06830153,  0.06992087,  0.06215985,</span>\r\n<span class=\"token comment\">#        -0.05676541, -0.02824923,  0.02718087,  0.02843787,  0.0080534 ,</span>\r\n<span class=\"token comment\">#         0.00514479, -0.02757844, -0.07203252,  0.04293729, -0.03302658,</span>\r\n<span class=\"token comment\">#        -0.04201087,  0.00627254,  0.00981415,  0.07647101, -0.04189033,</span>\r\n<span class=\"token comment\">#         0.03871723, -0.02481958,  0.02504495,  0.05058041, -0.0559503 ,</span>\r\n<span class=\"token comment\">#         0.04541543, -0.01264421, -0.00061642,  0.07493637,  0.0083749 ,</span>\r\n<span class=\"token comment\">#        -0.00631488, -0.00381612,  0.0087955 , -0.04895919, -0.01810147,</span>\r\n<span class=\"token comment\">#        -0.00563374, -0.01942711, -0.06643606, -0.01375432, -0.0424421 ,</span>\r\n<span class=\"token comment\">#        -0.031002  , -0.01434745, -0.00065674, -0.01838248,  0.04257468,</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\">#         0.06106788, -0.02926045,  0.0542987 ,  0.06052127, -0.05219182,</span>\r\n<span class=\"token comment\">#        -0.01690841,  0.07398193, -0.03742874,  0.03452309,  0.05847615,</span>\r\n<span class=\"token comment\">#        -0.00386532, -0.0130894 ,  0.01076577,  0.0173107 ,  0.00526984,</span>\r\n<span class=\"token comment\">#        -0.0067213 ,  0.05337993,  0.01132939,  0.05092739, -0.03460051,</span>\r\n<span class=\"token comment\">#         0.05583626,  0.00213644, -0.04915178, -0.01201128,  0.07745957,</span>\r\n<span class=\"token comment\">#        -0.03356914, -0.07428339], dtype=float32)></span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<h4 id=\"model-6\" style=\"position:relative;\">Model 6<a href=\"#model-6\" aria-label=\"model 6 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">sentence_encoder_layer <span class=\"token operator\">=</span> hub<span class=\"token punctuation\">.</span>KerasLayer<span class=\"token punctuation\">(</span>\r\n    <span class=\"token string\">\"https://tfhub.dev/google/universal-sentence-encoder/4\"</span><span class=\"token punctuation\">,</span>\r\n    input_shape <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\r\n    dtype <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>string<span class=\"token punctuation\">,</span>\r\n    trainable <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\r\n    name <span class=\"token operator\">=</span> <span class=\"token string\">\"USE\"</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_6 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\r\n    sentence_encoder_layer<span class=\"token punctuation\">,</span>\r\n    layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"sigmoid\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\nmodel_6<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_6<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_2\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># USE (KerasLayer)             (None, 512)               256797824</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_12 (Dense)             (None, 64)                32832     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_13 (Dense)             (None, 1)                 65        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 256,830,721</span>\r\n<span class=\"token comment\"># Trainable params: 32,897</span>\r\n<span class=\"token comment\"># Non-trainable params: 256,797,824</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_6_history <span class=\"token operator\">=</span> model_6<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences<span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"tf_hub_sentence_encoder\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210912-141527</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 4s 20ms/step - loss: 0.3790 - accuracy: 0.8340 - val_loss: 0.4280 - val_accuracy: 0.8097</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 4s 17ms/step - loss: 0.3728 - accuracy: 0.8345 - val_loss: 0.4244 - val_accuracy: 0.8176</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 3s 15ms/step - loss: 0.3688 - accuracy: 0.8361 - val_loss: 0.4209 - val_accuracy: 0.8176</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 3s 14ms/step - loss: 0.3604 - accuracy: 0.8422 - val_loss: 0.4234 - val_accuracy: 0.8241</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 215/215 [==============================] - 3s 14ms/step - loss: 0.3544 - accuracy: 0.8437 - val_loss: 0.4273 - val_accuracy: 0.8215</span>\r\n\r\nplot_loss_curves<span class=\"token punctuation\">(</span>model_6_history<span class=\"token punctuation\">)</span>\r\n\r\nmodel_6_pred_probs <span class=\"token operator\">=</span> model_6<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_6_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_6_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[0.1458481 ],</span>\r\n<span class=\"token comment\">#         [0.7300363 ],</span>\r\n<span class=\"token comment\">#         [0.9963089 ],</span>\r\n<span class=\"token comment\">#         [0.21826577],</span>\r\n<span class=\"token comment\">#         [0.72229815],</span>\r\n<span class=\"token comment\">#         [0.72220576],</span>\r\n<span class=\"token comment\">#         [0.9877683 ],</span>\r\n<span class=\"token comment\">#         [0.990924  ],</span>\r\n<span class=\"token comment\">#         [0.95667434],</span>\r\n<span class=\"token comment\">#         [0.07586008]], dtype=float32))</span>\r\n\r\nmodel_6_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_6_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_6_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)></span>\r\n\r\nmodel_6_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_6_pred<span class=\"token punctuation\">)</span>\r\nmodel_6_results\r\n<span class=\"token comment\"># {'accuracy': 82.1522309711286,</span>\r\n <span class=\"token comment\"># 'precision': 0.8256048451547083,</span>\r\n <span class=\"token comment\"># 'recall': 0.821522309711286,</span>\r\n <span class=\"token comment\"># 'f1': 0.8195898931605882}</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_6_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([ True,  True,  True,  True])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> 갖다 썼는데 더 좋아진 모습...</p>\n<hr>\n<p>데이터 10%로만 한다면...?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># 10% of dataset</span>\r\n\r\ntrain_sentences_90_percent<span class=\"token punctuation\">,</span> train_sentences_10_percent<span class=\"token punctuation\">,</span> train_labels_90_percent<span class=\"token punctuation\">,</span> train_labels_10_percent <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>\r\n    np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>train_sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    train_labels<span class=\"token punctuation\">,</span>\r\n    test_size <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>\r\n    random_state <span class=\"token operator\">=</span> <span class=\"token number\">42</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"전체 학습 데이터량 : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"전체 학습 데이터의 10% : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_sentences_10_percent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 전체 학습 데이터량 : 6851</span>\r\n<span class=\"token comment\"># 전체 학습 데이터의 10% : 686</span>\r\n\r\npd<span class=\"token punctuation\">.</span>Series<span class=\"token punctuation\">(</span>train_labels_10_percent<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 0    415</span>\r\n<span class=\"token comment\"># 1    271</span>\r\n<span class=\"token comment\"># dtype: int64</span>\r\n\r\nmodel_7 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>clone_model<span class=\"token punctuation\">(</span>model_6<span class=\"token punctuation\">)</span>\r\n\r\nmodel_7<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_7<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_2\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># USE (KerasLayer)             (None, 512)               256797824</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_12 (Dense)             (None, 64)                32832     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_13 (Dense)             (None, 1)                 65        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 256,830,721</span>\r\n<span class=\"token comment\"># Trainable params: 32,897</span>\r\n<span class=\"token comment\"># Non-trainable params: 256,797,824</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nmodel_7_history <span class=\"token operator\">=</span> model_7<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_sentences_10_percent<span class=\"token punctuation\">,</span>\r\n    train_labels_10_percent<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    callbacks <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\r\n        create_tensorboard_callback<span class=\"token punctuation\">(</span>\r\n            dir_name <span class=\"token operator\">=</span> SAVE_DIR<span class=\"token punctuation\">,</span>\r\n            experiment_name <span class=\"token operator\">=</span> <span class=\"token string\">\"10_percent_tf_hub_sentence_encoder\"</span>\r\n        <span class=\"token punctuation\">)</span>\r\n    <span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210912-145348</span>\r\n<span class=\"token comment\"># Epoch 1/5</span>\r\n<span class=\"token comment\"># 22/22 [==============================] - 17s 597ms/step - loss: 0.6637 - accuracy: 0.7026 - val_loss: 0.6416 - val_accuracy: 0.6955</span>\r\n<span class=\"token comment\"># Epoch 2/5</span>\r\n<span class=\"token comment\"># 22/22 [==============================] - 1s 38ms/step - loss: 0.5854 - accuracy: 0.8061 - val_loss: 0.5854 - val_accuracy: 0.7349</span>\r\n<span class=\"token comment\"># Epoch 3/5</span>\r\n<span class=\"token comment\"># 22/22 [==============================] - 1s 25ms/step - loss: 0.5086 - accuracy: 0.8222 - val_loss: 0.5326 - val_accuracy: 0.7598</span>\r\n<span class=\"token comment\"># Epoch 4/5</span>\r\n<span class=\"token comment\"># 22/22 [==============================] - 1s 25ms/step - loss: 0.4477 - accuracy: 0.8324 - val_loss: 0.5051 - val_accuracy: 0.7717</span>\r\n<span class=\"token comment\"># Epoch 5/5</span>\r\n<span class=\"token comment\"># 22/22 [==============================] - 1s 24ms/step - loss: 0.4043 - accuracy: 0.8367 - val_loss: 0.4894 - val_accuracy: 0.7835</span>\r\n\r\nmodel_7_pred_probs <span class=\"token operator\">=</span> model_7<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_7_pred_probs<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> model_7_pred_probs<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># ((762, 1),</span>\r\n<span class=\"token comment\">#  array([[0.2374287 ],</span>\r\n<span class=\"token comment\">#         [0.77781403],</span>\r\n<span class=\"token comment\">#         [0.9037036 ],</span>\r\n<span class=\"token comment\">#         [0.29900986],</span>\r\n<span class=\"token comment\">#         [0.53128344],</span>\r\n<span class=\"token comment\">#         [0.8304577 ],</span>\r\n<span class=\"token comment\">#         [0.8438761 ],</span>\r\n<span class=\"token comment\">#         [0.8459203 ],</span>\r\n<span class=\"token comment\">#         [0.83397806],</span>\r\n<span class=\"token comment\">#         [0.11899915]], dtype=float32))</span>\r\n\r\nmodel_7_pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_7_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel_7_pred<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)></span>\r\n\r\nmodel_7_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>y_true <span class=\"token operator\">=</span> val_labels<span class=\"token punctuation\">,</span> y_pred <span class=\"token operator\">=</span> model_7_pred<span class=\"token punctuation\">)</span>\r\nmodel_7_results\r\n<span class=\"token comment\"># {'accuracy': 78.34645669291339,</span>\r\n<span class=\"token comment\">#  'precision': 0.7868445599717488,</span>\r\n<span class=\"token comment\">#  'recall': 0.7834645669291339,</span>\r\n<span class=\"token comment\">#  'f1': 0.7809185675137833}</span>\r\nnp<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>model_7_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>baseline_results<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># array([False, False, False, False])</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>모델을 비교해 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">all_model_results <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\r\n    <span class=\"token string\">\"baseline\"</span> <span class=\"token punctuation\">:</span> baseline_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"simple_dense\"</span> <span class=\"token punctuation\">:</span> model_1_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"lstm\"</span> <span class=\"token punctuation\">:</span> model_2_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"gru\"</span> <span class=\"token punctuation\">:</span> model_3_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"bidirectional\"</span> <span class=\"token punctuation\">:</span> model_4_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"conv1d\"</span> <span class=\"token punctuation\">:</span> model_5_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"tf_hub_sentences_encoder\"</span> <span class=\"token punctuation\">:</span> model_6_results<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"tf_hub_10_percent_data\"</span> <span class=\"token punctuation\">:</span> model_7_results\r\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\r\nall_model_results <span class=\"token operator\">=</span> all_model_results<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nall_model_results<span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_model_results<span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> <span class=\"token number\">100</span>\r\n\r\nall_model_results\r\n<span class=\"token comment\"># accuracy\tprecision\trecall\tf1</span>\r\n<span class=\"token comment\"># baseline\t0.792651\t0.811139\t0.792651\t0.786219</span>\r\n<span class=\"token comment\"># simple_dense\t0.790026\t0.796983\t0.790026\t0.786470</span>\r\n<span class=\"token comment\"># lstm\t0.784777\t0.786239\t0.784777\t0.783061</span>\r\n<span class=\"token comment\"># gru\t0.783465\t0.786845\t0.783465\t0.780919</span>\r\n<span class=\"token comment\"># bidirectional\t0.766404\t0.766590\t0.766404\t0.765121</span>\r\n<span class=\"token comment\"># conv1d\t0.769029\t0.769124\t0.769029\t0.767865</span>\r\n<span class=\"token comment\"># tf_hub_sentences_encoder\t0.809711\t0.809659\t0.809711\t0.809175</span>\r\n<span class=\"token comment\"># tf_hub_10_percent_data\t0.775591\t0.779799\t0.775591\t0.772511</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>앙상블 해 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">all_model_results<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>kind<span class=\"token operator\">=</span><span class=\"token string\">\"bar\"</span><span class=\"token punctuation\">,</span> figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">7</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>bbox_to_anchor<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nall_model_results<span class=\"token punctuation\">.</span>sort_values<span class=\"token punctuation\">(</span><span class=\"token string\">\"f1\"</span><span class=\"token punctuation\">,</span> ascending<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"f1\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>kind<span class=\"token operator\">=</span><span class=\"token string\">\"bar\"</span><span class=\"token punctuation\">,</span> figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nbaseline_pred_probs <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>model_0<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\ncombined_pred_probs <span class=\"token operator\">=</span> baseline_pred_probs <span class=\"token operator\">+</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>model_2_pred_probs<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>model_6_pred_probs<span class=\"token punctuation\">)</span>\r\ncombined_preds <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>combined_pred_probs <span class=\"token operator\">/</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\r\ncombined_preds<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">20</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(20,), dtype=float32, numpy=</span>\r\n<span class=\"token comment\"># array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,</span>\r\n<span class=\"token comment\">#        0., 0., 1.], dtype=float32)></span>\r\n\r\nensenble_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>val_labels<span class=\"token punctuation\">,</span> combined_preds<span class=\"token punctuation\">)</span>\r\nensenble_results\r\n<span class=\"token comment\"># {'accuracy': 79.65879265091863,</span>\r\n<span class=\"token comment\">#  'precision': 0.7967460225061236,</span>\r\n<span class=\"token comment\">#  'recall': 0.7965879265091863,</span>\r\n<span class=\"token comment\">#  'f1': 0.7966545929710407}</span>\r\n\r\nall_model_results<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"ensemble_results\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> ensemble_results\r\nall_model_results<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"ensemble_results\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> ensemble_results\r\nall_model_results<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"ensemble_results\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> all_model_results<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span><span class=\"token string\">\"ensemble_results\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> <span class=\"token number\">100</span>\r\n\r\nall_model_results\r\n<span class=\"token comment\"># accuracy\tprecision\trecall\tf1</span>\r\n<span class=\"token comment\"># baseline\t0.792651\t0.811139\t0.792651\t0.786219</span>\r\n<span class=\"token comment\"># simple_dense\t0.790026\t0.796983\t0.790026\t0.786470</span>\r\n<span class=\"token comment\"># lstm\t0.784777\t0.786239\t0.784777\t0.783061</span>\r\n<span class=\"token comment\"># gru\t0.783465\t0.786845\t0.783465\t0.780919</span>\r\n<span class=\"token comment\"># bidirectional\t0.766404\t0.766590\t0.766404\t0.765121</span>\r\n<span class=\"token comment\"># conv1d\t0.769029\t0.769124\t0.769029\t0.767865</span>\r\n<span class=\"token comment\"># tf_hub_sentences_encoder\t0.809711\t0.809659\t0.809711\t0.809175</span>\r\n<span class=\"token comment\"># tf_hub_10_percent_data\t0.775591\t0.779799\t0.775591\t0.772511</span>\r\n<span class=\"token comment\"># ensemble_results\t0.796588\t0.796746\t0.796588\t0.796655</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>가장 우수한 성능을 보인 model 6을 저장한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">model_6<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"model_6.h5\"</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<hr>\n<ul>\n<li>\n<p><a href=\"https://www.tensorflow.org/tutorials/keras/save_and_load\">https://www.tensorflow.org/tutorials/keras/save_and_load</a></p>\n</li>\n<li>\n<p><a href=\"https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model\">https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model</a></p>\n</li>\n<li>\n<p>tensorlfow_nlp3.ipynb</p>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\">## tensorflow_nl3.ipynb</span>\r\n<span class=\"token comment\">## SaveModel (default) or HDF5</span>\r\n<span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\r\n<span class=\"token keyword\">import</span> tensorflow_hub <span class=\"token keyword\">as</span> hub\r\nloaded_model_6 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>load_model<span class=\"token punctuation\">(</span>\r\n    <span class=\"token string\">\"model_6.h5\"</span><span class=\"token punctuation\">,</span>\r\n    custom_objects <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\r\n        <span class=\"token string\">\"KerasLayer\"</span> <span class=\"token punctuation\">:</span> hub<span class=\"token punctuation\">.</span>KerasLayer\r\n    <span class=\"token punctuation\">}</span>\r\n<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<ul>\n<li><a href=\"https://twitter.com/BeirutCityGuide/status/1290773498743476224\">https://twitter.com/BeirutCityGuide/status/1290773498743476224</a></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\r\n\r\ntrain_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"train.csv\"</span><span class=\"token punctuation\">)</span>\r\ntest_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"test.csv\"</span><span class=\"token punctuation\">)</span>\r\n\r\ntrain_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> train_df<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> test_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> test_df<span class=\"token punctuation\">.</span>shape\r\ntrain_df_shuffled <span class=\"token operator\">=</span> train_df<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span>frac <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span>\r\ntrain_df_shuffled<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> train_df_shuffled<span class=\"token punctuation\">.</span>shape\r\n<span class=\"token comment\"># (        id      keyword               location  \\</span>\r\n<span class=\"token comment\">#  2644  3796  destruction                    NaN   </span>\r\n<span class=\"token comment\">#  2227  3185       deluge                    NaN   </span>\r\n<span class=\"token comment\">#  5448  7769       police                     UK   </span>\r\n<span class=\"token comment\">#  132    191   aftershock                    NaN   </span>\r\n<span class=\"token comment\">#  6845  9810       trauma  Montgomery County, MD   </span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\">#                                                     text  target  </span>\r\n<span class=\"token comment\">#  2644  So you have a new weapon that can cause un-ima...       1  </span>\r\n<span class=\"token comment\">#  2227  The f$&amp;amp;@ing things I do for #GISHWHES Just...       0  </span>\r\n<span class=\"token comment\">#  5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  </span>\r\n<span class=\"token comment\">#  132   Aftershock back to school kick off was great. ...       0  </span>\r\n<span class=\"token comment\">#  6845  in response to trauma Children of Addicts deve...       0  ,</span>\r\n<span class=\"token comment\">#  (7613, 5))</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"총 학습할 데이터의 수 : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"총 테스트할 데이터의 수 : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"총 데이터의 수 : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_df<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>test_df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 총 학습할 데이터의 수 : 7613</span>\r\n<span class=\"token comment\"># 총 테스트할 데이터의 수 : 3263</span>\r\n<span class=\"token comment\"># 총 데이터의 수 : 10876</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\r\n\r\ntrain_sentences<span class=\"token punctuation\">,</span> val_sentences<span class=\"token punctuation\">,</span> train_labels<span class=\"token punctuation\">,</span> val_labels <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>\r\n    train_df_shuffled<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    train_df_shuffled<span class=\"token punctuation\">[</span><span class=\"token string\">\"target\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    test_size <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span>\r\n    random_state<span class=\"token operator\">=</span> <span class=\"token number\">42</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>val_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># (6851, 6851, 762, 762)</span>\r\n\r\nloaded_model_6<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 24/24 [==============================] - 1s 14ms/step - loss: 0.4288 - accuracy: 0.8097</span>\r\n<span class=\"token comment\"># [0.4287616014480591, 0.8097112774848938]</span>\r\n\r\nloaded_model_6<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"model_6_SaveModel_format\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.</span>\r\n<span class=\"token comment\"># INFO:tensorflow:Assets written to: model_6_SaveModel_format\\assets</span>\r\n<span class=\"token comment\"># INFO:tensorflow:Assets written to: model_6_SaveModel_format\\assets</span>\r\n\r\nloaded_model_6_SaveModel <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>load_model<span class=\"token punctuation\">(</span><span class=\"token string\">\"model_6_SaveModel_format\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 24/24 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.8097</span>\r\n<span class=\"token comment\"># [0.4287616014480591, 0.8097112774848938]</span>\r\n\r\nloaded_model_6_SaveModel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_labels<span class=\"token punctuation\">)</span>\r\nmodel_6_pred_probs <span class=\"token operator\">=</span> loaded_model_6_SaveModel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">)</span>\r\nmodel_6_preds <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>model_6_pred_probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nval_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\r\n    <span class=\"token string\">\"text\"</span><span class=\"token punctuation\">:</span> val_sentences<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"target\"</span><span class=\"token punctuation\">:</span> val_labels<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"pred\"</span><span class=\"token punctuation\">:</span> model_6_preds<span class=\"token punctuation\">,</span>\r\n    <span class=\"token string\">\"pred_prob\"</span><span class=\"token punctuation\">:</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>model_6_pred_probs<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\r\nval_df\r\n<span class=\"token comment\"># text\ttarget\tpred\tpred_prob</span>\r\n<span class=\"token comment\"># 0\tDFR EP016 Monthly Meltdown - On Dnbheaven 2015...\t0\ttf.Tensor(0.0, shape=(), dtype=float32)\ttf.Tensor(0.21790454, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 1\tFedEx no longer to transport bioterror germs i...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.84315586, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 2\tGunmen kill four in El Salvador bus attack: Su...\t1\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.98890066, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 3\t@camilacabello97 Internally and externally scr...\t1\ttf.Tensor(0.0, shape=(), dtype=float32)\ttf.Tensor(0.21680078, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 4\tRadiation emergency #preparedness starts with ...\t1\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.7819313, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># ...\t...\t...\t...\t...</span>\r\n<span class=\"token comment\"># 757\tThat's the ultimate road to destruction\t0\ttf.Tensor(0.0, shape=(), dtype=float32)\ttf.Tensor(0.1251579, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 758\t@SetZorah dad why dont you claim me that mean ...\t0\ttf.Tensor(0.0, shape=(), dtype=float32)\ttf.Tensor(0.11191952, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 759\tFedEx will no longer transport bioterror patho...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.928153, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 760\tCrack in the path where I wiped out this morni...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.7186363, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 761\tI liked a @YouTube video from @dannyonpc http:...\t0\ttf.Tensor(0.0, shape=(), dtype=float32)\ttf.Tensor(0.10052046, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 762 rows × 4 columns</span>\r\n\r\nmost_wrong <span class=\"token operator\">=</span> val_df<span class=\"token punctuation\">[</span>val_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"target\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> val_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"pred\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>sort_values<span class=\"token punctuation\">(</span><span class=\"token string\">\"pred_prob\"</span><span class=\"token punctuation\">,</span> ascending <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\r\nmost_wrong<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># text\ttarget\tpred\tpred_prob</span>\r\n<span class=\"token comment\"># 31\t? High Skies - Burning Buildings ? http://t.co...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.9460672, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 759\tFedEx will no longer transport bioterror patho...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.928153, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 628\t@noah_anyname That's where the concentration c...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.8867433, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 49\t@madonnamking RSPCA site multiple 7 story high...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.8756112, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 393\t@SonofLiberty357 all illuminated by the bright...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.86915684, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 698\tåÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.86670816, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 109\t[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.8561237, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 209\tAshes 2015: AustraliaÛªs collapse at Trent Br...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.85130084, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 144\tThe Sound of Arson\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.84451985, shape=(), dtype=float32)</span>\r\n<span class=\"token comment\"># 1\tFedEx no longer to transport bioterror germs i...\t0\ttf.Tensor(1.0, shape=(), dtype=float32)\ttf.Tensor(0.84315586, shape=(), dtype=float32)</span>\r\n\r\n<span class=\"token comment\"># false positive 확인</span>\r\n<span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> most_wrong<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">10</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>itertuples<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    _<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">,</span> prob <span class=\"token operator\">=</span> row\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Target : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>target<span class=\"token punctuation\">}</span></span><span class=\"token string\">, Pred: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, Prob: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prob<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Text:\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>text<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"----\\n\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Target : 0, Pred: 1, Prob: 0.946067214012146</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># ? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 0, Pred: 1, Prob: 0.9281529784202576</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 0, Pred: 1, Prob: 0.8867433071136475</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># @noah_anyname That's where the concentration camps and mass murder come in.</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># EVERY. FUCKING. TIME.</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 0, Pred: 1, Prob: 0.8756111860275269</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># @madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n\r\n\r\n\r\n<span class=\"token comment\"># false negative 확인</span>\r\n<span class=\"token keyword\">for</span> row <span class=\"token keyword\">in</span> most_wrong<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">10</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>itertuples<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    _<span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">,</span> pred<span class=\"token punctuation\">,</span> prob <span class=\"token operator\">=</span> row\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Target : </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>target<span class=\"token punctuation\">}</span></span><span class=\"token string\">, Pred: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, Prob: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prob<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Text:\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>text<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"----\\n\"</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># Target : 1, Pred: 0, Prob: 0.06765037775039673</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 1, Pred: 0, Prob: 0.06651219725608826</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># 'The way you move is like a full on rainstorm and I'm a house of cards'</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 1, Pred: 0, Prob: 0.06409454345703125</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># going to redo my nails and watch behind the scenes of desolation of smaug ayyy</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 1, Pred: 0, Prob: 0.058147132396698</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Target : 1, Pred: 0, Prob: 0.05584031343460083</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Ron &amp;amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token operator\">-</span>\r\n</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> random\r\n\r\ntest_sentences <span class=\"token operator\">=</span> test_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_list<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\ntest_samples <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span>test_sentences<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">for</span> test_sample <span class=\"token keyword\">in</span> test_samples<span class=\"token punctuation\">:</span>\r\n    pred_prob <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>loaded_model_6_SaveModel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>test_sample<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n    pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>pred_prob<span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Pred: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>pred<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">, Prob: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred_prob<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Text: \\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>test_sample<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"----\\n\"</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Pred: 0, Prob: 0.3556998074054718</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Tumblr collective meltdown. #sebastianstanisaliveandwell #civilwar ?????? http://t.co/WOc1TeVVMP</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Pred: 1, Prob: 0.8391075730323792</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Who is Tomislav Salopek the Islamic State's Most Recent Hostage? http://t.co/puT3LgsDnf</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Pred: 0, Prob: 0.02966734766960144</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># So if you secretly have a crush on me and can sing lmk lmfao</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Pred: 1, Prob: 0.9253959655761719</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># 'When the aftershock happened (Nepal) we were the last int'l team still there; in a way we were 1st responders.' Chief Collins @LACo_FD</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Pred: 0, Prob: 0.05158120393753052</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Still wonder why they will do anything to have a life anywhere. Wars u support CAUSE refugees open boarders. #auspol https://t.co/3MjtE74AiW</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ----</span>\r\n\r\nmy_tweet <span class=\"token operator\">=</span> <span class=\"token string\">\"Life like an ensemble: take the best choices from others and make your own\"</span>\r\n<span class=\"token keyword\">def</span> <span class=\"token function\">predict_on_sentence</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> sentence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    pred_prob <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>sentence<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n    pred_label <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span><span class=\"token builtin\">round</span><span class=\"token punctuation\">(</span>pred_prob<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Pred: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred_label<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"부정\"</span> <span class=\"token keyword\">if</span> pred_label <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token keyword\">else</span> <span class=\"token string\">\"긍정\"</span><span class=\"token punctuation\">,</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"Prob: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>pred_prob<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Text: \\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>sentence<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\r\npredict_on_sentence<span class=\"token punctuation\">(</span>\r\n    model <span class=\"token operator\">=</span> loaded_model_6_SaveModel<span class=\"token punctuation\">,</span>\r\n    sentence <span class=\"token operator\">=</span> my_tweet\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Pred: 0.0 긍정 Prob: 0.052443891763687134</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Life like an ensemble: take the best choices from others and make your own</span>\r\n\r\nbad_news1 <span class=\"token operator\">=</span> <span class=\"token string\">\"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"</span>\r\nbad_news2 <span class=\"token operator\">=</span> <span class=\"token string\">\"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\"</span>\r\npredict_on_sentence<span class=\"token punctuation\">(</span>\r\n    model <span class=\"token operator\">=</span> loaded_model_6_SaveModel<span class=\"token punctuation\">,</span>\r\n    sentence <span class=\"token operator\">=</span> bad_news1\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Pred: 1.0 부정 Prob: 0.9783979654312134</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon</span>\r\n\r\npredict_on_sentence<span class=\"token punctuation\">(</span>\r\n    model <span class=\"token operator\">=</span> loaded_model_6_SaveModel<span class=\"token punctuation\">,</span>\r\n    sentence <span class=\"token operator\">=</span> bad_news2\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Pred: 1.0 부정 Prob: 0.9842044115066528</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># #Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon</span>\r\n\r\nmy_opinion <span class=\"token operator\">=</span> <span class=\"token string\">\"I my_opinion a baseball!\"</span>\r\npredict_on_sentence<span class=\"token punctuation\">(</span>\r\n    model <span class=\"token operator\">=</span> loaded_model_6_SaveModel<span class=\"token punctuation\">,</span>\r\n    sentence <span class=\"token operator\">=</span> my_opinion\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Pred: 0.0 긍정 Prob: 0.09839537739753723</span>\r\n<span class=\"token comment\"># Text:</span>\r\n<span class=\"token comment\"># I my_opinion a baseball!</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#16%EC%9D%BC%EC%B0%A8\">16일차</a></p>\n<ul>\n<li><a href=\"#model-2---lstm\">Model 2 - LSTM</a></li>\n<li><a href=\"#model_3--gru\">model_3 : GRU</a></li>\n<li><a href=\"#model-4--bidirectional-rnn\">Model 4 : Bidirectional RNN</a></li>\n<li><a href=\"#model-5--cnn-for-text\">Model 5 : CNN for text</a></li>\n<li><a href=\"#%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5\">전이학습</a></li>\n<li><a href=\"#model-6\">Model 6</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 3기 언어반 16일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-언어-16일차/"}},
    "staticQueryHashes": ["3159585216"]}