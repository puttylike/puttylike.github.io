{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-시각-심화-11일차/",
    "result": {"data":{"markdownRemark":{"html":"<p>이 강의는 TF 2.0 -> CNN -> Transfer Learning -> YOLO 순으로 넘어간다. 점차 문제점을 느껴 가면서.</p>\n<hr>\n<h3 id=\"11일차\" style=\"position:relative;\">11일차<a href=\"#11%EC%9D%BC%EC%B0%A8\" aria-label=\"11일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h5 id=\"복습\" style=\"position:relative;\">복습<a href=\"#%EB%B3%B5%EC%8A%B5\" aria-label=\"복습 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>컴퓨터 비전의 기본 아키텍트는 CNN이다.</p>\n<p>data definition 을 한다는 건 numpy를 한다는 건데,<br>\n그 전에 해야하는 data preprocess 작업이 70%는 된다.<br>\n그리고 그 이전에는 data gathering를 해야 하는데 이 또한 만만치 않다.</p>\n<p>test data를 valid로 활용해도 되긴 하다만,<br>\n학습 중 overfitting 확인 위해 validation data는 필요하다.</p>\n<h5 id=\"cats-and-dogs\" style=\"position:relative;\">cats and dogs<a href=\"#cats-and-dogs\" aria-label=\"cats and dogs permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>cf. <a href=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\">https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip</a></p>\n<p>raw data를 filtered하는데 오래 걸려서 filtered data를 사용한다.</p>\n<p>이번 예제는 이전과 다르게 이미지 크기가 정해져 있지 않다.<br>\npandas의 describe로 평균 사이즈를 알아낼 수 있다.</p>\n<p>train, valid data만 있어서 valid를 random shuffle이 필요하다.<br>\n<strong>딥러닝에서 data를 섞을 때는 index를 shuffle해야 한다.</strong></p>\n<p>model fit을 했다는 건 w, b를 구했다는 뜻이니,<br>\nadam 대신 다른 걸 쓴다고 치면 w, b 초기화부터 (model 생성) 다시 진행해야 한다.</p>\n<p>평균적인 size는 300대이지만, 224로 resize 했다.<br>\ntransfer learning 224x224x3 / 299x299x3이 default size라서 그렇다.<br>\n데이터 갯수가 3천 개로 적어 한계가 있었다.</p>\n<p>학습 전에 데이터와 label을 매칭하는 건 사람이 해야 하는 일..<br>\n랜덤 데이터로 검증하기 위해 predict하는데,</p>\n<ul>\n<li>데이터 수집 및 전처리를 자동화하는 건 어렵고, 프로세스를 하나 만드는 거 자체가 business model이 될 수 있다.</li>\n</ul>\n<p><del>파이썬 날코딩으로 알고 짜는 딥러닝</del></p>\n<hr>\n<h5 id=\"native-cnn-정확도-높이기\" style=\"position:relative;\">native CNN 정확도 높이기<a href=\"#native-cnn-%EC%A0%95%ED%99%95%EB%8F%84-%EB%86%92%EC%9D%B4%EA%B8%B0\" aria-label=\"native cnn 정확도 높이기 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<ol>\n<li>data가 많아야 하고, 다양성이 있어야 한다</li>\n</ol>\n<p>=> image data generator 방법이 있겠다.</p>\n<ol start=\"2\">\n<li>deep CNN 구조 (layer deep)</li>\n<li>learning rate를 낮춘다</li>\n</ol>\n<p>=> 나머지 2,3은 transfer learning이 최선이다. 아니면 image gathering</p>\n<ul>\n<li>data preprocess에서 제일 힘든 건 디렉토리랑 파일 정리이다</li>\n</ul>\n<hr>\n<h4 id=\"전이-학습\" style=\"position:relative;\">전이 학습<a href=\"#%EC%A0%84%EC%9D%B4-%ED%95%99%EC%8A%B5\" aria-label=\"전이 학습 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>cf. MRI 등 의료 영상 데이터 분석에 쓰이는 Unet은 U자형 구조로,<br>\nInception 처럼 중간중간 점프하는 구조이다.</p>\n<p>cf. 이미지 세그멘테이션 : 형상 분류</p>\n<h5 id=\"파인-튜닝\" style=\"position:relative;\">파인 튜닝<a href=\"#%ED%8C%8C%EC%9D%B8-%ED%8A%9C%EB%8B%9D\" aria-label=\"파인 튜닝 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>내 데이터에 맞게 미세하게 튜닝하는 걸 말한다. (fine : 미세한)</p>\n<p>정확도가 높다.</p>\n<p>include_top = False는 특징 추출기만 가져오고 (파인튜닝 없음),<br>\nTrue는 사용자 정의 분류기까지도 가져온다는 의미이다. (feature extractor + layers)</p>\n<p>VGG16은 이미 pre-trained된 것, 나머지 layer은 add한 것이라<br>\nfine tuning은 아주 조금씩 학습을 시키는 게 중요하다.<br>\n기존에 갖고 있는 게 (VGG) 있으니까.</p>\n<hr>\n<h5 id=\"pre-trained-model-사용하기\" style=\"position:relative;\">pre-trained model 사용하기<a href=\"#pre-trained-model-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\" aria-label=\"pre trained model 사용하기 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<ul>\n<li>decode_predictions 로 알아서 top 3 찾을 수 있다.</li>\n</ul>\n<p>cifar10에서 argsort로 top3 만든거랑 같다.</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#11%EC%9D%BC%EC%B0%A8\">11일차</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EB%B3%B5%EC%8A%B5\">복습</a></li>\n<li><a href=\"#cats-and-dogs\">cats and dogs</a></li>\n<li><a href=\"#native-cnn-%EC%A0%95%ED%99%95%EB%8F%84-%EB%86%92%EC%9D%B4%EA%B8%B0\">native CNN 정확도 높이기</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%EC%A0%84%EC%9D%B4-%ED%95%99%EC%8A%B5\">전이 학습</a></p>\n<ul>\n<li><a href=\"#%ED%8C%8C%EC%9D%B8-%ED%8A%9C%EB%8B%9D\">파인 튜닝</a></li>\n<li><a href=\"#pre-trained-model-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\">pre-trained model 사용하기</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 3기 심화 시각반 11일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-시각-심화-11일차/"}},
    "staticQueryHashes": ["3159585216"]}