{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-16일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"16일차\" style=\"position:relative;\">16일차<a href=\"#16%EC%9D%BC%EC%B0%A8\" aria-label=\"16일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>CNN에 진입했다. 예전에는 param 갯수 세는 거 이해 못 했는데, 이번엔 이해... 잘 하고 있는 듯. 코드만 익히면 될 거 같아 내심 기분이 좋다. RNN을 이 과정에서 못 배우는 게 아쉬워진다만 일단 CNN 열심히 배워야겠지 싶고. fully connected 부터는 다음주에 배운다.</li>\n<li>오차역전파를 다 흡수 못 했는지 순간적으로 ndmin=2 까먹었다. 역시 복습이 생명... ㅠㅠ</li>\n<li>이번 11월엔 if KAKAO도 있고, SDS Techtonic도 열리고, Naver Deview도 열린다. 코로나 때문에 11월이 난리다.<br>\n그나저나 인슈어테크 강연 언제 또 열리냐... 조언 좀 듣고 싶은데 막막하다.</li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Convolution 의미 ?  </li>\n<li>filter size만큼 weight 가 존재한다  </li>\n<li>필터 당 Bias 1개 필요하다  </li>\n<li>output channel은 filter 갯수랑 동일하다  </li>\n<li>channel 과 전체 data 를 헷갈리면 안 된다</li>\n</ul>\n<hr>\n<h4 id=\"은닉층\" style=\"position:relative;\">은닉층<a href=\"#%EC%9D%80%EB%8B%89%EC%B8%B5\" aria-label=\"은닉층 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>​\ncf. CNN을 tf 2. 버전 대에서 하면 코드가 함축적이라 내부를 알기 힘들어 이 수업에서는 1. 버전 대에서 수행한다.\n​</p>\n<p>(i) NN => CNN, RNN (LSTM, GRU, ...)<br>\n=> 은닉층 modify : 딥러닝 아키텍처가 바뀐다는 건 은닉층 구조가 바뀐다는 의미다.<br>\n(ii) CNN (이미지 처리) => 입력층 shape<br>\n현재까지 28*28 image를 행렬을 벡터로 변경했다. CNN에서는 vector 아닌 tensor로 해줘야 한다.</p>\n<p>★ 고급 아키텍처 : 은닉층 hidden layer 변경 => hidden layer = major component<br>\n특히 image 처리를 위해 정확도를 높히려면, ★ (x,y, color) tensor 로 써야 한다.<br>\n=> 실제 처리하는 건 은닉층이다만, 은닉층에서 잘 처리하기 위해서는 입력층이 바뀌어야한다.</p>\n<hr>\n<h4 id=\"convolution\" style=\"position:relative;\">Convolution<a href=\"#convolution\" aria-label=\"convolution permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>$f(t) * g(t) = ∫f(τ)g(t-τ)dτ$<br>\n적분 변수와 결과로 나온 변수가 다르다.<br>\n=> t에 대한 함수이다. = t에 대해 변한다.</p>\n<p>f 원본 data에 g 만큼의 변화를 준다고 볼 수 있는데, 적분은 연속적인 더하기 (sigma는 불연속) 이므로 <strong>원본 변화의 평균</strong>을 의미한다고 볼 수 있다.</p>\n<p>cf. 행렬곱 : XㆍW 원본 data에 평균적으로 변화를 줄 때 얼마나 변하는지 알 때</p>\n<p>★ 여기서는 t 변화로 다양한 변화를 줄 수 있다. (행렬곱은 정적이다.)</p>\n<p>insight => \"data variation , average , time shift\"</p>\n<p>Conv는 ​<strong>시간에 따라 원본에 대한 평균적인 변화를 알고 싶을 때 사용한다.</strong></p>\n<p>cf. 원본을 평균적으로 변화시키고 싶을 때는 행렬 곱,<br>\n입력의 미세한 변화에 얼마나 출력이 반응하나 볼 때는 미분 !</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Convolution\">예시</a>  </p>\n<div class=\"gatsby-highlight\" data-language=\"<imgsrc=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/convolution_of_spiky_function_with_box2.gif\">\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-<imgsrc=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/convolution_of_spiky_function_with_box2.gif\"> line-numbers\"><code class=\"language-<imgsrc=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/convolution_of_spiky_function_with_box2.gif\">\"></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"></span></pre></div>\n<p>=> 원본에 변화를 주는데, 원본의 특징 feature을 뽑아 내면서 변화를 준다<br>\n(원본 f가 오른쪽으로 감소하면, conv 결과도 결국 오른쪽으로 감소하는 특징을 띈다.)</p>\n<hr>\n<h3 id=\"cnn\" style=\"position:relative;\">CNN<a href=\"#cnn\" aria-label=\"cnn permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>CNN 아키텍처 : 은닉층 1개 이상의 conv + pool + 완전 연결층 을 갖고 있다.</li>\n</ul>\n<p>(1) 컨볼루션층 개요</p>\n<ol>\n<li>pooling - max, min, avg,,,<br>\n(max pooling) 주어진 data size에서 가장 큰 값을 추출하는 연산을 수행하는데, 데이터 특징을 압축하여 데이터의 연산량을 줄여주는 역할을 한다. 보통 max pooling을 가장 많이 쓴다.</li>\n<li>\n<p>conv (convolution)<br>\n입력과 filter의 convolution 연산을 통해 <strong>입력 data의 feature을 추출</strong>한다.  </p>\n<ul>\n<li>f(τ) : input  </li>\n<li>g(t-τ) : filter</li>\n</ul>\n</li>\n</ol>\n<p>컴퓨터에서 다루는 값은 이산적이다.</p>\n<p>​filter (kernel)는 가중치 W 집합체이다.</p>\n<ol start=\"3\">\n<li>\n<p>컨볼루션 (convolution) 연산 * – 특징 추출 (특징 맵, feature map)</p>\n<ul>\n<li>stride : 필터의 이동 간격, 시간적으로 이동한다<br>\nex) stride = 1 => 1칸 씩 이동</li>\n</ul>\n</li>\n</ol>\n<p>★ feature map : XㆍW + b => filter 1개 당 feature map 1개 나온다. ?<br>\nbias는 filter 당 1개이다.</p>\n<p>Y = XㆍW + b<br>\nY &#x3C;-> T => loss</p>\n<p>ex. X=10, T=100 : W = 6이면 10씩 올린다 치면, 5번 수행해야 오차가 최소가 된다.<br>\n=> b가 +10 있는 게 더 적은 횟수로 오차가 최소가 될 수 있다.<br>\n=> <strong>bias : 원래 계산한 값의 가속 또는 감속을 해준다</strong><br>\n= W : data variation\n= b : adjustment</p>\n<p>=> bias : 어떤 특징을 빨리 찾아가게 보정<br>\nfeature map : 원본 data 특징을 간직</p>\n<p>은닉층 갯수, 노드나 conv 수, 완전 연결층 수 비롯해서 conv filter size, stride 수치 모두 hyper paremeter이다.</p>\n<p>​Convolution의 핵심은 filter이다.<br>\nex. 필터 (가중치 집합체) size가 3x3 이면, 가중치는 9개다.<br>\nex. ​4x4 filter 가 4개이면 w는 64개이고, bias는 filter 당 1개니까 4개이다.</p>\n<p><strong>​★ filter size => weight / a bias per filter</strong></p>\n<p>ex. kernel 3x3 / filters 50 => w 갯수 450 , b 갯수 50</p>\n<p>ex. ​4x4 입력 data > conv 2x2 > relu > pooling > 1x1<br>\n=> 1x1가 되니 또 conv를 할 수가 없다.\n=> 이처럼 conv 시 shape이 줄어드는 문제를 해결하는 게 padding이다.</p>\n<ol start=\"4\">\n<li>\n<p>padding<br>\n원본 크기 줄어드는 걸 방지한다.\n원본에 padding하여 약간의 오차 발생하는 건, 어쩔 수 없다.</p>\n<ul>\n<li>padding = 1 : 껍데기 1</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h4 id=\"예제0\" style=\"position:relative;\">예제0<a href=\"#%EC%98%88%EC%A0%9C0\" aria-label=\"예제0 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p><a href=\"https://en.wikipedia.org/wiki/Kernel_(image_processing)\">Filter Sample</a></p>\n<p>​rgb 가 0~255 사이 값이니까, conv 결과 값이 255 넘으면 255로 세팅해 줘야 한다.</p>\n<p><strong>​★ 딥러닝으로 vertical 성분을 찾으려면 vertical loss func 값이 min 되는 w를 찾으면 된다.</strong></p>\n<p>예전에는 수학자들이 계산을 해서 filter 값을 구했지만, 지금은 정답 vertical 에 대한 loss min 되는 W 찾으면 그게 filter가 된다.</p>\n<hr>\n<h4 id=\"필터를-통한-입력-데이터-특징-추출-원리--특징-맵이-압축된-풀링-값\" style=\"position:relative;\">필터를 통한 입력 데이터 특징 추출 원리 – 특징 맵이 압축된 풀링 값<a href=\"#%ED%95%84%ED%84%B0%EB%A5%BC-%ED%86%B5%ED%95%9C-%EC%9E%85%EB%A0%A5-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8A%B9%EC%A7%95-%EC%B6%94%EC%B6%9C-%EC%9B%90%EB%A6%AC--%ED%8A%B9%EC%A7%95-%EB%A7%B5%EC%9D%B4-%EC%95%95%EC%B6%95%EB%90%9C-%ED%92%80%EB%A7%81-%EA%B0%92\" aria-label=\"필터를 통한 입력 데이터 특징 추출 원리  특징 맵이 압축된 풀링 값 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>2에 대해 가로, 대각선, 세로 필터 중 대각선의 경우가 가장 합이 크다.<br>\n= 많이 겹쳐서 크게 나왔다 = 필터와 겹치는 부분이 많다</p>\n<p>=> pooling이 크다는 건 conv가 가장 크다는 거고, conv가 가장 크다는 건 원본과 겹치는 게 가장 많다는 거니까 feature을 가장 많이 갖고 있다는 의미다.</p>\n<p>​...어떤 이미지의 특징을 뽑기 위해 필터를 몇 십개 해야할 수도...</p>\n<hr>\n<h4 id=\"컨볼루션-층-convolution-layer-역할\" style=\"position:relative;\">컨볼루션 층 (convolution layer) 역할<a href=\"#%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98-%EC%B8%B5-convolution-layer-%EC%97%AD%ED%95%A0\" aria-label=\"컨볼루션 층 convolution layer 역할 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>filter를 통해 특징을 추출하는 게 CNN Conv 층의 목적이다.</p>\n<p>NN은 구석에 적힌 5를 못 구분하는데, CNN은 구분 가능하다.<br>\n= NN은 특징을 추출하지 못 한다.</p>\n<p>​일반 신경망 NN에서는 vector로 변환해 input을 넣는다. vector 각 위치에 가중치가 곱해지니, 데이터의 위치에 민감하다.\n=> NN에서는 vector로 값을 넣어 숫자 위치의 조합하기에, feature 특징이 없어진다.</p>\n<p>CNN에서는 tensor 그 자체를 넣어 조합해서 특징을 뽑을 수 있다.</p>\n<p>일반 data는 position 위치에 dependency가 있는데, CNN은 feature을 갖고 있다. 이를 손상 시키지 않기 위해 vector로 안 만들고 통으로 data를 넣는다. CNN은 tensor 그대로 넣어줘야 한다.\ncf. 영상처리</p>\n<hr>\n<p>channel data의 이동통로 : input channel , output channel<br>\n=> output channel은 filter 갯수랑 동일하다</p>\n<p>ex. 5 짜리 1개 > filter 4개 > filter 4개 >>> 16개</p>\n<p>1개 채널로 들어오는 data에 대해 3x3 filter 32개가 적용되면, [3,3,1,32] 이렇게 표현할 수 있다.  </p>\n<ul>\n<li>padding = 'SAME' : 원본 크기가 줄지 않도록 padding</li>\n<li>padding = 'VALID' : padding 안 하는 건</li>\n</ul>\n<p>이런 경우, conv함수에 fileter 파라미터 리스트를 [3,3,2,32] 라고 주면, 에러가 난다.</p>\n<p>​ex. 5 1개 짜리 > 3x3 32개 > 4x4 128개<br>\n=> 각각 [3,3,1,32] [4,4,32,128] 이렇게 표현할 수 있다.</p>\n<p>​ex. 5 1개 짜리 > 3x3 32개 > 4x4 64개 > 5x5 128개<br>\n=> [3,3,1,32] [4,4,32,64] [5,5,64,128]</p>\n<p><strong>마지막 은닉층의 output 채널 갯수가 원본데이터에 대해 뽑으려는 최종 피처 개수</strong> 이다.\n​\ncf. 원자 atom</p>\n<hr>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">A2 = P2 = tf.nn.max_pool(Z2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=&#39;SAME&#39;)</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>max_pool(Z2, ksize=[1,2,2,1] 앞에서 넘어온 2x2에서 max 1개를 뽑겠다는 의미다.\nstrides=[1,2,2,1], => 뽑고 2칸 씩 이동하겠다는 의미이다.</p>\n<p>ksize는 데이터 몇 개에서 뽑는지, strides는 뽑고 얼마나 이동할 건지를 세팅할 때 쓴다.</p>\n<p>max_pool의 padding은 아까 conv에서의 padding 과는 다르다.<br>\n여기서는 max 구할 때 쓸 게 모자르면 그 나머지를 채워주느냐를 정할 때 쓴다.<br>\n=> VALID 버린다는 거고, SAME 나머지 붙여서 살린다는 거로, 보통 SAME을 쓰는 편이다.</p>\n<hr>\n<ul>\n<li>channel은 data가 들어오고 나가는 통로이다.</li>\n<li>​input channel의 갯수 x output 갯수, ​output_channel은 filter의 개수와 동일하다.</li>\n<li>channel 과 전체 data 를 헷갈리면 안 된다.</li>\n</ul>\n<p>ex. input 2개여도 filter 32.. 이면, 32 씩 빠져 나간다. 전체 나간 건 64이더라도.</p>\n<ul>\n<li>stddev 범위 정하는 거도 하이퍼 파라미터이다. 이렇게 CNN은 정교하게 설계해야 한다.</li>\n<li>bias는 필터 수 만큼 필요하고, w는 가중치 집합이다.</li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#16%EC%9D%BC%EC%B0%A8\">16일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#%EC%9D%80%EB%8B%89%EC%B8%B5\">은닉층</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#convolution\">Convolution</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#cnn\">CNN</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C0\">예제0</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#%ED%95%84%ED%84%B0%EB%A5%BC-%ED%86%B5%ED%95%9C-%EC%9E%85%EB%A0%A5-%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%8A%B9%EC%A7%95-%EC%B6%94%EC%B6%9C-%EC%9B%90%EB%A6%AC--%ED%8A%B9%EC%A7%95-%EB%A7%B5%EC%9D%B4-%EC%95%95%EC%B6%95%EB%90%9C-%ED%92%80%EB%A7%81-%EA%B0%92\">필터를 통한 입력 데이터 특징 추출 원리 – 특징 맵이 압축된 풀링 값</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-16%EC%9D%BC%EC%B0%A8/#%EC%BB%A8%EB%B3%BC%EB%A3%A8%EC%85%98-%EC%B8%B5-convolution-layer-%EC%97%AD%ED%95%A0\">컨볼루션 층 (convolution layer) 역할</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 16일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-16일차/"}},"staticQueryHashes":["3159585216"]}