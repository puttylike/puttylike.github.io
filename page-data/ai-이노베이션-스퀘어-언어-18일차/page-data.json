{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-언어-18일차/",
    "result": {"data":{"markdownRemark":{"html":"<p>어제에 이어서 계속 모델을 만들었다.</p>\n<hr>\n<h3 id=\"18일차\" style=\"position:relative;\">18일차<a href=\"#18%EC%9D%BC%EC%B0%A8\" aria-label=\"18일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h4 id=\"model-4-다시\" style=\"position:relative;\">Model 4 (다시)<a href=\"#model-4-%EB%8B%A4%EC%8B%9C\" aria-label=\"model 4 다시 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># Model 4 : token embedding + character embedding (hybrid embedding Layer)</span>\r\ntoken_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>string<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"token_input\"</span><span class=\"token punctuation\">)</span>\r\ntoken_embeddings <span class=\"token operator\">=</span> tf_hub_embedding_layer<span class=\"token punctuation\">(</span>token_inputs<span class=\"token punctuation\">)</span>\r\ntoken_output <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>token_embeddings<span class=\"token punctuation\">)</span>\r\ntoken_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> token_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> token_output\r\n<span class=\"token punctuation\">)</span>\r\n\r\nchar_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>string<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"char_input\"</span><span class=\"token punctuation\">)</span>\r\nchar_vectors <span class=\"token operator\">=</span> char_vectorizer<span class=\"token punctuation\">(</span>char_inputs<span class=\"token punctuation\">)</span>\r\nchar_embeddings <span class=\"token operator\">=</span> char_embed<span class=\"token punctuation\">(</span>char_vectors<span class=\"token punctuation\">)</span>\r\nchar_bi_lstm <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Bidirectional<span class=\"token punctuation\">(</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">25</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>char_embeddings<span class=\"token punctuation\">)</span>\r\nchar_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> char_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> char_bi_lstm\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntoken_char_concat <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Concatenate<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token string\">\"token_char_hybrid\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">[</span>token_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">,</span> char_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\ncombined_dropout <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>token_char_concat<span class=\"token punctuation\">)</span>\r\ncombine_dense <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>combined_dropout<span class=\"token punctuation\">)</span>\r\nfinal_dropout <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>combine_dense<span class=\"token punctuation\">)</span>\r\noutput_layer <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span>num_classes<span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"softmax\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>final_dropout<span class=\"token punctuation\">)</span>\r\n\r\nmodel_4 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>token_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">,</span> char_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> output_layer<span class=\"token punctuation\">,</span>\r\n    name <span class=\"token operator\">=</span> <span class=\"token string\">\"model_4_token_and_char_embeddings\"</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_4<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> <span class=\"token string\">\"categorical_crossentropy\"</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nmodel_4<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_4_token_and_char_embeddings\"</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                    Output Shape         Param #     Connected to                     </span>\r\n<span class=\"token comment\"># ==================================================================================================</span>\r\n<span class=\"token comment\"># char_input (InputLayer)         [(None, 1)]          0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># token_input (InputLayer)        [(None,)]            0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># char_vectorizer (TextVectorizat (None, 290)          0           char_input[0][0]                 </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[0][0]            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_2 (Dense)                 (None, 128)          65664       universal_sentence_encoder[2][0]</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># bidirectional (Bidirectional)   (None, 50)           10200       char_embed[0][0]                 </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># token_char_hybrid (Concatenate) (None, 178)          0           dense_2[0][0]                    </span>\r\n<span class=\"token comment\">#                                                                  bidirectional[0][0]              </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># dropout (Dropout)               (None, 178)          0           token_char_hybrid[0][0]          </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_3 (Dense)                 (None, 200)          35800       dropout[0][0]                    </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ==================================================================================================</span>\r\n<span class=\"token comment\"># Total params: 256,912,243</span>\r\n<span class=\"token comment\"># Trainable params: 114,419</span>\r\n<span class=\"token comment\"># Non-trainable params: 256,797,824</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n\r\ntrain_char_token_data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>train_sentences<span class=\"token punctuation\">,</span> train_chars<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\ntrain_char_token_labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>train_labels_one_hot<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\ntrain_char_token_dataset <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>train_char_token_data<span class=\"token punctuation\">,</span> train_char_token_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntrain_char_token_dataset <span class=\"token operator\">=</span> train_char_token_dataset<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>AUTOTUNE<span class=\"token punctuation\">)</span>\r\n\r\nval_char_token_data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>val_sentences<span class=\"token punctuation\">,</span> val_chars<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_char_token_labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>val_labels_one_hot<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_char_token_dataset <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>val_char_token_data<span class=\"token punctuation\">,</span> val_char_token_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\nval_char_token_dataset <span class=\"token operator\">=</span> val_char_token_dataset<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>AUTOTUNE<span class=\"token punctuation\">)</span>\r\n\r\ntrain_char_token_dataset<span class=\"token punctuation\">,</span> val_char_token_dataset\r\n<span class=\"token comment\"># (&lt;PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,</span>\r\n<span class=\"token comment\">#  &lt;PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)</span>\r\n\r\nmodel_4_history <span class=\"token operator\">=</span> model_4<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_char_token_dataset<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> val_char_token_dataset\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 1/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1392s 243ms/step - loss: 0.7558 - accuracy: 0.7113 - val_loss: 0.6298 - val_accuracy: 0.7620</span>\r\n<span class=\"token comment\"># Epoch 2/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1155s 205ms/step - loss: 0.6770 - accuracy: 0.7435 - val_loss: 0.6004 - val_accuracy: 0.7725</span>\r\n<span class=\"token comment\"># Epoch 3/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1074s 191ms/step - loss: 0.6533 - accuracy: 0.7531 - val_loss: 0.5857 - val_accuracy: 0.7783</span>\r\n\r\nmodel_4<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>val_char_token_dataset<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 945/945 [==============================] - 43s 45ms/step - loss: 0.5857 - accuracy: 0.7783</span>\r\n<span class=\"token comment\"># [0.5856992602348328, 0.7782669067382812]</span>\r\n\r\nmodel_4_pred_probs <span class=\"token operator\">=</span> model_4<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_char_token_dataset<span class=\"token punctuation\">)</span>\r\nmodel_4_pred_probs\r\n<span class=\"token comment\"># array([[4.5920759e-01, 3.5270458e-01, 2.6398026e-03, 1.7632075e-01,</span>\r\n<span class=\"token comment\">#         9.1272136e-03],</span>\r\n<span class=\"token comment\">#        [3.9703694e-01, 5.0043422e-01, 2.8697588e-03, 9.7028695e-02,</span>\r\n<span class=\"token comment\">#         2.6303916e-03],</span>\r\n<span class=\"token comment\">#        [4.6506163e-01, 1.2030231e-03, 1.0704625e-02, 5.2264196e-01,</span>\r\n<span class=\"token comment\">#         3.8873247e-04],</span>\r\n<span class=\"token comment\">#        ...,</span>\r\n<span class=\"token comment\">#        [6.0490420e-05, 2.3867613e-04, 6.2220809e-03, 2.0935395e-05,</span>\r\n<span class=\"token comment\">#         9.9345785e-01],</span>\r\n<span class=\"token comment\">#        [7.9255654e-03, 4.3332968e-02, 1.0774361e-01, 2.8592341e-03,</span>\r\n<span class=\"token comment\">#         8.3813864e-01],</span>\r\n<span class=\"token comment\">#        [3.1338368e-02, 9.6217674e-01, 3.6836299e-03, 2.9731510e-04,</span>\r\n<span class=\"token comment\">#         2.5038878e-03]], dtype=float32)</span>\r\n\r\nmodel_4_preds <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>model_4_pred_probs<span class=\"token punctuation\">,</span> axis <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\nmodel_4_preds\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1], dtype=int64)></span>\r\n\r\nmodel_4_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>\r\n    y_true <span class=\"token operator\">=</span> val_labels_encoded<span class=\"token punctuation\">,</span>\r\n    y_pred <span class=\"token operator\">=</span> model_4_preds\r\n<span class=\"token punctuation\">)</span>\r\nmodel_4_results\r\n<span class=\"token comment\"># {'accuracy': 77.82669138090826,</span>\r\n<span class=\"token comment\">#  'precision': 0.7764131506179106,</span>\r\n<span class=\"token comment\">#  'recall': 0.7782669138090825,</span>\r\n<span class=\"token comment\">#  'f1': 0.7743133351993391}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>google colab에서도 돌려보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">!nvidia<span class=\"token operator\">-</span>smi <span class=\"token operator\">-</span>L</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<h4 id=\"model-5\" style=\"position:relative;\">Model 5<a href=\"#model-5\" aria-label=\"model 5 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># Model 5 : token embedding + character embedding (여기까지 해서는 그다지 성능 향상이 없었다!) + positional embedding</span>\r\n\r\ntrain_df<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># target\ttext\tline_number\ttotal_lines</span>\r\n<span class=\"token comment\"># 0\tOBJECTIVE\tto investigate the efficacy of @ weeks of dail...\t0\t11</span>\r\n<span class=\"token comment\"># 1\tMETHODS\ta total of @ patients with primary knee oa wer...\t1\t11</span>\r\n<span class=\"token comment\"># 2\tMETHODS\toutcome measures included pain reduction and i...\t2\t11</span>\r\n<span class=\"token comment\"># 3\tMETHODS\tpain was assessed using the visual analog pain...\t3\t11</span>\r\n<span class=\"token comment\"># 4\tMETHODS\tsecondary outcome measures included the wester...\t4\t11</span>\r\n\r\ntrain_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"line_number\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 0     15000</span>\r\n<span class=\"token comment\"># 1     15000</span>\r\n<span class=\"token comment\"># 2     15000</span>\r\n<span class=\"token comment\"># 3     15000</span>\r\n<span class=\"token comment\"># 4     14992</span>\r\n<span class=\"token comment\"># 5     14949</span>\r\n<span class=\"token comment\"># 6     14758</span>\r\n<span class=\"token comment\"># 7     14279</span>\r\n<span class=\"token comment\"># 8     13346</span>\r\n<span class=\"token comment\"># 9     11981</span>\r\n<span class=\"token comment\"># 10    10041</span>\r\n<span class=\"token comment\"># 11     7892</span>\r\n<span class=\"token comment\"># 12     5853</span>\r\n<span class=\"token comment\"># 13     4152</span>\r\n<span class=\"token comment\"># 14     2835</span>\r\n<span class=\"token comment\"># 15     1861</span>\r\n<span class=\"token comment\"># 16     1188</span>\r\n<span class=\"token comment\"># 17      751</span>\r\n<span class=\"token comment\"># 18      462</span>\r\n<span class=\"token comment\"># 19      286</span>\r\n<span class=\"token comment\"># 20      162</span>\r\n<span class=\"token comment\"># 21      101</span>\r\n<span class=\"token comment\"># 22       66</span>\r\n<span class=\"token comment\"># 23       33</span>\r\n<span class=\"token comment\"># 24       22</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># 26        7</span>\r\n<span class=\"token comment\"># 27        4</span>\r\n<span class=\"token comment\"># 28        3</span>\r\n<span class=\"token comment\"># 29        1</span>\r\n<span class=\"token comment\"># 30        1</span>\r\n<span class=\"token comment\"># Name: line_number, dtype: int64</span>\r\n\r\ntrain_df<span class=\"token punctuation\">.</span>line_number<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\ntrain_line_numbers_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    train_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"line_number\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_line_numbers_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    val_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"line_number\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\r\n<span class=\"token punctuation\">)</span>\r\ntest_line_numbers_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    test_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"line_number\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntrain_line_numbers_one_hot<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> train_line_numbers_one_hot\r\n<span class=\"token comment\"># (TensorShape([180040, 15]),</span>\r\n<span class=\"token comment\">#  &lt;tf.Tensor: shape=(180040, 15), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[1., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 1., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 1., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         ...,</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)</span>\r\n\r\ntrain_line_numbers_one_hot<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">20</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(20, 15), dtype=float32, numpy=</span>\r\n<span class=\"token comment\"># array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],</span>\r\n<span class=\"token comment\">#       dtype=float32)></span>\r\n\r\ntrain_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"total_lines\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 11    24468</span>\r\n<span class=\"token comment\"># 10    23639</span>\r\n<span class=\"token comment\"># 12    22113</span>\r\n<span class=\"token comment\"># 9     19400</span>\r\n<span class=\"token comment\"># 13    18438</span>\r\n<span class=\"token comment\"># 14    14610</span>\r\n<span class=\"token comment\"># 8     12285</span>\r\n<span class=\"token comment\"># 15    10768</span>\r\n<span class=\"token comment\"># 7      7464</span>\r\n<span class=\"token comment\"># 16     7429</span>\r\n<span class=\"token comment\"># 17     5202</span>\r\n<span class=\"token comment\"># 6      3353</span>\r\n<span class=\"token comment\"># 18     3344</span>\r\n<span class=\"token comment\"># 19     2480</span>\r\n<span class=\"token comment\"># 20     1281</span>\r\n<span class=\"token comment\"># 5      1146</span>\r\n<span class=\"token comment\"># 21      770</span>\r\n<span class=\"token comment\"># 22      759</span>\r\n<span class=\"token comment\"># 23      264</span>\r\n<span class=\"token comment\"># 4       215</span>\r\n<span class=\"token comment\"># 24      200</span>\r\n<span class=\"token comment\"># 25      182</span>\r\n<span class=\"token comment\"># 26       81</span>\r\n<span class=\"token comment\"># 28       58</span>\r\n<span class=\"token comment\"># 3        32</span>\r\n<span class=\"token comment\"># 30       31</span>\r\n<span class=\"token comment\"># 27       28</span>\r\n<span class=\"token comment\"># Name: total_lines, dtype: int64</span>\r\n\r\ntrain_df<span class=\"token punctuation\">.</span>total_lines<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">.</span>hist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nnp<span class=\"token punctuation\">.</span>percentile<span class=\"token punctuation\">(</span>train_df<span class=\"token punctuation\">.</span>total_lines<span class=\"token punctuation\">,</span> <span class=\"token number\">98</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 20.0</span>\r\n\r\ntrain_total_lines_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    train_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"total_lines\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_total_lines_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    val_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"total_lines\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\r\n<span class=\"token punctuation\">)</span>\r\ntest_total_lines_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>one_hot<span class=\"token punctuation\">(</span>\r\n    test_df<span class=\"token punctuation\">[</span><span class=\"token string\">\"total_lines\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> depth <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntrain_total_lines_one_hot<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> train_total_lines_one_hot\r\n<span class=\"token comment\"># (TensorShape([180040, 20]),</span>\r\n<span class=\"token comment\">#  &lt;tf.Tensor: shape=(180040, 20), dtype=float32, numpy=</span>\r\n<span class=\"token comment\">#  array([[0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         ...,</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.],</span>\r\n<span class=\"token comment\">#         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">token_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>string<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"token_input\"</span><span class=\"token punctuation\">)</span>\r\ntoken_embeddings <span class=\"token operator\">=</span> tf_hub_embedding_layer<span class=\"token punctuation\">(</span>token_inputs<span class=\"token punctuation\">)</span>\r\ntoken_output <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>token_embeddings<span class=\"token punctuation\">)</span>\r\ntoken_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> token_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> token_embeddings\r\n<span class=\"token punctuation\">)</span>\r\n\r\nchar_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>string<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"char_input\"</span><span class=\"token punctuation\">)</span>\r\nchar_vectors <span class=\"token operator\">=</span> char_vectorizer<span class=\"token punctuation\">(</span>char_inputs<span class=\"token punctuation\">)</span>\r\nchar_embeddings <span class=\"token operator\">=</span> char_embed<span class=\"token punctuation\">(</span>char_vectors<span class=\"token punctuation\">)</span>\r\nchar_bi_lstm <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Bidirectional<span class=\"token punctuation\">(</span>layers<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>char_embeddings<span class=\"token punctuation\">)</span>\r\nchar_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> char_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> char_bi_lstm\r\n<span class=\"token punctuation\">)</span>\r\n\r\nline_number_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"line_number_input\"</span><span class=\"token punctuation\">)</span>\r\nx <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>line_number_inputs<span class=\"token punctuation\">)</span>\r\nline_number_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> line_number_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> x\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntotal_lines_inputs <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>int32<span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"total_lines_input\"</span><span class=\"token punctuation\">)</span>\r\ny <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> activation <span class=\"token operator\">=</span> <span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>total_lines_inputs<span class=\"token punctuation\">)</span>\r\ntotal_lines_model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> total_lines_inputs<span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> y\r\n<span class=\"token punctuation\">)</span>\r\n\r\ncombined_embeddings <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Concatenate<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token string\">\"token_char_hybrid_embedding\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">[</span>token_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">,</span> char_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\nz <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"relu\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>combined_embeddings<span class=\"token punctuation\">)</span>\r\nz <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\r\n\r\nz <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Concatenate<span class=\"token punctuation\">(</span>name <span class=\"token operator\">=</span> <span class=\"token string\">\"token_char_positional_embedding\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">[</span>line_number_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">,</span> total_lines_model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">,</span> z<span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\noutput_layer <span class=\"token operator\">=</span> layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">\"softmax\"</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> <span class=\"token string\">\"output_layer\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>z<span class=\"token punctuation\">)</span>\r\n\r\nmodel_5 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>\r\n    inputs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>line_number_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">,</span> total_lines_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">,</span> token_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">,</span> char_model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\r\n    outputs <span class=\"token operator\">=</span> output_layer<span class=\"token punctuation\">,</span>\r\n    name <span class=\"token operator\">=</span> <span class=\"token string\">\"model_5_token_and_char_positional_embeddings\"</span>\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\">###### label smoothing  </span>\r\ncf<span class=\"token punctuation\">.</span> <span class=\"token punctuation\">[</span>label smoothing<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>https<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>www<span class=\"token punctuation\">.</span>pyimagesearch<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span><span class=\"token number\">2019</span><span class=\"token operator\">/</span><span class=\"token number\">12</span><span class=\"token operator\">/</span><span class=\"token number\">30</span><span class=\"token operator\">/</span>label<span class=\"token operator\">-</span>smoothing<span class=\"token operator\">-</span><span class=\"token keyword\">with</span><span class=\"token operator\">-</span>keras<span class=\"token operator\">-</span>tensorflow<span class=\"token operator\">-</span><span class=\"token keyword\">and</span><span class=\"token operator\">-</span>deep<span class=\"token operator\">-</span>learning<span class=\"token operator\">/</span><span class=\"token punctuation\">)</span>  \r\n\r\n<span class=\"token punctuation\">[</span><span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.0</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">:</span> 예측 결과  \r\n<span class=\"token punctuation\">[</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.096</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">]</span> 로 좀더 유연하게 결과를 예측하겠다<span class=\"token punctuation\">.</span>  \r\n\r\n\r\n\r\n```python\r\nmodel_5<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>\r\n    loss <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>CategoricalCrossentropy<span class=\"token punctuation\">(</span>label_smoothing <span class=\"token operator\">=</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n    metrics <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"accuracy\"</span><span class=\"token punctuation\">]</span>\r\n<span class=\"token punctuation\">)</span>\r\n\r\ntrain_pos_char_token_data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>train_line_numbers_one_hot<span class=\"token punctuation\">,</span> train_total_lines_one_hot<span class=\"token punctuation\">,</span> train_sentences<span class=\"token punctuation\">,</span> train_chars<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\ntrain_pos_char_token_labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    train_labels_one_hot\r\n<span class=\"token punctuation\">)</span>\r\ntrain_pos_char_token_dataset <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>train_pos_char_token_data<span class=\"token punctuation\">,</span> train_pos_char_token_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\ntrain_pos_char_token_dataset <span class=\"token operator\">=</span> train_pos_char_token_dataset<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>AUTOTUNE<span class=\"token punctuation\">)</span>\r\n\r\nval_pos_char_token_data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>val_line_numbers_one_hot<span class=\"token punctuation\">,</span> val_total_lines_one_hot<span class=\"token punctuation\">,</span> val_sentences<span class=\"token punctuation\">,</span> val_chars<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_pos_char_token_labels <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\r\n    val_labels_one_hot\r\n<span class=\"token punctuation\">)</span>\r\nval_pos_char_token_dataset <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>\r\n    <span class=\"token punctuation\">(</span>val_pos_char_token_data<span class=\"token punctuation\">,</span> val_pos_char_token_labels<span class=\"token punctuation\">)</span>\r\n<span class=\"token punctuation\">)</span>\r\nval_pos_char_token_dataset <span class=\"token operator\">=</span> val_pos_char_token_dataset<span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>prefetch<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>AUTOTUNE<span class=\"token punctuation\">)</span>\r\n\r\ntrain_pos_char_token_dataset<span class=\"token punctuation\">,</span> val_pos_char_token_dataset\r\n<span class=\"token comment\"># (&lt;PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,</span>\r\n<span class=\"token comment\">#  &lt;PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)</span>\r\n\r\nmodel_5<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"model_5_token_and_char_positional_embeddings\"</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                    Output Shape         Param #     Connected to                     </span>\r\n<span class=\"token comment\"># ==================================================================================================</span>\r\n<span class=\"token comment\"># char_input (InputLayer)         [(None, 1)]          0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># char_vectorizer (TextVectorizat (None, 290)          0           char_input[0][0]                 </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># token_input (InputLayer)        [(None,)]            0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># char_embed (Embedding)          (None, 290, 25)      1750        char_vectorizer[6][0]            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># bidirectional_6 (Bidirectional) (None, 64)           14848       char_embed[6][0]                 </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># token_char_hybrid_embedding (Co (None, 576)          0           universal_sentence_encoder[8][0]</span>\r\n<span class=\"token comment\">#                                                                  bidirectional_6[0][0]            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># line_number_input (InputLayer)  [(None, 15)]         0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># total_lines_input (InputLayer)  [(None, 20)]         0                                            </span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_18 (Dense)                (None, 256)          147712      token_char_hybrid_embedding[0][0]</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n<span class=\"token comment\"># show more (open the raw output data in a text editor) ...</span>\r\n<span class=\"token comment\">#</span>\r\n<span class=\"token comment\"># ==================================================================================================</span>\r\n<span class=\"token comment\"># Total params: 256,964,923</span>\r\n<span class=\"token comment\"># Trainable params: 167,099</span>\r\n<span class=\"token comment\"># Non-trainable params: 256,797,824</span>\r\n<span class=\"token comment\"># __________________________________________________________________________________________________</span>\r\n\r\nhistory_model_5 <span class=\"token operator\">=</span> model_5<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>\r\n    train_pos_char_token_dataset<span class=\"token punctuation\">,</span>\r\n    epochs <span class=\"token operator\">=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span>\r\n    validation_data <span class=\"token operator\">=</span> val_pos_char_token_dataset\r\n<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 1/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1146s 202ms/step - loss: 0.9639 - accuracy: 0.8185 - val_loss: 0.9183 - val_accuracy: 0.8465</span>\r\n<span class=\"token comment\"># Epoch 2/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1147s 204ms/step - loss: 0.9249 - accuracy: 0.8489 - val_loss: 0.9082 - val_accuracy: 0.8548</span>\r\n<span class=\"token comment\"># Epoch 3/3</span>\r\n<span class=\"token comment\"># 5627/5627 [==============================] - 1129s 201ms/step - loss: 0.9154 - accuracy: 0.8551 - val_loss: 0.9018 - val_accuracy: 0.8580</span>\r\n\r\nmodel_5<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>val_pos_char_token_dataset<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 945/945 [==============================] - 46s 48ms/step - loss: 0.9018 - accuracy: 0.8580</span>\r\n<span class=\"token comment\"># [0.9018082618713379, 0.8580365180969238]</span>\r\n\r\nmodel_5_pred_probs <span class=\"token operator\">=</span> model_5<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>val_pos_char_token_dataset<span class=\"token punctuation\">)</span>\r\nmodel_5_pred_probs\r\n<span class=\"token comment\"># array([[0.60922456, 0.12058615, 0.00998181, 0.2443677 , 0.0158397 ],</span>\r\n<span class=\"token comment\">#        [0.5751243 , 0.10270885, 0.05144864, 0.25817865, 0.01253951],</span>\r\n<span class=\"token comment\">#        [0.39093482, 0.11479066, 0.04016395, 0.4121732 , 0.04193731],</span>\r\n<span class=\"token comment\">#        ...,</span>\r\n<span class=\"token comment\">#        [0.02000574, 0.06144356, 0.01907964, 0.02441884, 0.8750523 ],</span>\r\n<span class=\"token comment\">#        [0.02571532, 0.31107312, 0.046206  , 0.0237699 , 0.59323573],</span>\r\n<span class=\"token comment\">#        [0.04624481, 0.84173024, 0.05050771, 0.01891454, 0.04260261]],</span>\r\n<span class=\"token comment\">#       dtype=float32)</span>\r\n\r\nmodel_5_preds <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>model_5_pred_probs<span class=\"token punctuation\">,</span> axis <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\nmodel_5_preds\r\n<span class=\"token comment\"># &lt;tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1], dtype=int64)></span>\r\n\r\nmodel_5_results <span class=\"token operator\">=</span> calculate_results<span class=\"token punctuation\">(</span>\r\n    y_true <span class=\"token operator\">=</span> val_labels_encoded<span class=\"token punctuation\">,</span>\r\n    y_pred <span class=\"token operator\">=</span> model_5_preds\r\n<span class=\"token punctuation\">)</span>\r\nmodel_5_results\r\n<span class=\"token comment\"># {'accuracy': 85.80365417714815,</span>\r\n<span class=\"token comment\">#  'precision': 0.8591521781958201,</span>\r\n<span class=\"token comment\">#  'recall': 0.8580365417714815,</span>\r\n<span class=\"token comment\">#  'f1': 0.8548645763404921}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#18%EC%9D%BC%EC%B0%A8\">18일차</a></p>\n<ul>\n<li><a href=\"#model-4-%EB%8B%A4%EC%8B%9C\">Model 4 (다시)</a></li>\n<li><a href=\"#model-5\">Model 5</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 3기 언어반 18일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-언어-18일차/"}},
    "staticQueryHashes": ["3159585216"]}