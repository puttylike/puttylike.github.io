{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-시각-심화-12일차/",
    "result": {"data":{"markdownRemark":{"html":"<p>다음 주에는 이미지 시스템을 만든다. 이를 위한 이미지 크롤링이 요구된다.</p>\n<p>icrawler 하위 모듈로 GoogleImageCrawler 있지만,\r\n다음에서 받는 걸 추천한다. 이미지가 한글 이름이면 안 된다.</p>\n<hr>\n<h3 id=\"12일차\" style=\"position:relative;\">12일차<a href=\"#12%EC%9D%BC%EC%B0%A8\" aria-label=\"12일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h5 id=\"복습\" style=\"position:relative;\">복습<a href=\"#%EB%B3%B5%EC%8A%B5\" aria-label=\"복습 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>어제 실습 했던<br>\nTransferLearning_Exercise_decode_predictions.ipynb<br>\nTransferLearning_Example_1_MobileNet.ipynb<br>\n에서</p>\n<p>MobileNet의 경우, include_top = False일 때는 summary에서 conv_pw_13_relu (ReLU)까지 나와 있다만,<br>\nTrue일 때는 그 뒤에 global_average (이하 생략) ~ 부분도 나와 있다.</p>\n<p>아키텍처 관점에서 보면,\r\nTure일 때는 conv_pw_13_relu (ReLU)까지가 1번 feature extraction,\r\nglobal average pooling 2d가 2번, dropout부터 나머지가 3번으로 이 셋을 합해<br>\npretrained Mobilenet으로 볼 수 있다.</p>\n<p>False는 1번만 존재하는데, 이 1번은 pretrained 된 부분으로 feature 만 가져오고<br>\n2, 3번이 없으므로 Y를 만들어내려면 이 2개를 user define 해야 한다. (model.addd)<br>\n<strong>=> 이 False인 게 Transfer learning이다.</strong><br>\n기존에 pretrained된 model에서 feature extractor에 있는 w, b만 transfer 그대로 가져온다는 의미에서.</p>\n<p>정리하면, w, b만 갖고 오는 게 transfer learning,<br>\n필요한 거만 가져와서 조금씩 바꾸는게 fine tuning.<br>\nfine tuning하려면 learning rate 가 1e-4 ~ 1e-5 정도로 작아야 한다.</p>\n<p>False로 했던 TransferLearning_Example_1_MobileNet.ipynb를 보면,<br>\nFlatten을 add했는데, google은 global average pooling 2d가 더 성능이 좋다고 이걸 추가했을 뿐<br>\n3차원을 1차원으로 만드는 건 flatten과 동일하다.<br>\n(이 예제에서는 큰 차이 안 난다. 98%가 99%가 된 정도?)</p>\n<hr>\n<h5 id=\"복습2\" style=\"position:relative;\">복습2<a href=\"#%EB%B3%B5%EC%8A%B52\" aria-label=\"복습2 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>Cats_and_Dogs_Native_Colab_Ver1.ipynb</p>\n<p>MobileNet, ...V2는 224,224,3이고,<br>\nInceptionV3, ResNet은 299,299,3.<br>\npretrained model의 default shape을 기준으로 한다.</p>\n<p>cats and dogs의 평균 이미지 크기는 224,224,3 보다 컸다.\r\n큰거를 작게 줄이는 건 이미지가 안 꺠진다.<br>\n<strong>=> pandas로 통계를 내서 이미지 데이터 분포와 크기를 확인하는 작업을 거쳐야 한다.</strong></p>\n<hr>\n<h5 id=\"gtsrb---mobilenet\" style=\"position:relative;\">GTSRB - MobileNet<a href=\"#gtsrb---mobilenet\" aria-label=\"gtsrb   mobilenet permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>GTSRB를 MobileNet으로 해봤다.\r\nlearning rate가 1e-2일 때는 처참했는데, 더 작은 값을 쓰니까 좋아졌다.<br>\n1ㄷ-4는 수렴 속도가 빠르다.<br>\n2e-5보다는 1e-4가 epoch 10일 때 over fitting 발생없이 100%에 근사해서 1e-4가 더 좋다.<br>\n같은 모델을 쓸 거라면 1e-4가 best.</p>\n<hr>\n<p>GTSBR는 Native CNN도 정확도 99%, Trnasfer Learning도 99%가 나온다.<br>\n파라미터 수와 학습 시간을 비교해 보자<br>\n전자가 4분, 후자가 12분이 걸렸다.</p>\n<p>transfer learning의 기본 전제 조건은 데이터가 부족할 때 이다.<br>\n가령 학습데이터가 1만개 미만일 때. (주관적 기준)<br>\nCats and Dogs는 데이터가 1000개라 유효했다.</p>\n<p>cf. Colab Pro -> DL / MS Azure -> 개발환경 / AWS -> ..\r\n개발자, 일반인, 디렉터(의사결정) 별로 market share 를 분석한 보고서를 찾아 업무를 활용해 보자.</p>\n<hr>\n<h4 id=\"image-data-generator\" style=\"position:relative;\">Image Data Generator<a href=\"#image-data-generator\" aria-label=\"image data generator permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>transfer learning을 배웠다만,<br>\n여전히 매번 디렉토리 만들고 학습 데이와 테스트 데이터 만드는 작업을 반복해야만 한다.\r\nImage Data Augmentation 에는 Image Data Generator, GAN, VAE 등이 있다.</p>\n<ul>\n<li>Image Data Augmentation :</li>\n</ul>\n<p>원본 데이터에 변형을 가해 새로운 이미지를 만드는 방식<br>\n=> 데이터 증가</p>\n<p>ImageDataGenerator에는 rescale이 있어서 데이터를 만들 떄 정규화가 가능하다.\r\n디렉토리 만드는 작업만 해주면 된다.</p>\n<p>class+mode는 정답을 나타내는 방식이다.<br>\ncategorical, binary, sparse 3가지가 있다.</p>\n<p>작업 파일은 root 디렉토리가 있고, 그 밑에 디렉토리가 정답의 이름이고, 거기 있는 파일들이 학습할 데이터이면 된다.</p>\n<p>class_indices는 꼭 확인해야 한다.</p>\n<p>sub dir 갯수 만큼 정답을 숫자로 labeling해준다.<br>\n...파이썬에는 switch 문법이 없어 if 문으로 다 써야 한다. ㅠㅠ</p>\n<p>1만장 이상 모으면 가장 좋겠지만, 이미지가 없을 때 대안으로 쓸 만한 방법이다.</p>\n<ul>\n<li>ImageDataGenerator로,</li>\n</ul>\n<p>정답을 만들어내는 코드, 정규화 코드, cv2.imread(), resize(), cvtColor()를 대체할 수 있다.</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#12%EC%9D%BC%EC%B0%A8\">12일차</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"#%EB%B3%B5%EC%8A%B5\">복습</a></li>\n<li><a href=\"#%EB%B3%B5%EC%8A%B52\">복습2</a></li>\n<li><a href=\"#gtsrb---mobilenet\">GTSRB - MobileNet</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#image-data-generator\">Image Data Generator</a></p>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 3기 심화 시각반 12일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-시각-심화-12일차/"}},
    "staticQueryHashes": ["3159585216"]}