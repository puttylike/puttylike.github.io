{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-18일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"18일차\" style=\"position:relative;\">18일차<a href=\"#18%EC%9D%BC%EC%B0%A8\" aria-label=\"18일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>CNM을 마무리하며 TF 2 버전대로 진입했다. Keras도 배웠다. 왜 많이들 쓰는지 알 것 같다. 굉장히 사용하기 쉽다.</li>\n<li>교수님께서 다음 주에는 시험을 본다고 했다. 사전 평가 때보다 수준이 높을 거 같아 걱정은 된다.<br>\n전체적으로 복습을 좀 하고, 여건이 되면 12월에는 빅데이터 분석기사를 벼락치기 해봐야겠다. 그리고 DOCKER 기초 지식을 습득하고. ㅎㅎ</li>\n<li>사실, 고급 과정 문의나 대학원 문의를 해볼까 했는데, 고급 과정이 열리면 사무국(?)을 통해 기본 과정 수강생들에게 공지를 주시겠다고 하셔서 일단은 보류... 커뮤니케이션을 위해 기본과정을 수료한 사람이 편하신가 보다. 아무튼 고급 과정은 내가 앞으로 뭘 하게 되든 무조건 들을 예정이다. ㅇㅇ<br>\n고급 과정에는 음성/시각/언어 3가지가 있다. 보험은 인지산업이라 불렸다만, 내게는 셋 다 재밌어 보여서 과정 열리는 대로 다 듣고 싶다. 근데, RNN은 교수님 책이랑 유튜브 봐야 하나...?</li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Fratten 완전 연결층의 의미 ?  </li>\n</ul>\n<hr>\n<h4 id=\"예제8-3conv-pool-제거--index-label-list\" style=\"position:relative;\">예제8 3conv pool 제거 &#x26; index label list<a href=\"#%EC%98%88%EC%A0%9C8-3conv-pool-%EC%A0%9C%EA%B1%B0--index-label-list\" aria-label=\"예제8 3conv pool 제거  index label list permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>예제처럼 마지막에 꼭 pool을 없앨 필요는 없다. 중간에 없애 놓아도 된다. flatten 전에 tensor, 후에 vector 이면 된다.<br>\npooling 하나 안 하나 정확도는 별 차이가 없다. but data가 더 많아지든, conv 층이 더 바뀌든 하면 바뀔 거다. 그럴 땐 차이점을 파악해야 한다.  </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함</span>\npredicted_val <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>A5<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>T<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># batch_size X 10 의 True, False 를 1 또는 0 으로 변환</span>\naccuracy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>predicted_val<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\naccuracy_index <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>predicted_val<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span> <span class=\"token comment\"># index list 출력</span>\npredicted_list <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>A5<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 예측값 처리</span>\nindex_label_prediction_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># session 안에서 정의하면 종료 시 소멸되어서</span>\n<span class=\"token comment\"># 중략</span>\n\n<span class=\"token comment\"># 학습 후 sess.run</span>\naccuracy_val<span class=\"token punctuation\">,</span> predicted_list_val<span class=\"token punctuation\">,</span> index_label <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>accuracy<span class=\"token punctuation\">,</span> predicted_list<span class=\"token punctuation\">,</span> accuracy_index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> test_x_data<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">:</span> test_t_data<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\nindex_label_list <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>index_label<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"length of index_label_list = \"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>index_label_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"false label count = \"</span><span class=\"token punctuation\">,</span> index_label_list<span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ntemp_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">for</span> index <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>index_label<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> index_label<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        temp_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>index<span class=\"token punctuation\">)</span>\n        temp_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>test_t_data<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># one-hot encoding 이므로 argmax 로 정답 추출</span>\n        temp_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>predicted_list_val<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        index_label_prediction_list<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>temp_list<span class=\"token punctuation\">)</span>\n        temp_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h4 id=\"예제-9-1-c2-a2-img-출력\" style=\"position:relative;\">예제 9-1 C2, A2 img 출력<a href=\"#%EC%98%88%EC%A0%9C-9-1-c2-a2-img-%EC%B6%9C%EB%A0%A5\" aria-label=\"예제 9 1 c2 a2 img 출력 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>return 값의 shape과 type, 형상을 봐야한다</li>\n</ul>\n<p>노드가 정의돼 있다면 return 값 알고 싶다면 sess.run만 실행하면 된다. X data에 대해 F2, C2, A2를 실행하면,</p>\n<p>elapsed time\n= 0:01:13.558847<br>\n========================================<br>\nF2<em>ret</em>val.shape = (3, 3, 1, 32) ,<br>\nC2<em>ret</em>val.shape = (10000, 28, 28, 32) ,<br>\nA2<em>ret</em>val.shape = (10000, 14, 14, 32)<br>\n========================================</p>\n<p>=> 10000, 28, 28, 32 ? 입력데이터 수, size, size, feature 수</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># conv_ret_val_list[0] => 1st conv layer</span>\n<span class=\"token comment\"># [9, :, :, 15] => 16번째 필터에 의해 컨볼루션 연산된 28 x 28 크기의 10번째 이미지 (즉, test_x_data[9] 데이터를 나타냄)</span>\nplt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>conv_ret_val_list<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">15</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>=> [9, :, :, 15] ?<br>\n10000개 img 중 10번째에 대해 16번째 filter가 feature를 뽑아낸 결과인 (28x28) 모든 pixel을 출력하라는 의미\n​</p>\n<hr>\n<h4 id=\"예제9-2-3conv-cs-as-img-출력\" style=\"position:relative;\">예제9-2 3conv Cs, As img 출력<a href=\"#%EC%98%88%EC%A0%9C9-2-3conv-cs-as-img-%EC%B6%9C%EB%A0%A5\" aria-label=\"예제9 2 3conv cs as img 출력 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>for문에 넣어 layer, image 별 C, A image 출력할 수 있다.</p>\n<p>cf. subplot을 써서 여러 개 같이 출력할 수도 있다.</p>\n<hr>\n<h3 id=\"tensorflow-20\" style=\"position:relative;\">Tensorflow 2.0<a href=\"#tensorflow-20\" aria-label=\"tensorflow 20 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>TF 1 버전 대에 비해 user-friendly하며, code 직관성을 높이고 디버깅을 쉽게 할 수 있는 eager execution 적용되었다.</p>\n<h4 id=\"tensorflow-20-주요-특징\" style=\"position:relative;\">TensorFlow 2.0 주요 특징<a href=\"#tensorflow-20-%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95\" aria-label=\"tensorflow 20 주요 특징 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>(1) eager execution 즉시실행모드 : session 이 필요 없고, python처럼 그때그때 실행된다.<br>\nlazy evaluation 형태로 코드를 짤 수 있긴 하나 그닥 쓰진 않는다.<br>\n= 프로그램 중간 중간 print 문 등을 넣어 언제든 동작 방식을 확인할 수 있다 = interactive 방식<br>\n​\ncf. 1 버전대는 lazy evaluation 방식 = complexity 증가 performance 증가 (소스 코드가 복잡하나 속도가 빠르다)<br>\n= batch script 이런 방식은 perform 증가하나 debugging이 어렵다 = none-interactive 방식 = 대화형이 아니다 쭉 진행하면 끝</p>\n<p>(2) keras = google에서 유일한 api로 선정했다. (tf.keras 사용 권장)</p>\n<p>(3) api cleanup = tf.placeholder 삭제, tf.contrib 삭제 등<br>\n(placeholder : session 내에서 외부 입력 받을 때 사용했으나 session이 없어져서 같이 소멸한 것으로 보임.)<br>\ncf. contrib = RNN / LSTM / GRU 사용되는데, 2 버전으로 오면서 삭제돼 새로 짜야된다.</p>\n<ul>\n<li>상수 - tf.constant : tf는 기본 데이터 타입이 tensor. 2 버전대에서는 sess.run 대신 .numpy() 붙이면 값이 나온다.  </li>\n<li>변수 - tf.Variable : 2 버전대에서는 변수 정의 시 자동 초기화된다. 초기화 소스 코드가 필요 없다.  </li>\n<li>placeholder 삭제 : 값을 리턴해 주니까 2 버전 대에서는 함수로 표현하면 된다.  </li>\n</ul>\n<hr>\n<h3 id=\"keras\" style=\"position:relative;\">Keras<a href=\"#keras\" aria-label=\"keras permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>cpu/gpu/tpu &#x3C;=> TF (backend) &#x3C;=> Keras (HighLevel Api) &#x3C;=> User<br>\n= TF는 하나의 백엔드처럼 동작하고 Keras가 API로 user가 사용</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> keras <span class=\"token keyword\">import</span> models <span class=\"token operator\">=</span> native keras</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>이러한 native 없어질 거라 아래와 같은 방식의 tf.keras 사용을 권장한다.\n​</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras <span class=\"token keyword\">import</span> <span class=\"token operator\">~</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Keras는 model 바탕으로 architecture 설계한다.</p>\n<p>model = 입력층, 은닉층, 출력층 각 layer를 포함하는 프레임 워크로,<br>\nmodel 생성 후, 각 layer를 add하면 된다.<br>\n(cf. java gui 설계 = canvas + textbox + label ...)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">model <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모델 생성 => layer 코드 순서대로 add된다</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 층 추가</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 층 추가</span>\n\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 손실함수 지정</span>\n                   <span class=\"token comment\"># 옵티마이저 지정</span>\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># ! 생략 가능</span>\n\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 학습 진행</span>\n\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nload_model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>Sequential API는 케라스의 함수형 API(Keras Functional API) 의 일종이다.  </p>\n<p>입력 ~ 출력까지 데이터 가는 거는 feed forward => sequential</p>\n<ul>\n<li>ML       = 데이터 정의 / w, b초기화 / y, loss 계산식 / 학습 for</li>\n<li>KERAS ML = data 정의 / model 정의 아키텍처 설계 / model.compile() / model.fit()\n​</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 입력층</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'linear'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 출력층</span>\n\n<span class=\"token comment\"># 이렇게 1줄로 표현해도 된다.</span>\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'linear'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>처음에는 Flatten을 쓰나, 앞뒤로 연결된 경우에는 Dense를 쓴다.</p>\n<p>model.add(Dense(1, activation='linear')) => 1 출력에서 나가는 거를 말한다.<br>\n입력층과 붙어있는 애만 input_shape을 쓴다. add 앞뒤로 연결한다는 의미다.</p>\n<p>Dense 안에 W, b가 들어 있다. 이렇게 keras는 자동으로 param을 만들어준다.<br>\nadd 할 때마다 w, b가 자동으로 초기화된다.</p>\n<ul>\n<li>compile = loss func, learning rate, SGD 미분 정의</li>\n</ul>\n<p>model.compile 이후 보통 model.summary를 쓴다\nw = (1,1) b = (1) => parma 수 2개</p>\n<ul>\n<li>fit = for W, b update</li>\n</ul>\n<hr>\n<h4 id=\"예제1-linear-regression\" style=\"position:relative;\">예제1 Linear Regression<a href=\"#%EC%98%88%EC%A0%9C1-linear-regression\" aria-label=\"예제1 linear regression permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>입력노드3 정답노드1 로 답은 숫자니까 LR이다.</p>\n<h4 id=\"-modelweights\" style=\"position:relative;\">* model.weights<a href=\"#-modelweights\" aria-label=\" modelweights permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>[&#x3C;tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32, numpy= array([[ <strong>1.9999089</strong>], [<strong>-3.0000947</strong>], [ <strong>1.9999369</strong>]], dtype=float32)>, &#x3C;tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([<strong>0.00061585</strong>], dtype=float32)>]</p>\n<p>=> 가중치 W 3개 값  1.9999089, -3.0000947,  1.9999369 과 bias 0.00061585 값 을 확인할 수 있다.</p>\n<h4 id=\"-histhistory\" style=\"position:relative;\">* hist.history<a href=\"#-histhistory\" aria-label=\" histhistory permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">&lt;class &#39;tensorflow.python.keras.callbacks.History&#39;&gt;  \ndict_keys([&#39;loss&#39;])  </code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>​\n=> hist.history = dictionary 타입으로, keys:loss values:loss_val 는 기본적으로 들어 있다.</p>\n<p>compile 안에 ,metrics=['accuracy'] 를 쓰면, hist에 새로운 keys : accuracy 에 대한 dict이 추가된다.</p>\n<p>예전 소스 코드에서 for 문에서 feed_ 안에 loss_val.append() 썼던 게 keras의 hist라 보면 된다.</p>\n<h4 id=\"-modelinput-modeloutput\" style=\"position:relative;\">* model.input, model.output<a href=\"#-modelinput-modeloutput\" aria-label=\" modelinput modeloutput permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>output<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>weights<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>Tensor(\"flatten_input:0\", shape=(None, 3), dtype=float32)<br>\nTensor(\"dense/BiasAdd:0\", shape=(None, 1), dtype=float32)<br>\n[&#x3C;tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32, numpy= array([[ 2.0000443], [-2.9999547], [ 2.000029 ]], dtype=float32)>, &#x3C;tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([-0.00029324], dtype=float32)>]  </p>\n<p>​=> 각 layer에서의 tensor shape 을 알 수 있다.</p>\n<p>layer[0]의 output => c2가 나온다, 쉽다...!</p>\n<ul>\n<li>classification 분류에서는 accuracy를 보통 써준다.</li>\n<li>model.fit 에서 verbose=2를 쓰면, 모든 정보를 표시한다.</li>\n<li>model.evaluate(x<em>data, t</em>data) 모델 정확도 평가</li>\n</ul>\n<p>​activation sigmoid -> relu, tanh<br>\nloss binary<em>crossentropy      ///     mnist categorical</em>crossentropy ~<br>\noptimizer = SGD -> AdaGrid, adam<br>\nvalidation_split = 0.2 -> 0.3  (cf. DataGeneration np.random.shuffle 사용)</p>\n<p>​___</p>\n<h4 id=\"예제2-index-label-prediction-list-by-list-comprehension\" style=\"position:relative;\">예제2 index label prediction list by list comprehension<a href=\"#%EC%98%88%EC%A0%9C2-index-label-prediction-list-by-list-comprehension\" aria-label=\"예제2 index label prediction list by list comprehension permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">real_prediction_val <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">)</span>\nlogical_prediction_val <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>real_prediction_val <span class=\"token operator\">></span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># [[True], [False], ... ]</span>\n\nlogical_prediction_val <span class=\"token operator\">=</span> logical_prediction_val<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token string\">'float32'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 2차원 -> 1차원</span>\nlabel <span class=\"token operator\">=</span> t_data<span class=\"token punctuation\">.</span>flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncomp_result <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span>label<span class=\"token punctuation\">,</span> logical_prediction_val<span class=\"token punctuation\">)</span>\n\nindex_label_prediction_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span> <span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">,</span> label<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> logical_prediction_val<span class=\"token punctuation\">[</span>idx<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">]</span>  <span class=\"token keyword\">for</span> idx<span class=\"token punctuation\">,</span> value <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>comp_result<span class=\"token punctuation\">)</span>  <span class=\"token keyword\">if</span> value <span class=\"token operator\">==</span> <span class=\"token boolean\">False</span> <span class=\"token punctuation\">]</span>\n\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>index_label_prediction_list<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#18%EC%9D%BC%EC%B0%A8\">18일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C8-3conv-pool-%EC%A0%9C%EA%B1%B0--index-label-list\">예제8 3conv pool 제거 &#x26; index label list</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C-9-1-c2-a2-img-%EC%B6%9C%EB%A0%A5\">예제 9-1 C2, A2 img 출력</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C9-2-3conv-cs-as-img-%EC%B6%9C%EB%A0%A5\">예제9-2 3conv Cs, As img 출력</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#tensorflow-20\">Tensorflow 2.0</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#tensorflow-20-%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95\">TensorFlow 2.0 주요 특징</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#keras\">Keras</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C1-linear-regression\">예제1 Linear Regression</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#-modelweights\">* model.weights</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#-histhistory\">* hist.history</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#-modelinput-modeloutput\">* model.input, model.output</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-18%EC%9D%BC%EC%B0%A8/#%EC%98%88%EC%A0%9C2-index-label-prediction-list-by-list-comprehension\">예제2 index label prediction list by list comprehension</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 18일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-18일차/"}},"staticQueryHashes":[]}