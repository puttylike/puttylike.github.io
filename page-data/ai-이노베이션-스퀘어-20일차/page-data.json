{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-20일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"20일차\" style=\"position:relative;\">20일차<a href=\"#20%EC%9D%BC%EC%B0%A8\" aria-label=\"20일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>마지막 날이라 오늘은 오전까지 진행되었다. 지금까지 배운 내용을 정리하고, Next AI 그간의 ai 역사와 현재 기준 이슈 ai trend 그리고 차세대 ai에 대해 배웠다. 유튜브 전이학습 TF 2.0 영상을 기대하며.. 고급반 기다려야지. ㅠ</li>\n<li>12월에 뭐할까 생각은 했는데, 빅데이터 분석기사 뭔가 안 끌리는데 접수는 했으니 공부를 시작해야겠다.  </li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Fairness AI > mission Critical</li>\n</ul>\n<hr>\n<h4 id=\"dropout\" style=\"position:relative;\">dropout<a href=\"#dropout\" aria-label=\"dropout permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>(예제7-2,7-5)  </p>\n<ul>\n<li>dropout은 overfitting 방지 기법 중 하나로, conn 뒤 flatten 다음부터<br>\n일반신경망 dense - dropout 순으로 진행된다.</li>\n<li>flatten이 입력, 출력층을 출력이라 보면, 가운데 있는 drop은 일반신경망의 은닉층이라 볼 수 있다.<br>\n=>> 그 안에 dropout 몇개가 오든 상관없다.</li>\n<li>ftlatten dense dropout 사이 dense를 없애는 게 문법적으로는 된다만, (dense 없어도 실행된다.)<br>\n입력이 누락되니 dense를 쓰는게 맞다.</li>\n<li>dense를 하나 더 줬다는 건 은닉층하나 더 준 거니까,<br>\ndense 1개 512였다면, dense 2개 줄 거면 64. 64 이렇게 512보다 작아야 한다.</li>\n</ul>\n<hr>\n<h4 id=\"summary\" style=\"position:relative;\">summary<a href=\"#summary\" aria-label=\"summary permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>(1) python<br>\ndatatype  </p>\n<ul>\n<li>list, slicing ★  </li>\n<li>string 안에저장된 애 자체도 문자열이다 split return type list / strip<br>\nlist comprehension<br>\n[ for ]<br>\nenumerate ★  return index, value  </li>\n</ul>\n<p>​(2) function<br>\nmutable [ ] / immutable<br>\nlambda  C언어 # define 대체효과  </p>\n<p>(3) class<br>\noop contept  </p>\n<ul>\n<li>encapsulation [information hiding] <strong>=> C++은 만족X oop 아님</strong>  </li>\n<li>inheritance  </li>\n<li>polymorphism  </li>\n</ul>\n<p>cf. in C++</p>\n<div class=\"gatsby-highlight\" data-language=\"c++\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-c++ line-numbers\"><code class=\"language-c++\">class Person;\nobj = Person();\nPerson * ttt = &amp;obj;\ndelete ttt; // ttt가 가르키는 곳 지워라 데이터 통으로 날아가서 encapsulation 만족 안 딤</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span></span></pre></div>\n<p>​\nclass => exception : 내 의도와 상관없이 발생할 수 있어서 필요하다.</p>\n<ul>\n<li>IO, 네트워크  </li>\n<li>exception은 caller 호출하는 곳에서 처리<br>\n발생하는 곳에선 throw 해야 한다 => class 내부를 고치기 시작하면 다 고쳐야 해서 그렇다.</li>\n</ul>\n<p>​(4) numpy  </p>\n<p>(5) 미분  </p>\n<ul>\n<li>aE/aW => w가 미세하게 변할 떄 E가 얼마나 변할까</li>\n</ul>\n<p>​(6) ML  </p>\n<ul>\n<li>Linear Regression  </li>\n<li>Logistic Regression => XOR 안풀려서=> Deep Learning</li>\n</ul>\n<p>(7) DL</p>\n<ul>\n<li>I ~ H ~ O => 미분 넘 오래 걸려서 => Back Propagation\ncf. Xavier/He</li>\n</ul>\n<p>​(8) Tensorflow</p>\n<ul>\n<li>\n<p>TF 1.x => legacy  </p>\n<ul>\n<li>node / session  </li>\n</ul>\n</li>\n<li>\n<p>TF 2.x  </p>\n<ul>\n<li>eager execution  </li>\n<li>keras  </li>\n</ul>\n</li>\n</ul>\n<p>​(9) CNN  </p>\n<ul>\n<li>tensor input type  </li>\n<li>\n<p>filter : feature extraction  </p>\n<ul>\n<li>\n<p>$f(t) * g(t) = ∫f(τ)*g(t-τ) dτ$  </p>\n<ul>\n<li>$*g(t-τ)$ : variation 관점</li>\n<li>∫ = 평균</li>\n<li>∫f(τ)*g(t-τ) dτ = t에 대한 함수 => time shift 개념</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"next-ai\" style=\"position:relative;\">NEXT AI<a href=\"#next-ai\" aria-label=\"next ai permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h4 id=\"인공지능-역사\" style=\"position:relative;\">인공지능 역사<a href=\"#%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EC%97%AD%EC%82%AC\" aria-label=\"인공지능 역사 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>​- 1차 암흑기 XOL => DL로 해결<br>\n​- 2차 암흑기 고유지비용 / 회의감 등 => 오차역전파로 해결  </p>\n<ul>\n<li>2012년 alexnet CNN<br>\ncf. 알파고 DQN = CNN + 강화학습  </li>\n</ul>\n<p>​</p>\n<hr>\n<h4 id=\"현재-state-of-the-art---강화학습transfer-learninggan\" style=\"position:relative;\">현재 state of the art - 강화학습/transfer learning/GAN​<a href=\"#%ED%98%84%EC%9E%AC-state-of-the-art---%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5transfer-learninggan\" aria-label=\"현재 state of the art   강화학습transfer learninggan permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>전이학습 Transfer Learning 이 실제 실무에서 가장 많이 쓰인다.\n계속 연구중인 건 강화학습, 그리고 발전여부가 ?인 (?????) GAN</p>\n<h5 id=\"gan-적대적-생성-신경망\" style=\"position:relative;\">GAN 적대적 생성 신경망<a href=\"#gan-%EC%A0%81%EB%8C%80%EC%A0%81-%EC%83%9D%EC%84%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D\" aria-label=\"gan 적대적 생성 신경망 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>cf. 오바마 gan</p>\n<p>원본data와 noise 간의 비슷한 image 생성\n비슷하다는 건 loss min이란 거</p>\n<p>image를 아주 조금 바꿔 loss가 얼마나 변하나<br>\nimg = img - a aloss/aimg<br>\nimage 백지이면 점 찍는 식<br>\nimg가 비슷해 진다 loss가 작다<br>\nloss가 0.01 , 0.02 , 0.009 ... 생성 이미지가 조금씩 바귄다.<br>\nGAN 1개에 3~4일ㅠㅠ  </p>\n<ul>\n<li>GAN이 바로되는 건 GAN에 Transfer learning이 더해졌기 때문.</li>\n</ul>\n<h5 id=\"transfer-learning-전이학습\" style=\"position:relative;\">transfer learning 전이학습<a href=\"#transfer-learning-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5\" aria-label=\"transfer learning 전이학습 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>CNN 정확도를 높이려면 레이어 추가해야 하는데, 시간이 오래 걸린다. (일일이 add 언제 add 하냐)  </p>\n<p>feature extraction = filter => set of weights<br>\nimg feature는 정해져 있다 = / - | RGB...<br>\nfeature를 뽑으려면 filter가 있어야 하고 weights 는 학습의 대상이다.  </p>\n<p>처음부터 add 구축하는 게 아니라 갖다 쓰면 괜찮지 않나?<br>\n<strong>전이학습 = pre trained model을 가져다쓰는 것</strong>  </p>\n<p>Google Inception-v3 layer 60개<br>\n최고의 성능 Ms ResNet layer 152개  </p>\n<p>cf. <a href=\"https://www.tensorflow.org/hub\">tensorflow hub</a><br>\nmodel > tfhub.dev problem domain ... => m.fit하면 된다  </p>\n<p>cf .transfer learning 인강</p>\n<p>처음부터 구축하면 너무 오래 걸리니 갖다 써서 튜닝하는 것도 하나의 방법이다.</p>\n<h4 id=\"차세대-ai---xai--fairness-ai--vtt\" style=\"position:relative;\">차세대 AI - XAI / Fairness AI / VTT<a href=\"#%EC%B0%A8%EC%84%B8%EB%8C%80-ai---xai--fairness-ai--vtt\" aria-label=\"차세대 ai   xai  fairness ai  vtt permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<h5 id=\"xai-explainable-ai\" style=\"position:relative;\">XAI explainable AI<a href=\"#xai-explainable-ai\" aria-label=\"xai explainable ai permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>안에서 무슨 일이 벌어지는 지는 모르지만 여태까지 숫자(소숫점) 로 판단했다.<br>\n정답과 판단 근거를 text 형태로 제시 = XAI<br>\n=> 언어로 매핑시키는 레이어가 필요해져서 연구  </p>\n<p>ex) asis 고양이 97% 손실 0.0001<br>\ntobe => 고양이 = 발톱 털 4발 ...  </p>\n<ul>\n<li>mission critical 금융 의료 분야 등 다양한 분야에서 확산되며 XAI 필요성이 대두되었다.<br>\nex) 암 확률 91%인데 근거는 종양이 어떻고 시간이 어떻고...<br>\nex) 주식이 오를 확률이 92%인데 근거는 ..  </li>\n</ul>\n<p>cf. XAI는 KAIST에서 최재식 교수님이 연구 중이다.</p>\n<h5 id=\"fairness-ai\" style=\"position:relative;\">Fairness AI<a href=\"#fairness-ai\" aria-label=\"fairness ai permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>data의 fair함에 대해 기준을 세우는 분야<br>\n언어학자도 참여 필요.. 언어는 발전하니까.<br>\n아직 참고할 만한 곳이 거의 없음.  </p>\n<p>cf. AMAZON REKOGNITION<br>\n흑인에 대한 bias 존재 > data contamination 등 문제로 &#x3C; 사람 input에 고릴라 output.. ;;  </p>\n<p>​cf. MS Tay 테이 채팅봇<br>\n데이터 수집 단계에서 필터기능이 있어야 하는 문제? 아니... 필터 자체가 bias...  </p>\n<h5 id=\"vtt-video-turing-test\" style=\"position:relative;\">VTT (video turing test)<a href=\"#vtt-video-turing-test\" aria-label=\"vtt video turing test permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>영상 분석<br>\n​영상 = 이미지 연속  </p>\n<hr>\n<p>내용 정리  </p>\n<ul>\n<li>실무에서 transfer learning을 많이 쓴다.</li>\n<li>VTT 가장 갈 길이 멀다.</li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#20%EC%9D%BC%EC%B0%A8\">20일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#dropout\">dropout</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#summary\">summary</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#next-ai\">NEXT AI</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EC%97%AD%EC%82%AC\">인공지능 역사</a></li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#%ED%98%84%EC%9E%AC-state-of-the-art---%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5transfer-learninggan\">현재 state of the art - 강화학습/transfer learning/GAN​</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#gan-%EC%A0%81%EB%8C%80%EC%A0%81-%EC%83%9D%EC%84%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9D\">GAN 적대적 생성 신경망</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#transfer-learning-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5\">transfer learning 전이학습</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#%EC%B0%A8%EC%84%B8%EB%8C%80-ai---xai--fairness-ai--vtt\">차세대 AI - XAI / Fairness AI / VTT</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#xai-explainable-ai\">XAI explainable AI</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#fairness-ai\">Fairness AI</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-20%EC%9D%BC%EC%B0%A8/#vtt-video-turing-test\">VTT (video turing test)</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 20일차 후기 (last)"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-20일차/"}},"staticQueryHashes":[]}