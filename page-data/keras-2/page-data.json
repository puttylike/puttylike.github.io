{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/keras-2/",
    "result": {"data":{"markdownRemark":{"html":"<hr>\n<h3 id=\"cnn\" style=\"position:relative;\">CNN<a href=\"#cnn\" aria-label=\"cnn permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>cf. 이태영님<br>\n금융공학을 인공지능에 접목하는 연구를 하는 중</p>\n<ul>\n<li>해결 방법</li>\n</ul>\n<ul>\n<li>under fitting - activation function</li>\n<li>slow - learning rate ...</li>\n<li>over fitting - drop out</li>\n</ul>\n<ul>\n<li>\n<p>swish - google에서 개발한 activation function</p>\n</li>\n<li>\n<p>CNN의 변천사</p>\n</li>\n</ul>\n<p>cf. ResNet을 많이 쓴다<br>\nSENet<br>\n=> ResNet에서 변형하는 형태\r\n=> 결국 백본이 중요</p>\n<p>이미지 - 오픈cv 중요</p>\n<ul>\n<li>field trend</li>\n</ul>\n<p>a-z를 다 만들기 보다 pretrained 모델된 걸 가져와서 커스터마이징ㅇㅇ<br>\n도메인에 대한 이해가 있어야 적용 가능한지 체크가 가능하다<br>\n백본이 있어야 응용 가능하고<br>\nex. 금융이면 금융에 어떻게 적용할지 이해를 할 수 있어야..</p>\n<ul>\n<li>ZFNet Code</li>\n</ul>\n<p><a href=\"https://paperswithcode.com/method/zfnet\">https://paperswithcode.com/method/zfnet</a></p>\n<h4 id=\"cnn-1\" style=\"position:relative;\">CNN<a href=\"#cnn-1\" aria-label=\"cnn 1 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>conv : feature extraction layer의 일종</li>\n</ul>\n<p>cf. filter : detect 하려는 feature 내용이 담긴 사각형<br>\ncf. repective filter : 이미지 위를 filter size로 rolling하며 detect 되는 실제 feature\r\ncf. activation map (feature map) : 해당 repective field 에 filter에서 detect 하고자 하는 feature 가 있는지 없는지 알려줌</p>\n<ul>\n<li>pool : sub sampling 목적</li>\n</ul>\n<p>ex. max pooling</p>\n<p>cf. 네이버 - E2E 모델 방식<br>\nText detection -> Text Recognition -> Text Parsing</p>\n<h4 id=\"cnn-아키텍처\" style=\"position:relative;\">CNN 아키텍처<a href=\"#cnn-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98\" aria-label=\"cnn 아키텍처 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>AlexNet</li>\n<li>VGG</li>\n<li>GoogLeNet</li>\n<li>ResNet</li>\n</ul>\n<ul>\n<li>GoogLeNet</li>\n</ul>\n<p>성능 향상에 집중하는 것</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#cnn\">CNN</a></p>\n<ul>\n<li><a href=\"#cnn-1\">CNN</a></li>\n<li><a href=\"#cnn-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98\">CNN 아키텍처</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"keras 특강 - CNN"}}},"pageContext":{"slug":"/keras-2/"}},
    "staticQueryHashes": ["3159585216"]}