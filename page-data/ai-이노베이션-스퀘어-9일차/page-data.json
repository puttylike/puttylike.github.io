{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-9일차/",
    "result": {"data":{"markdownRemark":{"html":"<h3 id=\"9일차\" style=\"position:relative;\">9일차<a href=\"#9%EC%9D%BC%EC%B0%A8\" aria-label=\"9일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>일주일 내내 야근했더니 이제야 새로운 글을 올릴 수 있게 되었다. 다음 주엔 꼭 뭐라도 글 올리고 싶다. 이전 글에 수식이랑 코드도 수정하고 싶고.</p>\n<p>오늘 강의를 통해 XOR을 지나, 드디어 딥러닝에 진입했다. 예전에 배웠을 때 코딩을 별로 안 해서 지금처럼 python으로 내부 로직을 다 만드는 게 생소하고 어렵다. 하지만, 무엇보다 재미있다.</p>\n<p>feed forward 개념, 딥러닝 아키텍처 구성 등 개념 정리 좀 해야겠다ㅠ</p>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>XOR insight</li>\n<li>활성화 함수 insight</li>\n</ul>\n<hr>\n<h3 id=\"1-문제-풀이-시간에-배운-점-logistic-regression-예제\" style=\"position:relative;\">1. 문제 풀이 시간에 배운 점 (Logistic Regression 예제)<a href=\"#1-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4-%EC%8B%9C%EA%B0%84%EC%97%90-%EB%B0%B0%EC%9A%B4-%EC%A0%90-logistic-regression-%EC%98%88%EC%A0%9C\" aria-label=\"1 문제 풀이 시간에 배운 점 logistic regression 예제 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>​\r\n예제3-2.<br>\n간단한 디자인 패턴, 생성자에 기본적으로 저장한다지만, 저장data가 크면 객체 생성 시 마다 낭비가 될 테니, 또다른 메서드에서 param으로 받자.</p>\n<p>cf. 디자인 패턴<br>\n지난 시간에 고민했던 클래스 입력 파라미터 설정 방법 등이 여기 해당된다. 파라미터는 일반적으로 내부에 저장을 한다. SW 설계 시 최소의 메모리로 성능을 높일까에 대한 고민을 하는데, 도움을 주는데 중급 이상 권장한다고.</p>\n<ul>\n<li>단, 5%마다 출력할 때 int로 type casting 해야 한다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">step <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.05</span><span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>iteration_count<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>여기서 cnt가 177번일 수도 있으니까. 어떤 값으로 나누기 하려면, 필요하다.</p>\n<hr>\n<h3 id=\"2-xor-문제\" style=\"position:relative;\">2. XOR 문제<a href=\"#2-xor-%EB%AC%B8%EC%A0%9C\" aria-label=\"2 xor 문제 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>ML에서 Linear Regression은 continuous 값을, Logistic Regression은 discrete 값을 다뤘다. 하지만 이거 2개로는 한계가 있다.</p>\n<p>대표적인 반례로는 XOR 문제가 있다. 그래서 나온 게 딥러닝이다.</p>\n<ul>\n<li>​AND 둘다 1이면 1</li>\n<li>OR 둘다 0이면 0</li>\n<li>NAND 둘다 1이면 0</li>\n<li>XOR 같으면 0</li>\n</ul>\n<p><del>cf. 자동문 AND / 암호 not XOR / NAND 전화번호 카톡 sms... NAND FLASH > SSD</del></p>\n<p>XOR의 경우, 데이터 view point에서 보면 입력 data 2개, 정답 data 1개다.<br>\n정답이 0, 1 뿐이니 얼핏 봐선 logistic regression일까 싶어 보이기도 하다.</p>\n<p>\"hyper parameter is dependent on data.\"</p>\n<p>손실 함수가 줄어들지도 않고 hyper parameter를 바꿔도 변화가 없고, 손실함수 최소값인가 했는데 정확도도 50% 겨우 정도에서 그친다.​</p>\n<p>그래프 상에서 XOR을 표현하려면 선이 2개 필요하다.</p>\n<p>마빈 민스키는 XOR 문제는 수학적으로 풀 수 없다를 증명했다. 이후, AI 암흑기가 찾아 오기도 했다.<br>\ncf. XOR 문제 by 마빈 민스키 - <a href=\"https://www.amazon.com/Perceptrons-Introduction-Computational-Geometry-Expanded/dp/0262631113\">책, 퍼셉트론 : Perceptrons: An Introduction to Computational Geometry, Expanded Edition</a></p>\n<p>=> 다음과 같이, AND, OR, NAND 조합하여 XOR을 구현할 수 있다.</p>\n<p>NAND\r\n↘\r\nAND\r\n↗\r\nOR</p>\n<ul>\n<li>insight ?</li>\n</ul>\n<p>NAND / OR / AND 의 공통점 : 1개의 Logistic Regression로 표현할 수 있다.<br>\n​\r\ncf. FC Fully connection (완전 연결) : 이전 출력이 모두 다음의 입력으로 들어가는 것</p>\n<p>=> multi-layer LR을 적절하게 조합하면, 안 풀리던 XOR도 풀린다.<br>\n​= 딥러닝의 핵심 idea</p>\n<p>​XOR처럼 ML로 안 풀리는 문제를 DL로 풀 수 있다. DL은 성능 차이 떄문이 아니라, ML의 한계 때문에 쓰게 되었다.</p>\n<p><strong>딥러닝은 Multi-Layer 를 가지며, 각각의 Gate는 Logistic System(Regression + Classification)으로 구성되고, 이전 Gate의 모든 출력은 다음 Gate의 입력으로 쓰인다.</strong></p>\n<ul>\n<li>XOR 코딩\n<ul>\n<li>NAND, OR, AND obj 생성</li>\n<li>학습</li>\n<li>연결</li>\n<li>s1, s2, y</li>\n</ul>\n</li>\n</ul>\n<p>​cf. 코딩은 복잡했다만, 딥러닝에서는 이걸 hidden layer로 쉽게 구현한다.</p>\n<hr>\n<h3 id=\"3-딥러닝-deep-learning\" style=\"position:relative;\">3. 딥러닝 Deep Learning<a href=\"#3-%EB%94%A5%EB%9F%AC%EB%8B%9D-deep-learning\" aria-label=\"3 딥러닝 deep learning permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>(1) 뉴런</p>\n<p>혼자 알러지가 있다면, 남들보다 느껴지는 가중치가 크다는 의미다.<br>\n모든 입력에는 가중치가 있어 사람마다 다르게 반응한다고 보면, 뉴런으로 연결된 신경망은 XOR과 구조가 유사하다.</p>\n<p>​(2) 활성화 함수 Activation function</p>\n<p>데이터 분류를 위해 변곡점 가진 함수이다.\r\n특정 값이 넘어야만 출력하게 하는 식으로 값을 분류한다.</p>\n<ul>\n<li>insight</li>\n</ul>\n<p>​변곡점이 있다면, 활성화 함수를 쓸 수 있다.<br>\n다만, 변곡점 threshold (임계점) 기준으로 2가지 분류만 가능하다.</p>\n<p>=> 그럼 5개는 어떻게 나눌까?<br>\n활성화함수를 쓰려면 변곡점 기준으로 나눌 수 있어야 하는데, sigmoid 를 y 값에 따라 5개로 쪼개는 건 무의미하다.</p>\n<p>그래서 이런 거는 one-hot encoding으로 분류한다. 변곡점 있는 함수가 몇 없고... 그래서 나온 아이디어이다.</p>\n<ul>\n<li>활성화 함수 예\n<ul>\n<li>ReLU : $$ = max(0, x)$$</li>\n<li>sigmoid : $$ = 1 / (1 + e^(-x))$$</li>\n<li>tanh : $$ = (e^x - e^(-x)) / (e^x + e^(-x)) = (e^(2x) - 1) / (e^(2x) + 1)$$​</li>\n</ul>\n</li>\n</ul>\n<p>​cf. tanh 자연어처리 / sigmoid 성능 / reLu 속도 => hyper parameter</p>\n<p>(3) 신경망(Neural Network) – architecture</p>\n<p>입, 출력은 정해져 있다.</p>\n<p>cf. CNN / RNN / FRCNN / SRCNN ... : 입출력은 같은데, hidden layer가 제각각이다.</p>\n<p>cf. 이전 층 출력이 다음 층으로 전달될 때 가중치 전달, feed forward...</p>\n<p>히든 레이어를 많이 둘수록, 노드를 많이 만들거나 할 수록 정확도가 올라간다. 그래서 deep Learning이다만, 정확도가 높아지면, (시간이 오래 걸린다) 성능이 떨어진다</p>\n<p>노드 하나는 하나의 Logistic Regression을 뜻한다. ​node 수만큼 hyper parameter를 둔다.</p>\n<p>​(현재 강의 기준,) 입력층의 노드는 정답을 만들어내는 입력 data 갯수만큼 필요하다.<br>\n은닉층 노드 갯수는 hyper parameter, 은닉층 갯수도 hyper parameter로 직접 설정해야 한다.</p>\n<p>(관습적) 입력층 드갈 땐 가중치 없이 그대로 통과한다. 레이어의 일관성을 위해라나.</p>\n<ul>\n<li>가중치 notation 표기법</li>\n</ul>\n<p><strong>다음 계층의 노드 번호가 먼저 나온다.</strong></p>\n<p>ex. $$W_2 $$ $$_1$$ 노드 1에서 2로 전달되는 신호를 강화시키는 가중치이다.</p>\n<p>ex. $$W^(2)$$ $$_n $$ , $$_c$$</p>\n<p>위에 적힌 (2)는 계층 번호이고, (2번째 계층 앞에 있는 가중치라는 것)<br>\n아래 적힌 n, c 는 현재 계층의 노드c에서 다음 계층의 노드 n으로 전달된다는 의미다.</p>\n<p>딥러닝은 w 갯가 많아서 오래 걸린다.<br>\nb는 노드 당 1개 per node 존재하고, w는 노드 사이 between node 존재한다.​</p>\n<p><strong>★ data 정의 / Y 값 계산 / 오차 계산 / W, b 업데이트</strong></p>\n<p>cf. 강화학습은 data 정의에 포커스를 둔다.</p>\n<p>(4) 딥러닝 구조</p>\n<p>1개의 입,출력 계층과 n개의 은닉층 계층이 ㅈㄴ재한다.</p>\n<p>입력부터 출력까지의 전파 propagation 과정 = 데이터 흐름 feed forward<br>\n한 계층에서의 W들을 행렬로 표기하면, 이전 층의 출력이 하나의 행이다.</p>\n<p>feed forward는 y를 만든다, 이후 y와 t를 비교하는데, 일반적으로 cross entropy 사용한다.</p>\n<p>이전에 만든 loss function 역할을 여기서는 feed forward가 한다.<br>\nfeed forward 과정을 반복하여 가중치와 b를 학습한다.\r\n​</p>\n<p>============<br>\nxor 인사이트 / 히든 레이어 역할 는 내일 강의에서 ..</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#9%EC%9D%BC%EC%B0%A8\">9일차</a></p>\n<ul>\n<li><a href=\"#%EB%A9%94%EB%AA%A8\">메모</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#1-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%9D%B4-%EC%8B%9C%EA%B0%84%EC%97%90-%EB%B0%B0%EC%9A%B4-%EC%A0%90-logistic-regression-%EC%98%88%EC%A0%9C\">1. 문제 풀이 시간에 배운 점 (Logistic Regression 예제)</a></p>\n</li>\n<li>\n<p><a href=\"#2-xor-%EB%AC%B8%EC%A0%9C\">2. XOR 문제</a></p>\n</li>\n<li>\n<p><a href=\"#3-%EB%94%A5%EB%9F%AC%EB%8B%9D-deep-learning\">3. 딥러닝 Deep Learning</a></p>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 12기 기본반 9일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-9일차/"}},
    "staticQueryHashes": ["3159585216"]}