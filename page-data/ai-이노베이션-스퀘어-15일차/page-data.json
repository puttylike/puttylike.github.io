{"componentChunkName":"component---src-templates-blog-post-js","path":"/ai-이노베이션-스퀘어-15일차/","result":{"data":{"markdownRemark":{"html":"<h3 id=\"15일차\" style=\"position:relative;\">15일차<a href=\"#15%EC%9D%BC%EC%B0%A8\" aria-label=\"15일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>Google Colab을 활용하여 Tensorflow 1 버전 대 (1.15.0) 사용법을 배웠다. 또한, TF를 통해 기존에 배웠던 걸 녹이는 시간을 가졌다. 잠깐 tf 배웠을 때는 1 버전 대만 있었는데, 작년에 2 버전 대가 나왔다니... 그저 신기하다.</li>\n<li>내일부터 드디어 고급의 첫 번째 과정 CNN에 들어간다...! 금일 colab을 써도 mnist 정확도가 95퍼 언저리였는데, 내일 CNN을 쓰면 99퍼가 나온다고 한다. CNN의 원리를 배운다고 하니 기대된다. 오차역전파 이후 간만에 A4 종이를 또 쓴다니. 흠.</li>\n<li>공모전 해봐야하나... 뭘 해야 하나 고민이다. 더 나아가기 위해 뭘 해야 하나. AI 이노베이션 고급 과정은 내년에 개설이 되려나. 교수님 유튜브라도 정주행 해야 하나 T.T 연차가 많이 남아 다시 주4일제를 시작했다. 회사 일도 빈익빈 부익부인가 싶고... 에휴. 회사 학점 채울 겸 공부할 겸 도커 docker 인강을 신청했다. 교수님이 도커 알아두랬으니까. (다음 달에 글 쓸 예정... ㅎㅎ )</li>\n</ul>\n<h4 id=\"메모\" style=\"position:relative;\">메모<a href=\"#%EB%A9%94%EB%AA%A8\" aria-label=\"메모 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Mount ?  </li>\n<li>Lazy evaluation ?  </li>\n</ul>\n<hr>\n<h3 id=\"tensorflow\" style=\"position:relative;\">Tensorflow<a href=\"#tensorflow\" aria-label=\"tensorflow permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>​\n지금까지 python으로 해서 개념, 원리를 익히는 건 좋았는데 실무에서 생산성이 떨어진다. 그래서 앞으로는 tf를 쓸 거다. tf 등등 DL 프레임워크에는 오차역전파가 내부적으로 잘 돼 있다.</p>\n<p>프랑슈아 숄레 keras 창시자가 구글에 입사하여 tf + keras 를 tf 2.0 에 통합시켜 놓았다. 이 tf 2 버전 대는 참고로 작년 9월에 나왔다.</p>\n<p>tf가 성능은 별로다. 성능은 pytorch나 ms가 개발하는 cntk가 더 좋다. 하지만, tf가 LinkedIn jobs in usa, # of git topics, stack overflow questions, paper on arxive 모두 제일 많으니 tf를 쓰든 안 쓰든 알아둬야 한다.</p>\n<ul>\n<li>tf 1.15.0 => tf 2.x (~2.3.0 ?)<br>\ntf 1이 기간이 더 오래돼 실무에서 legacy code를 modify 하려면, 1 버전을 알아야 할 필요가 있다. 논문 참고를 위해서도.</li>\n</ul>\n<p>cf. 1.15.0 => major version . minor version . stable/experimental  </p>\n<ul>\n<li>세 번째 숫자가 홀수면 테스트 짝수면 안정된 버전을 뜻한다.</li>\n<li>보통 첫 번째 숫자가 바뀌려면 아키텍처, 두 번째 숫자가 바뀌려면 기능 functionality 추가 등 이슈가 있다고.</li>\n<li>아키텍처가 바뀌었다는 건 완전히 새로운 거라는 거다.<br>\nex) 2.2.0 -> 2.3.1 기능이 추가됐는데 테스트 중이다.​</li>\n</ul>\n<p>cf. SMP (시메트릭 멀티프로세싱) 지원</p>\n<p>anaconda prompt cmd에서 다음의 명령어로 tensorflow를 설치할 수도 있겠다만,</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">pip install tensorflow==1.15</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>내 컴에 모든 걸 install 하는 standalone 상에서는, version miss match로 인해 타인과 co-work하기 힘들고, 설치를 하며 다양한 에러가 날 수도 있는 등등 다양한 문제들이 생길 수 있다.<br>\n=> 이 점은 cloud 상에서 작업을 하면 해결되는 문제.<br>\n=> google colab 을통해 cloud를 쓸 거다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\ntf<span class=\"token punctuation\">.</span>__version__ <span class=\"token comment\"># 1.15</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<hr>\n<h3 id=\"google-colab\" style=\"position:relative;\">Google colab<a href=\"#google-colab\" aria-label=\"google colab permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>Google Colaboratory (Colab)(<a href=\"https://colab.research.google.com\">https://colab.research.google.com</a>)은 gmail 계정으로 로그인하여 사용하면 된다. 1 버전 대, 2 버전 대 모두 쓸 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">!python <span class=\"token operator\">-</span>version <span class=\"token comment\"># python version 확인</span>\n<span class=\"token operator\">%</span>tensorflow_version <span class=\"token number\">1.</span>x <span class=\"token comment\"># 원하는 기능을 쓸 수 있게 버전 스위칭 기능이 있다</span>\n!pip install keras <span class=\"token comment\"># 필요한 library 설치</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<ul>\n<li>site 여러 개 띄워 놓은 경우, 앞에 colab과 뒤의 colab은 별개의 독립적인 개발환경이다.</li>\n<li>\n<p>Colab 메뉴의 ‘런타임’ -> ‘런타임 유형 변경’ -> ‘하드웨어 가속기’ 설정을 None 에서 GPU로\n변경하여 저장하면 GPU 를 사용할 수 있다. (TPU는 구글이 개발하는 거...)\n​</p>\n<hr>\n</li>\n<li>\n<p>Tensorflow : (기본 데이터 타입 3차원 이상인 tensor...) 텐서(Tensor)를 흘려 보내면서(Flow) 머신러닝과 딥러닝 알고리즘을 수행하는 라이브러리  </p>\n<ul>\n<li>tf 1.x : 노드 Node, 엣지 Edge 정의 (변수 함수 정의 등등도) => (print 등세션 실행 단계) Session 생성 및 실행으로 나뉜다.<br>\n=> lazy evaluation : 성능 ↑ but 프로그램 짜기가 좀 힘들다...</li>\n<li>노드 정의 : 값을 실제로 할당하는 게 아니라 넣을 공간을 만든다</li>\n<li>세션 : transaction 의 단위, => sess.run 해야 값이 실제로 할당된다</li>\n</ul>\n</li>\n</ul>\n<p>​</p>\n<ul>\n<li>tf.constant(…) : 상수 노드, 값 불변  </li>\n<li>tf.Variable(…) : 변수 노드, (...) 안의 값으로 초기화 하겠다는 의미로, (W, b) update 되는 값 저장 시 사용한다.</li>\n</ul>\n<p>cf .tf.random<em>normal = Xavier/he 정규분포\ncf. tf.random</em>uniform = 0 ~ 1 사이 값</p>\n<ul>\n<li>tf.placeholder : (x, T data) 변수 선언해놓고 값을 외부에서 받을 때 쓰는데, tf 2.0에서 없어졌다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span> <span class=\"token comment\"># 외부에서 실수타입 받아서 다른 곳에 전달하겠다는 의미</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<ul>\n<li>feed<em>dict : placeholder 에 실제 대입되는 값을 쓰면 된다.<br>\nex) a에게 1.0, b에게 3.0을 줘라 => feed</em>dict={a:1.0,b:3.0}</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>a<span class=\"token punctuation\">:</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span>b<span class=\"token punctuation\">:</span><span class=\"token number\">3.0</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># feed_dict 앞을 실행한다.</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>​</p>\n<p>cf. 정리하면,  </p>\n<ul>\n<li>x, T data : placeholder  </li>\n<li>w, b : variable  </li>\n<li>수식 하나 하나 : node ...</li>\n</ul>\n<hr>\n<h4 id=\"mount\" style=\"position:relative;\">Mount<a href=\"#mount\" aria-label=\"mount permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>colab 하나하나 각각의 가상환경이니 내 pc의 diabetes.csv를 각각 올려야 하는데 이는 너무 비효율적이다.</p>\n<p>=> ​colab 작업에서 file upload 를 google drive에 한 다음,<br>\ngoogle drive에 저장된 파일을 colab에서 쓸 수 있게 Mount하면 된다.</p>\n<ul>\n<li>\n<p>​파일?  </p>\n<ul>\n<li>반드시 디렉토리에 있어야 한다.</li>\n<li>이름이 있어야 한다.</li>\n<li>os 입장에서 파일이름을 dir까지 본다.</li>\n</ul>\n</li>\n</ul>\n<p>file system이 다르다는 건 os가 인식하는 방식이 다르다는 것이다. win은 파일명에 /가 안 되는데 리눅스는 되는 거처럼. 로컬 디스크 C: 속성에 NTFS 파일 시스템 적혀 있다.</p>\n<p>cf. <a href=\"https://neul-carpediem.tistory.com/98\">리눅스</a> ext3, ext4  / 스마트폰 jfs / window NFTS</p>\n<ul>\n<li>mount : 특정 디렉토리에 파일을 넣어주는 작업 (storage를 특정 디렉토리에 연결하는 것) 을 말한다.<br>\n...파일은 디렉토리 안에 존재할 때만 의미가 있으니까. 외부 파일 갖고 오려면 이런 걸 넣어줘야 한다.</li>\n</ul>\n<p>cf. colab : 리눅스</p>\n<p>cf. Mount 소개하는 교수님 강의</p>\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/eOFShZfAsNQ\" frameborder=\"0\" allowfullscreen></iframe>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> google<span class=\"token punctuation\">.</span>colab <span class=\"token keyword\">import</span> drive\ndrive<span class=\"token punctuation\">.</span>mount<span class=\"token punctuation\">(</span><span class=\"token string\">'/content/drive'</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># colab 기본 디렉토리인 /content에 /gdrive 붙이겠다는 의미</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>​=> 위 소스 코드에서 mount point는 gdrive로, 여기 밑으로 넣겠다는 뜻이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">working_dir <span class=\"token operator\">=</span> tensorflow_1<span class=\"token punctuation\">.</span>x_working_dir <span class=\"token comment\"># google drive 내 실제 존재하는 dir 이름</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>=> /content/gdrive/my Drive/Colab Notebook 밑에 이걸 두면 된다.</p>\n<hr>\n<h4 id=\"tensorflow-1x-노드--연산-정의\" style=\"position:relative;\">TensorFlow 1.x​ 노드 / 연산 정의<a href=\"#tensorflow-1x-%EB%85%B8%EB%93%9C--%EC%97%B0%EC%82%B0-%EC%A0%95%EC%9D%98\" aria-label=\"tensorflow 1x 노드  연산 정의 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>GradientDescentOptimizer<span class=\"token punctuation\">(</span>learning_rate<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>=> W, b 업데이트 방식으로, 손실함수 최소가 될 때까지 미분으로 update w, b한다는 의미다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">​accuracy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span>predicted<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>=> diabetes 759개 data 각각을 predicted와 T를 equal 비교한 결과에 대하여 True는 1.0, False 는 0.0으로 바꿔준다는 뜻.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">train <span class=\"token operator\">=</span> optimize<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>=> 마지막 노드인 loss랑 train만 실행시키면 <strong>여기 연결된 건</strong> 다 실행된다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">loss_val<span class=\"token punctuation\">,</span> _ <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>loss<span class=\"token punctuation\">,</span> train<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> feed_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> x_data<span class=\"token punctuation\">,</span> T<span class=\"token punctuation\">:</span> t_data<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>=> feed dict으로 데이터를 주면, 연결된 건 다 찾아간다.</p>\n<p>_ : train - anonymous.<br>\n=> 우리가 필요한 건 loss 값 그래서 _ 언더바로 표기했다. 의미 없는 값이라는 뜻이다.</p>\n<p>​\npredict 하기 위해서는 y가 필요하다 y에는 z가 필요하고, 이를 위해 w,b가 필요하고 x가 필요하고... accuracy 하기 위해 predicted와 T가 필요하고...</p>\n<p>​</p>\n<p>=> sess.run에서 실행하는 애들은 tensor, return 값은 numpy 행렬이다.\n​</p>\n<p>cf. lazy evaluation... 이거도 하나의 방법 technic이다.<br>\n아키텍처 보는 insight 성능이 안 나오면 아키텍처를 바꿔야 한댔다만.</p>\n<p>cf. 소프트웨어 개발론 >> test driven development TDD 방식</p>\n<p>cf. agile 방식 >> agile 해결 방식 중 하나 TDD</p>\n<p>​</p>\n<hr>\n<h4 id=\"tf-요약\" style=\"position:relative;\">TF 요약<a href=\"#tf-%EC%9A%94%EC%95%BD\" aria-label=\"tf 요약 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<ul>\n<li>Tf 1.0 은 Node, edge 구성해서 정의하는 부분 &#x26; Sessino 실행하는 부분으로 나뉜다.<br>\n=> 이런 걸 lazy evaluation 이라 한다.</li>\n<li>마지막 노드만 sess.run()으로 실행시킬 때 feed_dict 으로 해주면 처음부터 끝까지 진행된다.\n​</li>\n<li>DL의 목적은 loss min을 위해 w b update 하기 이다.</li>\n<li>기존 코드에는 train 안에 w,b update하는 부분이 명시돼 있었다.​</li>\n</ul>\n<p>★ tensor 흘려주면서 tf에서 w, b 같은 <strong>tf.variable을 자동으로 update</strong> 해준다.</p>\n<ul>\n<li>tf는 relu가 빠르다.​</li>\n<li>logits : 출력층의 선형회귀 값으로, z 가기 전 값이다.</li>\n</ul>\n<hr>\n<h4 id=\"softmax-function\" style=\"position:relative;\">softmax function<a href=\"#softmax-function\" aria-label=\"softmax function permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>여기저기 다 통과 시키면 SoftMax 전체에 대한 하나의 확률로 표시된다.\n$e^(z_i^(k)) / ∑ exp(z_i^(k))$</p>\n<p>=> ​전체 중에 몇 %인지 확률로 알 수 있다.</p>\n<p>​cf. 실무에서는 속도가 중요하니 softmax를 쓰지 않는다.<br>\n어차피 크기가 나왔으니까. 다만, 테스트 검증 시 각 값들의 확률을 보려고 쓴다.<br>\n=> 실제 서비스 시에는, sigmoid까지 쓰고 끝내면 된다.</p>\n<p>전체 중에 각 노드가 %를 차지하는지 알려주는 함수 (확률로 나타난다) 실무에서 이걸 굳이 써서 속도를 저하시킬 필요가 없다.\n​</p>\n<hr>\n<p>tf에는 cross entropy 구하는 함수가 있다. logits=Z3를 쓴다.</p>\n<p>tf.argmax(A3,1) 10개 1줄인 행 기준으로 max의 index를 찾음</p>\n<ul>\n<li>세션 실행 전 내가 알고싶은 값을 정의해야 한다.</li>\n<li>내가 알고자 하는 노드를 연결시키고 마지막에 feed dict 해주면 된다.</li>\n<li>소스 flow 파악하자.</li>\n<li>노드 설정 부분 유심히 보자.</li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#15%EC%9D%BC%EC%B0%A8\">15일차</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#%EB%A9%94%EB%AA%A8\">메모</a></li>\n</ul>\n</li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#tensorflow\">Tensorflow</a></li>\n<li>\n<p><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#google-colab\">Google colab</a></p>\n<ul>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#mount\">Mount</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#tensorflow-1x-%EB%85%B8%EB%93%9C--%EC%97%B0%EC%82%B0-%EC%A0%95%EC%9D%98\">TensorFlow 1.x​ 노드 / 연산 정의</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#tf-%EC%9A%94%EC%95%BD\">TF 요약</a></li>\n<li><a href=\"/ai-%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98-%EC%8A%A4%ED%80%98%EC%96%B4-15%EC%9D%BC%EC%B0%A8/#softmax-function\">softmax function</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 13기 기본반 15일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-15일차/"}},"staticQueryHashes":[]}