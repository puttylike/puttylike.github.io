{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/ai-이노베이션-스퀘어-시각-심화-4일차/",
    "result": {"data":{"markdownRemark":{"html":"<p>이따금 말에 찔릴 때가 있다. 인격은 지갑에서 나오고, 카리스마, 리더십은 실력에서 나온다라. ㅎㅎ...</p>\n<hr>\n<h3 id=\"4일차\" style=\"position:relative;\">4일차<a href=\"#4%EC%9D%BC%EC%B0%A8\" aria-label=\"4일차 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h4 id=\"tf-이어서\" style=\"position:relative;\">TF 이어서<a href=\"#tf-%EC%9D%B4%EC%96%B4%EC%84%9C\" aria-label=\"tf 이어서 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>for epochs,\r\nfor step ...<br>\ntraining<br>\nvalidation<br>\ntest\r\n=> validation은 epochs 당 필요</p>\n<ul>\n<li>data</li>\n</ul>\n<ul>\n<li>training data : w, b update (during learning)</li>\n<li>validation data : 검증 (during learning)</li>\n<li>test data : test (after learning)</li>\n</ul>\n<p>cf. [tensorflow 2.x 강의 03] Keras (케라스)</p>\n<ul>\n<li>linear Regression</li>\n</ul>\n<p>활성화함수 linear<br>\nloss mse\r\nmetrics 불필요</p>\n<ul>\n<li>logistic Regression</li>\n</ul>\n<p>활성화함수 sigmoid<br>\nloss binary_crossentropy\r\nmetrics accuracy</p>\n<h4 id=\"logistic-regression-예제-diabetes\" style=\"position:relative;\">Logistic Regression 예제 (diabetes)<a href=\"#logistic-regression-%EC%98%88%EC%A0%9C-diabetes\" aria-label=\"logistic regression 예제 diabetes permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Flatten<span class=\"token punctuation\">,</span> Dense\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers <span class=\"token keyword\">import</span> SGD<span class=\"token punctuation\">,</span> Adam\r\n\r\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\r\n\r\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n  loaded_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>loadtxt<span class=\"token punctuation\">(</span><span class=\"token string\">'./diabetes.csv'</span><span class=\"token punctuation\">,</span>delimiter<span class=\"token operator\">=</span><span class=\"token string\">','</span><span class=\"token punctuation\">)</span>\r\n\r\n  x_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\r\n  t_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"x_data shape = \"</span><span class=\"token punctuation\">,</span> x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_data shape = \"</span><span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>   \r\n\r\n<span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> err<span class=\"token punctuation\">:</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># x_data shape =  (759, 8)</span>\r\n<span class=\"token comment\"># t_data shape =  (759, 1)</span>\r\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span>t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\r\n                input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'sigmoid'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>SGD<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'binary_crossentropy'</span><span class=\"token punctuation\">,</span> metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_2\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># dense (Dense)                (None, 1)                 9         </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 9</span>\r\n<span class=\"token comment\"># Trainable params: 9</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nhist <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span> validation_split<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 500/500</span>\r\n<span class=\"token comment\"># 19/19 - 0s - loss: 0.4834 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7237</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 24/24 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7642</span>\r\n<span class=\"token comment\"># [0.485337495803833, 0.7641633749008179]</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token comment\"># graph</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># graph</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation accuracy'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> step 값이 19인 이유<br>\n(759*0.8)/32 = 18.975</p>\n<p>=> val 의 loss, accuracy graph 상으로는 오버피팅 문제가 보인다.</p>\n<hr>\n<p>정답은 없지만, 동일 조건이면 parameter가 작은 게 좋다.<br>\n위 예제를 다중분류로 변형해 실습해 보자.</p>\n<h4 id=\"다중분류-예제\" style=\"position:relative;\">다중분류 예제<a href=\"#%EB%8B%A4%EC%A4%91%EB%B6%84%EB%A5%98-%EC%98%88%EC%A0%9C\" aria-label=\"다중분류 예제 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>keras에서 to_categorical 로 one-hot encoding 할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\">t_data_one_hot <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>to_categorical<span class=\"token punctuation\">(</span>t_data<span class=\"token punctuation\">,</span> num_classes<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> t_data_one_hot<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># (759, 1) (759, 2)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>다중분류는 softmax, 이항분류는 sigmoid를 써야 한다.</p>\n<p>다중분류 시 one-hot encoding한 경우에는 categorical_crossentropy<br>\none-hot encoding 안 하고 정수로 하는 경우에는 sparse_crossentropy 를 쓴다.</p>\n<ul>\n<li>다중분류 시 one-hot encoding한 경우</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> to_categorical\r\n\r\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n  loaded_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>loadtxt<span class=\"token punctuation\">(</span><span class=\"token string\">'./diabetes.csv'</span><span class=\"token punctuation\">,</span>delimiter<span class=\"token operator\">=</span><span class=\"token string\">','</span><span class=\"token punctuation\">)</span>\r\n\r\n  x_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\r\n  t_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"x_data shape = \"</span><span class=\"token punctuation\">,</span> x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_data shape = \"</span><span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>   \r\n\r\n  t_data <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_data<span class=\"token punctuation\">,</span> num_classes<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_data shape = \"</span><span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>   \r\n\r\n<span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> err<span class=\"token punctuation\">:</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># x_data shape =  (759, 8)</span>\r\n<span class=\"token comment\"># t_data shape =  (759, 1)</span>\r\n<span class=\"token comment\"># t_data shape =  (759, 2)</span>\r\n\r\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>\r\n                input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>SGD<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'categorical_crossentropy'</span><span class=\"token punctuation\">,</span>metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>                  \r\n<span class=\"token comment\"># Model: \"sequential_2\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># dense_2 (Dense)              (None, 2)                 18        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 18</span>\r\n<span class=\"token comment\"># Trainable params: 18</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nhist <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span> validation_split<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 500/500</span>\r\n<span class=\"token comment\"># 19/19 - 0s - loss: 0.4710 - accuracy: 0.7759 - val_loss: 0.4828 - val_accuracy: 0.7434</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 24/24 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7694</span>\r\n<span class=\"token comment\"># [0.47329020500183105, 0.7694334387779236]</span>\r\n\r\n<span class=\"token comment\"># loss</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># accuracy</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation accuracy'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<ul>\n<li>다중분류 시 one-hot encoding 안 한 경우</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Flatten<span class=\"token punctuation\">,</span> Dense\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers <span class=\"token keyword\">import</span> SGD<span class=\"token punctuation\">,</span> Adam\r\n\r\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\r\n\r\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\r\n  loaded_data <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>loadtxt<span class=\"token punctuation\">(</span><span class=\"token string\">'./diabetes.csv'</span><span class=\"token punctuation\">,</span>delimiter<span class=\"token operator\">=</span><span class=\"token string\">','</span><span class=\"token punctuation\">)</span>\r\n\r\n  x_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\r\n  t_data <span class=\"token operator\">=</span> loaded_data<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"x_data shape = \"</span><span class=\"token punctuation\">,</span> x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_data shape = \"</span><span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>   \r\n\r\n<span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> err<span class=\"token punctuation\">:</span>\r\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># x_data shape =  (759, 8)</span>\r\n<span class=\"token comment\"># t_data shape =  (759, 1)  </span>\r\n\r\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token comment\"># 2여야 함</span>\r\n                input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>SGD<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_5\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># dense_4 (Dense)              (None, 2)                 18        </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 18</span>\r\n<span class=\"token comment\"># Trainable params: 18</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nhist <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span> validation_split<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">,</span> verbose<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 500/500</span>\r\n<span class=\"token comment\"># 19/19 - 0s - loss: 0.4723 - accuracy: 0.7776 - val_loss: 0.4855 - val_accuracy: 0.7368</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_data<span class=\"token punctuation\">,</span> t_data<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 24/24 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7694</span>\r\n<span class=\"token comment\"># [0.47482922673225403, 0.7694334387779236]</span>\r\n\r\n<span class=\"token comment\"># loss</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation loss'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># accuracy</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'train accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation accuracy'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h4 id=\"mnist\" style=\"position:relative;\">MNIST<a href=\"#mnist\" aria-label=\"mnist permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>MNIST data는 흑백이다.</p>\n<p>참고로 open cv를 이용해 image를 read할 때 BGR로 읽는다.<br>\ncf. opencv bgr to rgb<br>\n요즘 추세는 RGB.</p>\n<p>cf. CIFAR-10</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> cifar10\r\n\r\n<span class=\"token punctuation\">(</span>x_train2<span class=\"token punctuation\">,</span> t_train2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test2<span class=\"token punctuation\">,</span> t_test2<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cifar10<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_train2.shape = '</span><span class=\"token punctuation\">,</span> x_train2<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_train2.shape = '</span><span class=\"token punctuation\">,</span> t_train2<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_test2.shape = '</span><span class=\"token punctuation\">,</span> x_test2<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_test2.shape = '</span><span class=\"token punctuation\">,</span> t_test2<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># x_train2.shape =  (50000, 32, 32, 3) , t_train2.shape =  (50000, 1)</span>\r\n<span class=\"token comment\"># x_test2.shape =  (10000, 32, 32, 3) , t_test2.shape =  (10000, 1)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>데이터를 그대로 학습하는 데 쓰면 신경망 down될 수도 있고,<br>\n0 ~ 1 사이 값으로 학습하는 게 학습이 잘 된다. 그래서 scaling (normalization)하는 작업이 필요하다.<br>\n최대값, 최소값의 차이로 값을 나눠야 한다.<br>\n=> 원래 값은 반대로 구하면 된다.</p>\n<p>일반적인 신경망에서는 Flatten하여 1차원으로 데이터를 신경망에 넣어야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\r\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Flatten<span class=\"token punctuation\">,</span> Dense\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> mnist\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> to_categorical\r\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_train.shape = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_train.shape = '</span><span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_test.shape = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_test.shape = '</span><span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># x_train.shape =  (60000, 28, 28) , t_train.shape =  (60000,)</span>\r\n<span class=\"token comment\"># x_test.shape =  (10000, 28, 28) , t_test.shape =  (10000,)</span>\r\n\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\n<span class=\"token comment\"># 48개의 이미지 출력</span>\r\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># (6,1), (12,1), (12,6), (6,6) 등으로 다양하게 해본다</span>\r\n\r\n<span class=\"token keyword\">for</span> index <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">48</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>    <span class=\"token comment\"># 48 개 이미지 출력</span>\r\n\r\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> index <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 4행 12열</span>\r\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\"># 1행 1열 -> 1행 2열 -> ...-> 1행 12열 -> 2행 1열 -> ...</span>\r\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># plt.axis('off) 하면 x, y 축의 0~25 사라짐    </span>\r\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># x_train, x_test 값 범위를 0~1 사이로 정규화</span>\r\n\r\nx_train <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\r\nx_test <span class=\"token operator\">=</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\r\n\r\n<span class=\"token comment\"># 정규화 결과 확인</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'train max = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', train min = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test max = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', test min = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># train max =  1.0 , train min =  0.0</span>\r\n<span class=\"token comment\"># test max =  1.0 , test min =  0.0</span>\r\n\r\n<span class=\"token comment\"># 정답 데이터 one-hot encoding</span>\r\n\r\nt_train <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\r\nt_test <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># one-hot encoding 확인</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'train label = '</span><span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', decimal value = '</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test label = '</span><span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', decimal value = '</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># train label =  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] , decimal value =  5</span>\r\n<span class=\"token comment\"># test label =  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] , decimal value =  7</span>\r\n\r\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모델 생성</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers <span class=\"token keyword\">import</span> SGD\r\n\r\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>SGD<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\r\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_1\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># flatten_1 (Flatten)          (None, 784)               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_2 (Dense)              (None, 100)               78500     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_3 (Dense)              (None, 10)                1010      </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 79,510</span>\r\n<span class=\"token comment\"># Trainable params: 79,510</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nhist <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">=</span> <span class=\"token number\">30</span><span class=\"token punctuation\">,</span> validation_split <span class=\"token operator\">=</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 30/30</span>\r\n<span class=\"token comment\"># 1500/1500 [==============================] - 3s 2ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 0.1144 - val_accuracy: 0.9678</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 313/313 [==============================] - 1s 2ms/step - loss: 0.1090 - accuracy: 0.9691</span>\r\n<span class=\"token comment\"># [0.10904819518327713, 0.9690999984741211]</span>\r\n\r\n<span class=\"token comment\"># loss</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Loss Trend'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'training loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_loss'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation loss'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># accuracy</span>\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy Trend'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'epochs'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'training accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>hist<span class=\"token punctuation\">.</span>history<span class=\"token punctuation\">[</span><span class=\"token string\">'val_accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'validation accuracy'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'best'</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h5 id=\"confusion-matrix\" style=\"position:relative;\">confusion matrix<a href=\"#confusion-matrix\" aria-label=\"confusion matrix permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> confusion_matrix\r\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\r\n\r\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\npredicted_value <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span>\r\n\r\ncm <span class=\"token operator\">=</span> confusion_matrix<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n                      np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predicted_value<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nsns<span class=\"token punctuation\">.</span>heatmap<span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">,</span> annot<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> fmt<span class=\"token operator\">=</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">)</span>\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> confusion_matrix\r\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\r\n\r\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\npredicted_value <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span>\r\n\r\ncm <span class=\"token operator\">=</span> confusion_matrix<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n                      np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>predicted_value<span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\r\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">'label = %d\\t(%d/%d)\\taccuracy = %.3f'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span>\r\n          <span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n           np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>cm<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>=> 숫자 1에 대해 98%, 숫자 5에 대해 80%의 정확도를 갖고 있다.</p>\n<p>다중분류 - 정답이 2개 이상인 경우<br>\n출력층의 노드는 정답의 갯수 n만큼 필요<br>\ndense(n, activation = 'softmax')</p>\n<p>input은 model에 넣기 전에 one hot encoding / sparse로 처리</p>\n<hr>\n<h4 id=\"fashion-mnist\" style=\"position:relative;\">fashion MNIST<a href=\"#fashion-mnist\" aria-label=\"fashion mnist permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> fashion_mnist\r\nfashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>=> val graph로 봐서는 overfitting이 밠생했다. 어떻게 줄일 수 있을까?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\r\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Flatten<span class=\"token punctuation\">,</span> Dense\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> fashion_mnist\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> to_categorical\r\n\r\n<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> fashion_mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_train.shape = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_train.shape = '</span><span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'x_test.shape = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">,</span> <span class=\"token string\">', t_test.shape = '</span><span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># x_train.shape =  (60000, 28, 28) , t_train.shape =  (60000,)</span>\r\n<span class=\"token comment\"># x_test.shape =  (10000, 28, 28) , t_test.shape =  (10000,)</span>\r\n\r\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\r\n\r\n<span class=\"token comment\"># 48개의 이미지 출력</span>\r\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># (6,1), (12,1), (12,6), (6,6) 등으로 다양하게 해본다</span>\r\n\r\n<span class=\"token keyword\">for</span> index <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">48</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>    <span class=\"token comment\"># 48 개 이미지 출력</span>\r\n\r\n    plt<span class=\"token punctuation\">.</span>subplot<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">,</span> index <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 4행 12열</span>\r\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> cmap<span class=\"token operator\">=</span><span class=\"token string\">'gray'</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\"># 1행 1열 -> 1행 2열 -> ...-> 1행 12열 -> 2행 1열 -> ...</span>\r\n    plt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">'off'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># plt.axis('off) 하면 x, y 축의 0~25 사라짐    </span>\r\n    plt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># x_train, x_test 값 범위를 0~1 사이로 정규화</span>\r\n\r\nx_train <span class=\"token operator\">=</span> x_train <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\r\nx_test <span class=\"token operator\">=</span> x_test <span class=\"token operator\">/</span> <span class=\"token number\">255.0</span>\r\n\r\n<span class=\"token comment\"># 정규화 결과 확인</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'train max = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', train min = '</span><span class=\"token punctuation\">,</span> x_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test max = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', test min = '</span><span class=\"token punctuation\">,</span> x_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># train max =  1.0 , train min =  0.0</span>\r\n<span class=\"token comment\"># test max =  1.0 , test min =  0.0</span>\r\n\r\n<span class=\"token comment\"># 정답 데이터 one-hot encoding</span>\r\n\r\nt_train <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\r\nt_test <span class=\"token operator\">=</span> to_categorical<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># one-hot encoding 확인</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'train label = '</span><span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', decimal value = '</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_train<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test label = '</span><span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">', decimal value = '</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>t_test<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># train label =  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] , decimal value =  9</span>\r\n<span class=\"token comment\"># test label =  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] , decimal value =  9</span>\r\n\r\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 모델 생성</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Flatten<span class=\"token punctuation\">(</span>input_shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>optimizers <span class=\"token keyword\">import</span> SGD\r\n\r\nmodel<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span>SGD<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\r\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\r\n              metrics<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Model: \"sequential_3\"</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># Layer (type)                 Output Shape              Param #   </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># flatten_3 (Flatten)          (None, 784)               0         </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_5 (Dense)              (None, 100)               78500     </span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n<span class=\"token comment\"># dense_6 (Dense)              (None, 10)                1010      </span>\r\n<span class=\"token comment\"># =================================================================</span>\r\n<span class=\"token comment\"># Total params: 79,510</span>\r\n<span class=\"token comment\"># Trainable params: 79,510</span>\r\n<span class=\"token comment\"># Non-trainable params: 0</span>\r\n<span class=\"token comment\"># _________________________________________________________________</span>\r\n\r\nhist <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">,</span> t_train<span class=\"token punctuation\">,</span> epochs <span class=\"token operator\">=</span> <span class=\"token number\">30</span><span class=\"token punctuation\">,</span> validation_split <span class=\"token operator\">=</span> <span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># Epoch 30/30</span>\r\n<span class=\"token comment\"># 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3288 - accuracy: 0.8836 - val_loss: 0.3374 - val_accuracy: 0.8809</span>\r\n\r\nmodel<span class=\"token punctuation\">.</span>evaluate<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">,</span> t_test<span class=\"token punctuation\">)</span>\r\n<span class=\"token comment\"># 313/313 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8692</span>\r\n<span class=\"token comment\"># [0.3628668189048767, 0.8691999912261963]</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<hr>\n<h4 id=\"overfitting\" style=\"position:relative;\">overfitting<a href=\"#overfitting\" aria-label=\"overfitting permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>ML/DL의 대표적인 문제 로<br>\ntraining data에만 w,b가 최적화되는 문제</p>\n<ul>\n<li>오버 피팅 을 줄이는 방법</li>\n</ul>\n<p><strong>dropout</strong><br>\ncf. batch normalization - 특정 조건에서만 잘 되곤 함, 논란 있음</p>\n<p>X * W + b = Y, Y - T : loss<br>\nX,T는 고정이니<br>\n원래부터 조금씩 변하는 W, b 값을 강제로 변화를 준다 = dropout</p>\n<h5 id=\"dropout\" style=\"position:relative;\">dropout<a href=\"#dropout\" aria-label=\"dropout permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<p>보통 dropout은 은닉층과 출력층 사이에 넣는다.</p>\n<p>dropout은 hyper parameter의 일종이다. data, 시스템 환경 등 저마다 결과가 다를 수 있다.<br>\n데이터 도메인 지식이 요구된다.</p>\n<ul>\n<li>fashion mnist 예제에 dropout 추가</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers <span class=\"token keyword\">import</span> Dropout\r\n\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.25</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># dropout</span>\r\nmodel<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> activation<span class=\"token operator\">=</span><span class=\"token string\">'softmax'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<ul>\n<li>0.25 droupout 추가 시- val과 train graph가 가까워진다</li>\n</ul>\n<p>Epoch 30/30<br>\n1500/1500 [==============================] - 3s 2ms/step - loss: 0.2587 - accuracy: 0.9033 - val_loss: 0.3283 - val_accuracy: 0.8788</p>\n<ul>\n<li>0.5 dropout 추가 시 - val과 train graph가 가까워진다</li>\n</ul>\n<p>Epoch 30/30\r\n1500/1500 [==============================] - 3s 2ms/step - loss: 0.3544 - accuracy: 0.8662 - val_loss: 0.3604 - val_accuracy: 0.8676</p>\n<ul>\n<li>0.75 dropout 추가 시 - 오히려 더 안 좋아진다</li>\n</ul>\n<p>Epoch 50/50<br>\n480/480 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.8226 - val_loss: 0.3722 - val_accuracy: 0.8662</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#4%EC%9D%BC%EC%B0%A8\">4일차</a></p>\n<ul>\n<li>\n<p><a href=\"#tf-%EC%9D%B4%EC%96%B4%EC%84%9C\">TF 이어서</a></p>\n</li>\n<li>\n<p><a href=\"#logistic-regression-%EC%98%88%EC%A0%9C-diabetes\">Logistic Regression 예제 (diabetes)</a></p>\n</li>\n<li>\n<p><a href=\"#%EB%8B%A4%EC%A4%91%EB%B6%84%EB%A5%98-%EC%98%88%EC%A0%9C\">다중분류 예제</a></p>\n</li>\n<li>\n<p><a href=\"#mnist\">MNIST</a></p>\n<ul>\n<li><a href=\"#confusion-matrix\">confusion matrix</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#fashion-mnist\">fashion MNIST</a></p>\n</li>\n<li>\n<p><a href=\"#overfitting\">overfitting</a></p>\n<ul>\n<li><a href=\"#dropout\">dropout</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"AI 이노베이션 스퀘어 3기 심화 시각반 4일차 후기"}}},"pageContext":{"slug":"/ai-이노베이션-스퀘어-시각-심화-4일차/"}},
    "staticQueryHashes": ["3159585216"]}