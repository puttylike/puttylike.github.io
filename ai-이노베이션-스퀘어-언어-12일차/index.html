<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style id="typography.js">html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:112.5%/1.44 'Fira Sans',sans-serif;box-sizing:border-box;overflow-y:scroll;}*{box-sizing:inherit;}*:before{box-sizing:inherit;}*:after{box-sizing:inherit;}body{color:hsla(0,0%,0%,0.8);font-family:'Fira Sans',sans-serif;font-weight:400;word-wrap:break-word;font-kerning:normal;-moz-font-feature-settings:"kern", "liga", "clig", "calt";-ms-font-feature-settings:"kern", "liga", "clig", "calt";-webkit-font-feature-settings:"kern", "liga", "clig", "calt";font-feature-settings:"kern", "liga", "clig", "calt";}img{max-width:100%;margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}h1{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:2.15rem;line-height:1.1;}h2{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.58293rem;line-height:1.1;}h3{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1.35824rem;line-height:1.1;}h4{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:1rem;line-height:1.1;}h5{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.85805rem;line-height:1.1;}h6{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;color:hsla(0,0%,0%,1);font-family:'Playfair Display',serif;font-weight:700;text-rendering:optimizeLegibility;font-size:0.79482rem;line-height:1.1;}hgroup{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}ul{margin-left:1.44rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;list-style-position:outside;list-style-image:none;}ol{margin-left:1.44rem;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;list-style-position:outside;list-style-image:none;}dl{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}dd{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}p{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}figure{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}pre{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:0.85rem;line-height:1.44rem;}table{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:1rem;line-height:1.44rem;border-collapse:collapse;width:100%;}fieldset{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}blockquote{margin-left:0;margin-right:1.44rem;margin-top:0;padding-bottom:0;padding-left:1.17rem;padding-right:0;padding-top:0;margin-bottom:1.08rem;font-size:1.16543rem;line-height:1.44rem;color:hsla(0,0%,0%,0.59);font-style:italic;border-left:0.27rem solid hsla(0,0%,0%,0.2);}form{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}noscript{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}iframe{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}hr{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:calc(1.08rem - 1px);background:hsla(0,0%,0%,0.2);border:none;height:1px;}address{margin-left:0;margin-right:0;margin-top:0;padding-bottom:0;padding-left:0;padding-right:0;padding-top:0;margin-bottom:1.08rem;}b{font-weight:700;}strong{font-weight:700;}dt{font-weight:700;}th{font-weight:700;}li{margin-bottom:calc(1.08rem / 2);}ol li{padding-left:0;}ul li{padding-left:0;}li > ol{margin-left:1.44rem;margin-bottom:calc(1.08rem / 2);margin-top:calc(1.08rem / 2);}li > ul{margin-left:1.44rem;margin-bottom:calc(1.08rem / 2);margin-top:calc(1.08rem / 2);}blockquote *:last-child{margin-bottom:0;}li *:last-child{margin-bottom:0;}p *:last-child{margin-bottom:0;}li > p{margin-bottom:calc(1.08rem / 2);}code{font-size:0.85rem;line-height:1.44rem;}kbd{font-size:0.85rem;line-height:1.44rem;}samp{font-size:0.85rem;line-height:1.44rem;}abbr{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}acronym{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;}abbr[title]{border-bottom:1px dotted hsla(0,0%,0%,0.5);cursor:help;text-decoration:none;}thead{text-align:left;}td,th{text-align:left;border-bottom:1px solid hsla(0,0%,0%,0.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding-left:0.96rem;padding-right:0.96rem;padding-top:0.72rem;padding-bottom:calc(0.72rem - 1px);}th:first-child,td:first-child{padding-left:0;}th:last-child,td:last-child{padding-right:0;}a{color:#9f392b;}blockquote > :last-child{margin-bottom:0;}blockquote cite{font-size:1rem;line-height:1.44rem;color:hsla(0,0%,0%,0.8);font-weight:400;}blockquote cite:before{content:"— ";}@media only screen and (max-width:480px){blockquote{margin-left:-1.08rem;margin-right:0;padding-left:0.81rem;}}</style><style data-href="/styles.e667edcd973d4522d1dd.css" data-identity="gatsby-global-css">code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#f8f8f2;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;line-height:1.5;-o-tab-size:4;tab-size:4;text-align:left;text-shadow:0 1px rgba(0,0,0,.3);white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}pre[class*=language-].line-numbers{counter-reset:linenumber;padding-left:3.8em;position:relative}pre[class*=language-].line-numbers>code{position:relative;white-space:inherit}.line-numbers .line-numbers-rows{border-right:1px solid #999;font-size:100%;left:-3.8em;letter-spacing:-1px;pointer-events:none;position:absolute;top:0;-webkit-user-select:none;-ms-user-select:none;user-select:none;width:3em}.line-numbers-rows>span{counter-increment:linenumber;display:block}.line-numbers-rows>span:before{color:#999;content:counter(linenumber);display:block;padding-right:.8em;text-align:right}</style><meta name="generator" content="Gatsby 3.13.0"/><style type="text/css">
    .custom-class.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .custom-class.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .custom-class svg,
    h2 .custom-class svg,
    h3 .custom-class svg,
    h4 .custom-class svg,
    h5 .custom-class svg,
    h6 .custom-class svg {
      visibility: hidden;
    }
    h1:hover .custom-class svg,
    h2:hover .custom-class svg,
    h3:hover .custom-class svg,
    h4:hover .custom-class svg,
    h5:hover .custom-class svg,
    h6:hover .custom-class svg,
    h1 .custom-class:focus svg,
    h2 .custom-class:focus svg,
    h3 .custom-class:focus svg,
    h4 .custom-class:focus svg,
    h5 .custom-class:focus svg,
    h6 .custom-class:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 100)
          }), 0)
        }
      }
    })
  </script><link href="//fonts.googleapis.com/css?family=Playfair+Display:700|Fira+Sans:400,400i,700,700i" rel="stylesheet" type="text/css"/><link as="script" rel="preload" href="/webpack-runtime-6ebff4c415c09dde9e8d.js"/><link as="script" rel="preload" href="/framework-24ad6bf468f69b85cc4b.js"/><link as="script" rel="preload" href="/app-f81057f30f7387c76463.js"/><link as="script" rel="preload" href="/commons-71b7b1d300b3ebc29573.js"/><link as="script" rel="preload" href="/e3fcc2076860498e4deed45a66207f3abfe77099-7463bcd7e6ea2ff920c3.js"/><link as="script" rel="preload" href="/component---src-templates-blog-post-js-33322b93090050d5fb1b.js"/><link as="fetch" rel="preload" href="/page-data/ai-이노베이션-스퀘어-언어-12일차/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3159585216.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="1x3051k">.css-1x3051k{margin:0 auto;max-width:720px;padding:2.88rem;padding-top:2.16rem;}</style><main class="css-1x3051k"><a href="/"><style data-emotion-css="i0b9uu">.css-i0b9uu{margin-bottom:2.88rem;display:inline-block;font-style:normal;}</style><h3 class="css-i0b9uu">Blog</h3></a><style data-emotion-css="146q31f">.css-146q31f{float:right;}</style><a class="css-146q31f" href="/about/">About</a><p class="css-146q31f"> / </p><a class="css-146q31f" href="/contact/">Contact</a><div class="sc-bdnxRM jIvSMM"><div class="sc-bdnxRM hzYCxF"><nav class="sc-bdnxRM dSYgIj table-of-contents" color="grey01" width="calc((100vw - 720px) / 2 - 50px)"><h3 class="sc-bdnxRM jiIaSW">TABLE OF CONTENTS</h3><div class="sc-bdnxRM jCvOkx"><ul>
<li>
<p><a href="#12%EC%9D%BC%EC%B0%A8">12일차</a></p>
</li>
<li>
<p><a href="#cnn">CNN</a></p>
<ul>
<li><a href="#data-augmentation">data Augmentation</a></li>
<li><a href="#multi-classification-cnn">multi-classification (CNN)</a></li>
<li><a href="#pytorch-%EC%9D%B4%EC%96%B4%EC%84%9C">pytorch (이어서)</a></li>
</ul>
</li>
</ul></div></nav></div><header class="sc-bdnxRM fzUdiI"><div font-size="24px" class="sc-bdnxRM eFFssn">AI 이노베이션 스퀘어 3기 언어반 12일차 후기</div><div color="#bbb" class="sc-bdnxRM jBinAJ"></div></header><style data-emotion-css="8xh4e7">.css-8xh4e7{line-height:30px;position:static;}</style><div class="sc-bdnxRM fzUdiI css-8xh4e7"><p>전이학습에 입문했다. 다음주부터는 tf를 이용한 NLP를 배운다.</p>
<hr>
<h3 id="12일차" style="position:relative;">12일차<a href="#12%EC%9D%BC%EC%B0%A8" aria-label="12일차 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h3>
<ul>
<li>02_neural_network_classification.ipynb 를 연다.</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_15<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Model: "sequential_14"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># flatten_3 (Flatten)          (None, 784)               0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_37 (Dense)             (None, 4)                 3140      </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_38 (Dense)             (None, 4)                 20        </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_39 (Dense)             (None, 10)                50        </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 3,210</span>
<span class="token comment"># Trainable params: 3,210</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span>

model_15<span class="token punctuation">.</span>layers<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>model_15<span class="token punctuation">.</span>layers<span class="token punctuation">)</span>

<span class="token comment"># ([&lt;keras.layers.core.Flatten at 0x2d215521790>,</span>
<span class="token comment">#   &lt;keras.layers.core.Dense at 0x2d2155bc070>,</span>
<span class="token comment">#   &lt;keras.layers.core.Dense at 0x2d2155aebb0>,</span>
<span class="token comment">#   &lt;keras.layers.core.Dense at 0x2d2155ae340>],</span>
<span class="token comment">#  list)</span>

model_15<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment"># &lt;keras.layers.core.Dense at 0x2d2155bc070></span>

weights<span class="token punctuation">,</span> biases <span class="token operator">=</span> model_15<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>
weights<span class="token punctuation">,</span> weights<span class="token punctuation">.</span>shape

<span class="token comment"># (array([[ 0.7150266 , -0.06077086, -0.9976308 , -1.0484312 ],</span>
<span class="token comment">#         [ 0.27732116, -0.47155362, -0.5291646 ,  0.02329238],</span>
<span class="token comment">#         [ 0.7752429 ,  0.54027545, -1.1288568 , -0.74261546],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [-0.39453447,  0.47628677, -0.22641525,  0.25505912],</span>
<span class="token comment">#         [-0.40515828,  0.61810106,  0.23928423, -0.5038759 ],</span>
<span class="token comment">#         [ 0.23884551,  0.11606929, -0.12131333,  0.04352404]],</span>
<span class="token comment">#        dtype=float32),</span>
<span class="token comment">#  (784, 4))</span>

biases<span class="token punctuation">,</span> biases<span class="token punctuation">.</span>shape

<span class="token comment"># (array([ 2.4486070e-02, -6.1512832e-04, -2.7230212e-01,  8.1124848e-01],</span>
<span class="token comment">#        dtype=float32),</span>
<span class="token comment">#  (4,))</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">weights<span class="token punctuation">,</span> biases <span class="token operator">=</span> model_15<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

weights<span class="token punctuation">,</span> weights<span class="token punctuation">.</span>shape

<span class="token comment"># (array([[ 1.0736768 , -0.19358198,  0.5072533 , -0.35606688],</span>
<span class="token comment">#         [ 0.34898186,  1.134145  ,  0.84305024,  0.5526559 ],</span>
<span class="token comment">#         [ 0.09337563,  0.46247587, -0.69962776,  0.58674866],</span>
<span class="token comment">#         [-0.32451472, -0.21780188,  0.5666561 ,  1.275238  ]],</span>
<span class="token comment">#        dtype=float32),</span>
<span class="token comment">#  (4, 4))</span>

biases<span class="token punctuation">,</span> biases<span class="token punctuation">.</span>shape

<span class="token comment"># (array([-0.650878  , -0.28385457,  0.28233323, -0.3790987 ], dtype=float32),</span>
<span class="token comment">#  (4,))</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<h3 id="cnn" style="position:relative;">CNN<a href="#cnn" aria-label="cnn permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h3>
<ul>
<li>03_CNN.ipynb</li>
</ul>
<p>강사님께 파일 링크를 제공받았다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">
<span class="token keyword">import</span> zipfile

!wget https<span class="token punctuation">:</span><span class="token operator">//</span>storage<span class="token punctuation">.</span>googleapis<span class="token punctuation">.</span>com<span class="token operator">/</span>ztm_tf_course<span class="token operator">/</span>food_vision<span class="token operator">/</span>pizza_steak<span class="token punctuation">.</span><span class="token builtin">zip</span>

zip_ref <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span><span class="token string">"pizza_steak.zip"</span><span class="token punctuation">,</span><span class="token string">"r"</span><span class="token punctuation">)</span>
zip_ref<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span><span class="token punctuation">)</span>
zip_ref<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>데이터 분석을 하든 머신러닝을 하든 아주 중요한 첫 단계는 데이터와 하나가 되는 것,<br>
즉, 데이터를 살펴보고 알아보는 것 => 시각화 이용할 수도 있고, 간단한 통계량을 활용할 수도 있습니다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> os

<span class="token keyword">for</span> dirpath<span class="token punctuation">,</span> dirnames<span class="token punctuation">,</span> filenames <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span><span class="token string">"pizza_steak"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>dirpath<span class="token punctuation">}</span></span><span class="token string">에는 </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dirnames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">개의 디렉토리와 </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>filenames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">개의 파일이 존재합니다."</span></span><span class="token punctuation">)</span>

<span class="token comment"># pizza_steak에는 2개의 디렉토리와 1개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\test에는 2개의 디렉토리와 1개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\test\pizza에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\test\steak에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\train에는 2개의 디렉토리와 1개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\train\pizza에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># pizza_steak\train\steak에는 0개의 디렉토리와 750개의 파일이 존재합니다.   </span>

num_steak_images_train <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token string">"pizza_steak/train/steak"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
num_steak_images_train
<span class="token comment"># 750</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>image <span class="token keyword">as</span> mpimg
<span class="token keyword">import</span> random

<span class="token keyword">def</span> <span class="token function">view_random_image</span><span class="token punctuation">(</span>target_dir<span class="token punctuation">,</span> target_class<span class="token punctuation">)</span><span class="token punctuation">:</span>
    target_folder <span class="token operator">=</span> target_dir <span class="token operator">+</span> target_class
    random_image <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>target_folder<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    img <span class="token operator">=</span> mpimg<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>target_folder <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> random_image<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>target_class<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Image shape: </span><span class="token interpolation"><span class="token punctuation">{</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> img

img <span class="token operator">=</span> view_random_image<span class="token punctuation">(</span>target_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/train/"</span><span class="token punctuation">,</span> target_class <span class="token operator">=</span> <span class="token string">"steak"</span><span class="token punctuation">)</span>   
img <span class="token operator">=</span> view_random_image<span class="token punctuation">(</span>target_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/train/"</span><span class="token punctuation">,</span> target_class <span class="token operator">=</span> <span class="token string">"pizza"</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 이미지를 확인해 보자. 피자/스테이크라고 말하기 애매한 이미지도 보인다. 이미지 크기도 조금씩 다르다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">img

<span class="token comment"># array([[[ 21,  29,  16],</span>
<span class="token comment">#         [ 22,  30,  17],</span>
<span class="token comment">#         [ 21,  29,  16],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [235, 231, 186],</span>
<span class="token comment">#         [234, 225, 182],</span>
<span class="token comment">#         [233, 225, 179]],</span>
<span class="token comment">#</span>
<span class="token comment">#        [[ 21,  29,  16],</span>
<span class="token comment">#         [ 23,  31,  18],</span>
<span class="token comment">#         [ 21,  29,  16],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [237, 230, 186],</span>
<span class="token comment">#         [232, 224, 178],</span>
<span class="token comment">#         [230, 222, 175]],</span>
<span class="token comment">#</span>
<span class="token comment">#        [[ 18,  28,  17],</span>
<span class="token comment">#         [ 19,  29,  18],</span>
<span class="token comment">#         [ 17,  27,  16],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [234, 228, 180],</span>
<span class="token comment">#         [230, 222, 173],</span>
<span class="token comment">#         [229, 219, 170]],</span>
<span class="token comment">#</span>
<span class="token comment">#        ...,</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#         [ 16,  19,  10],</span>
<span class="token comment">#         [ 12,  18,   8],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [162, 179, 186],</span>
<span class="token comment">#         [160, 177, 184],</span>
<span class="token comment">#         [159, 178, 184]]], dtype=uint8)</span>

img<span class="token punctuation">.</span>shape <span class="token comment"># rutnrm의 형태는 (width, height, color channel = RGB)</span>
<span class="token comment"># (512, 382, 3)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<ul>
<li><a href="https://en.wikipedia.org/wiki/RGB_color_model">https://en.wikipedia.org/wiki/RGB_color_model</a></li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">img <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">.</span> <span class="token comment"># 값을 0 ~ 1 사이로 scaling => normalization</span>

<span class="token comment"># array([[[0.08235294, 0.11372549, 0.0627451 ],</span>
<span class="token comment">#         [0.08627451, 0.11764706, 0.06666667],</span>
<span class="token comment">#         [0.08235294, 0.11372549, 0.0627451 ],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [0.92156863, 0.90588235, 0.72941176],</span>
<span class="token comment">#         [0.91764706, 0.88235294, 0.71372549],</span>
<span class="token comment">#         [0.91372549, 0.88235294, 0.70196078]],</span>
<span class="token comment">#</span>
<span class="token comment">#        [[0.08235294, 0.11372549, 0.0627451 ],</span>
<span class="token comment">#         [0.09019608, 0.12156863, 0.07058824],</span>
<span class="token comment">#         [0.08235294, 0.11372549, 0.0627451 ],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [0.92941176, 0.90196078, 0.72941176],</span>
<span class="token comment">#         [0.90980392, 0.87843137, 0.69803922],</span>
<span class="token comment">#         [0.90196078, 0.87058824, 0.68627451]],</span>
<span class="token comment">#</span>
<span class="token comment">#        [[0.07058824, 0.10980392, 0.06666667],</span>
<span class="token comment">#         [0.0745098 , 0.11372549, 0.07058824],</span>
<span class="token comment">#         [0.06666667, 0.10588235, 0.0627451 ],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [0.91764706, 0.89411765, 0.70588235],</span>
<span class="token comment">#         [0.90196078, 0.87058824, 0.67843137],</span>
<span class="token comment">#         [0.89803922, 0.85882353, 0.66666667]],</span>
<span class="token comment">#</span>
<span class="token comment">#        ...,</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#         [0.0627451 , 0.0745098 , 0.03921569],</span>
<span class="token comment">#         [0.04705882, 0.07058824, 0.03137255],</span>
<span class="token comment">#         ...,</span>
<span class="token comment">#         [0.63529412, 0.70196078, 0.72941176],</span>
<span class="token comment">#         [0.62745098, 0.69411765, 0.72156863],</span>
<span class="token comment">#         [0.62352941, 0.69803922, 0.72156863]]])</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 학습을 위해 이미지 전처리를 하고 학습해 보자.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

train_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>
valid_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>

train_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/train/"</span>
test_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/test/"</span>

train_data <span class="token operator">=</span> train_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
                train_dir<span class="token punctuation">,</span>
                batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token comment"># 한 번에 처리할 이미지의 갯수르 지정</span>
                target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 224로 조정 (resize)</span>
                class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
                seed <span class="token operator">=</span> <span class="token number">42</span>
<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> valid_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
                test_dir<span class="token punctuation">,</span>
                batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token comment"># 한 번에 처리할 이미지의 갯수르 지정</span>
                target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 224로 조정 (resize)</span>
                class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
                seed <span class="token operator">=</span> <span class="token number">42</span>
<span class="token punctuation">)</span>

model_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment"># (3, 3)</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>
        pool_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># (2, 2)</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_1<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_1 <span class="token operator">=</span> model_1<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> valid_data
<span class="token punctuation">)</span>

<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 500 images belonging to 2 classes.</span>
<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 76s 2s/step - loss: 0.5611 - accuracy: 0.7013 - val_loss: 0.4231 - val_accuracy: 0.8160</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 68s 1s/step - loss: 0.4222 - accuracy: 0.8180 - val_loss: 0.3404 - val_accuracy: 0.8580</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 69s 1s/step - loss: 0.3916 - accuracy: 0.8320 - val_loss: 0.3208 - val_accuracy: 0.8520</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 70s 1s/step - loss: 0.3464 - accuracy: 0.8500 - val_loss: 0.2899 - val_accuracy: 0.8800</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 66s 1s/step - loss: 0.3091 - accuracy: 0.8767 - val_loss: 0.3040 - val_accuracy: 0.8660</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_1<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Model: "sequential"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># conv2d_4 (Conv2D)            (None, 222, 222, 10)      280       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_5 (Conv2D)            (None, 220, 220, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_2 (MaxPooling2 (None, 110, 110, 10)      0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_6 (Conv2D)            (None, 108, 108, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_7 (Conv2D)            (None, 106, 106, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_3 (MaxPooling2 (None, 53, 53, 10)        0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># flatten (Flatten)            (None, 28090)             0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense (Dense)                (None, 1)                 28091     </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 31,101</span>
<span class="token comment"># Trainable params: 31,101</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>어제 만든 model_15를 참고해 model_2를 만든다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 1. 모델을 create</span>
model_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 2. 모델을 compile</span>
model_2<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># 3. 모델을 fit</span>
history_model_2 <span class="token operator">=</span> model_2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> validation_data <span class="token operator">=</span> valid_data<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 17s 332ms/step - loss: 1.4543 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.5000</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 15s 312ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 17s 371ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 14s 308ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 15s 311ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_2<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Model: "sequential_3"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># flatten_3 (Flatten)          (None, 150528)            0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_7 (Dense)              (None, 4)                 602116    </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_8 (Dense)              (None, 4)                 20        </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_9 (Dense)              (None, 1)                 5         </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 602,141</span>
<span class="token comment"># Trainable params: 602,141</span>
<span class="token comment"># Non-trainable params: 0</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>summary에서 parameter들은 데이터에서 모델이 학습할 수 있는 패턴들로 간주할 수 있다.<br>
직관적으로 생각한다면 parameter 갯수가 많으면 많을수록 더 좋지 않을까 합니다.<br>
model_2에서는 dense 층을 많이 사용했고, 이 층을 이루는 parameter들은 서로 연결되어 있고,<br>
학습해야 할 패턴들이 많아진다.<br>
model_1에서 사용한 CNN (Convolutional Neural Network)는 이미지에서 가장 중요한 패턴을 찾으려고 노력합니다.<br>
그래서 parameter가 갯수가 적더라도, 이미지에서 서로 다른 feature (특징)들을 구분하는데 도움이 됩니다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment"># 성능을 높이기 위해서 Layer를 추가하고, 각 레이어의 뉴런을 늘려본다.</span>
tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 1. 모델을 create</span>
model_3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>activations<span class="token punctuation">.</span>sigmoid<span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 2. 모델을 compile</span>
model_3<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># 3. 모델을 fit</span>
history_model_3 <span class="token operator">=</span> model_3<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> validation_data <span class="token operator">=</span> valid_data<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 18s 365ms/step - loss: 3.8343 - accuracy: 0.6087 - val_loss: 0.5905 - val_accuracy: 0.7380</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 18s 385ms/step - loss: 0.7791 - accuracy: 0.7040 - val_loss: 0.4837 - val_accuracy: 0.7960</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 18s 378ms/step - loss: 0.6030 - accuracy: 0.7333 - val_loss: 0.4976 - val_accuracy: 0.7660</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 18s 391ms/step - loss: 0.5303 - accuracy: 0.7587 - val_loss: 0.6026 - val_accuracy: 0.7260</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 16s 340ms/step - loss: 0.4746 - accuracy: 0.7813 - val_loss: 0.5549 - val_accuracy: 0.7540</span>

model_3<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Model: "sequential_4"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># flatten_4 (Flatten)          (None, 150528)            0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_10 (Dense)             (None, 100)               15052900  </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_11 (Dense)             (None, 100)               10100     </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_12 (Dense)             (None, 100)               10100     </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_13 (Dense)             (None, 1)                 101       </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 15,073,201</span>
<span class="token comment"># Trainable params: 15,073,201</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 여전히 model_1보다 성능이 낮다. CNN이 적은 파라미터 수로 좋은 성능은 보여 이미지에서는 강력하다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
steak_img <span class="token operator">=</span> view_random_image<span class="token punctuation">(</span><span class="token string">"pizza_steak/train/"</span><span class="token punctuation">,</span> <span class="token string">"steak"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
pizza_img <span class="token operator">=</span> view_random_image<span class="token punctuation">(</span><span class="token string">"pizza_steak/train/"</span><span class="token punctuation">,</span> <span class="token string">"pizza"</span><span class="token punctuation">)</span>

train_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/train/"</span>
test_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/test/"</span>

<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator

train_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale<span class="token operator">=</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
test_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale<span class="token operator">=</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

train_data <span class="token operator">=</span> train_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    directory <span class="token operator">=</span> train_dir<span class="token punctuation">,</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token punctuation">)</span>

test_data <span class="token operator">=</span> test_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    directory <span class="token operator">=</span> test_dir<span class="token punctuation">,</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token punctuation">)</span>

<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 500 images belonging to 2 classes.</span>

images<span class="token punctuation">,</span> labels <span class="token operator">=</span> train_data<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
<span class="token comment"># (32, 32)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<ul>
<li><a href="https://twitter.com/ylecun/status/989610208497360896?s=20">https://twitter.com/ylecun/status/989610208497360896?s=20</a></li>
</ul>
<p>=> model_1으로 간결한 model_4를 만든다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_4 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment"># (3, 3)</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_4<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_4 <span class="token operator">=</span> model_4<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> valid_data
<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> pooling이 없어 시간이 오래 걸린다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history_4<span class="token punctuation">.</span>history<span class="token punctuation">)</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>figsize <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span></span></pre></div>
<p>overfitting이 된 상태!!!<br>
validation loss가 증가하기 시작하면, 학습 데이터를 overfitting이 되어가고 있다<br>
즉, 너무나도 학습 데이터의 패턴을 잘 학습하기는 했다, 그런데 잘 모르는 데이터에 대해서 대응 잘 못 한다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_loss_curves</span><span class="token punctuation">(</span>history<span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span>
    val_loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"val_loss"</span><span class="token punctuation">]</span>

    accuracy <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
    val_accuracy <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"val_accuracy"</span><span class="token punctuation">]</span>

    epochs <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"traning_loss"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"val_loss"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epochs"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"traning_accuracy"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> val_accuracy<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"val_val_accuracy"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Accuracy"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epochs"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

plot_loss_curves<span class="token punctuation">(</span>history_4<span class="token punctuation">)</span>    

model_4<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Model: "sequential_6"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># conv2d_11 (Conv2D)           (None, 222, 222, 10)      280       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_12 (Conv2D)           (None, 220, 220, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_13 (Conv2D)           (None, 218, 218, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># flatten_6 (Flatten)          (None, 475240)            0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_15 (Dense)             (None, 1)                 475241    </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 477,341</span>
<span class="token comment"># Trainable params: 477,341</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> train, valid data에 대한 Loss graph, Accuracy graph 1개씩 나온다. overffiting이다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_5 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_5<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_5 <span class="token operator">=</span> model_5<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> test_data
<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 33s 677ms/step - loss: 0.5938 - accuracy: 0.6640 - val_loss: 0.5005 - val_accuracy: 0.7620</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 28s 597ms/step - loss: 0.5049 - accuracy: 0.7620 - val_loss: 0.4542 - val_accuracy: 0.7840</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 27s 576ms/step - loss: 0.4420 - accuracy: 0.8113 - val_loss: 0.3660 - val_accuracy: 0.8320</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 27s 571ms/step - loss: 0.4111 - accuracy: 0.8240 - val_loss: 0.3386 - val_accuracy: 0.8420</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 30s 635ms/step - loss: 0.3946 - accuracy: 0.8360 - val_loss: 0.3403 - val_accuracy: 0.8520</span>

model_5<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Model: "sequential_10"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># conv2d_23 (Conv2D)           (None, 222, 222, 10)      280       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_10 (MaxPooling (None, 111, 111, 10)      0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_24 (Conv2D)           (None, 109, 109, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_11 (MaxPooling (None, 54, 54, 10)        0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_25 (Conv2D)           (None, 52, 52, 10)        910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_12 (MaxPooling (None, 26, 26, 10)        0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># flatten_10 (Flatten)         (None, 6760)              0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_19 (Dense)             (None, 1)                 6761      </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 8,861</span>
<span class="token comment"># Trainable params: 8,861</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>= accuracy가 그렇게 줄어들지 않았다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">plot_loss_curves<span class="token punctuation">(</span>history_5<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span></span></pre></div>
<p>=> train, valid의 graph가 model_4보다 비슷한 양상을 보인다.</p>
<p>Convolutional Neural Network 의 특징 => 가능한 이미지에서 중요한 특징, 즉 패턴을 찾겠다!!!<br>
MaxPooling2D의 특징 => 가장 중요한 패턴 찾았어? 그럼 나는 쓸모없는 것 제거해 줄게!<br>
pool_size가 (2, 2) => 2행 2열짜리, 즉, 한 번에 4개 데이터를 가지고 1개만 선택<br>
pool_size가 (5, 5) => 5행 5열짜리, 즉, 한 번에 25개 데이터를 가지고 1개만 선택</p>
<hr>
<h4 id="data-augmentation" style="position:relative;">data Augmentation<a href="#data-augmentation" aria-label="data augmentation permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<p>Data Augmentation : overfitting을 방지하는 기법<br>
학습 데이터를 변형하는 과정 => 데이터의 다양성을 더 추가하여 더 많은 패턴을 익히도록 하는 것!</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">train_datagenerator_augmented <span class="token operator">=</span>  ImageDataGenerator<span class="token punctuation">(</span>
    rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>
    rotation_range <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>
    shear_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    zoom_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    width_shift_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    height_shift_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    horizontal_flip <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token punctuation">)</span>

train_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>
valid_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>

train_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/train/"</span>
test_dir <span class="token operator">=</span> <span class="token string">"pizza_steak/test/"</span>

train_data_augmented <span class="token operator">=</span> train_datagenerator_augmented<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
    shuffle <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token punctuation">)</span>

train_data <span class="token operator">=</span> train_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
    shuffle <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token punctuation">)</span>

valid_data <span class="token operator">=</span> valid_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    test_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
<span class="token punctuation">)</span>
<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 500 images belonging to 2 classes.</span>

images<span class="token punctuation">,</span> labels <span class="token operator">=</span> train_data<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
augmented_images<span class="token punctuation">,</span> augmented_labels <span class="token operator">=</span> train_data_augmented<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

random_number <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>random_number<span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Original Image"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>augmented_images<span class="token punctuation">[</span>random_number<span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Augmented Image"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 같은 이미지인데, 아래 꺼가 약간 변형된 이미지임을 알아볼 수 있다. 이 Augmented data로 학습을 해본다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_6 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_6<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_6 <span class="token operator">=</span> model_6<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data_augmented<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> valid_data
<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 45s 931ms/step - loss: 0.7396 - accuracy: 0.5160 - val_loss: 0.6892 - val_accuracy: 0.5080</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 45s 947ms/step - loss: 0.6970 - accuracy: 0.5100 - val_loss: 0.6790 - val_accuracy: 0.7040</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 47s 994ms/step - loss: 0.6841 - accuracy: 0.6427 - val_loss: 0.6495 - val_accuracy: 0.7280</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 51s 1s/step - loss: 0.6427 - accuracy: 0.6947 - val_loss: 1.1209 - val_accuracy: 0.5000</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 47s 994ms/step - loss: 0.6285 - accuracy: 0.6800 - val_loss: 0.5787 - val_accuracy: 0.6940</span>

plot_loss_curves<span class="token punctuation">(</span>history_6<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> shuffle 안 해서 학습률 떨어진다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">train_data_augmented_shuffled <span class="token operator">=</span> train_datagenerator_augmented<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
    shuffle <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token punctuation">)</span>

train_data <span class="token operator">=</span> train_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
    shuffle <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token punctuation">)</span>

valid_data <span class="token operator">=</span> valid_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    test_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"binary"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
<span class="token punctuation">)</span>

<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 1500 images belonging to 2 classes.</span>
<span class="token comment"># Found 500 images belonging to 2 classes.</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 학습 데이터에 shuffle을 추가해 새 모델로 학습한다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_7 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_7<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_7 <span class="token operator">=</span> model_7<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data_augmented_shuffed<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> valid_data
<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 23s 476ms/step - loss: 0.6493 - accuracy: 0.6060 - val_loss: 0.6015 - val_accuracy: 0.6440</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 23s 485ms/step - loss: 0.5872 - accuracy: 0.6773 - val_loss: 0.4488 - val_accuracy: 0.8240</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 23s 495ms/step - loss: 0.5115 - accuracy: 0.7547 - val_loss: 0.3911 - val_accuracy: 0.8260</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 23s 493ms/step - loss: 0.4872 - accuracy: 0.7700 - val_loss: 0.3490 - val_accuracy: 0.8520</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 23s 491ms/step - loss: 0.4638 - accuracy: 0.7767 - val_loss: 0.3254 - val_accuracy: 0.8600</span>

plot_loss_curves<span class="token punctuation">(</span>history_7<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> model_6 보다는 graph가 smooth해 보인다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">model_8 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"sigmoid"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_8<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_8 <span class="token operator">=</span> model_8<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data_augmented_shuffed<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> valid_data
<span class="token punctuation">)</span>
<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 47/47 [==============================] - 33s 696ms/step - loss: 0.6113 - accuracy: 0.6413 - val_loss: 0.6678 - val_accuracy: 0.6020</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 47/47 [==============================] - 36s 754ms/step - loss: 0.5754 - accuracy: 0.7127 - val_loss: 0.4827 - val_accuracy: 0.8140</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 47/47 [==============================] - 35s 745ms/step - loss: 0.5434 - accuracy: 0.7340 - val_loss: 0.4357 - val_accuracy: 0.8080</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 47/47 [==============================] - 35s 750ms/step - loss: 0.5374 - accuracy: 0.7533 - val_loss: 0.4053 - val_accuracy: 0.8440</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 47/47 [==============================] - 36s 766ms/step - loss: 0.5228 - accuracy: 0.7533 - val_loss: 0.4238 - val_accuracy: 0.8220</span>

plot_loss_curves<span class="token punctuation">(</span>history_8<span class="token punctuation">)</span>


model_1<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Model: "sequential"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># conv2d (Conv2D)              (None, 222, 222, 10)      280       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_1 (Conv2D)            (None, 220, 220, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d (MaxPooling2D) (None, 110, 110, 10)      0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_2 (Conv2D)            (None, 108, 108, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_3 (Conv2D)            (None, 106, 106, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_1 (MaxPooling2 (None, 53, 53, 10)        0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># flatten (Flatten)            (None, 28090)             0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense (Dense)                (None, 1)                 28091     </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 31,101</span>
<span class="token comment"># Trainable params: 31,101</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span>

model_8<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Model: "sequential_3"</span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># Layer (type)                 Output Shape              Param #   </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># conv2d_16 (Conv2D)           (None, 222, 222, 10)      280       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_17 (Conv2D)           (None, 220, 220, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_11 (MaxPooling (None, 110, 110, 10)      0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_18 (Conv2D)           (None, 108, 108, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># conv2d_19 (Conv2D)           (None, 106, 106, 10)      910       </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># max_pooling2d_12 (MaxPooling (None, 53, 53, 10)        0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># flatten_7 (Flatten)          (None, 28090)             0         </span>
<span class="token comment"># _________________________________________________________________</span>
<span class="token comment"># dense_12 (Dense)             (None, 1)                 28091     </span>
<span class="token comment"># =================================================================</span>
<span class="token comment"># Total params: 31,101</span>
<span class="token comment"># Trainable params: 31,101</span>
<span class="token comment"># Non-trainable params: 0</span>
<span class="token comment"># _________________________________________________________________</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>model_1과 8의 parameter 수는 31101로 동일하다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>class_name<span class="token punctuation">)</span>
<span class="token comment"># ['pizza' 'steak']</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span></span></pre></div>
<p>=> 모델을 test file로 predict 해보자.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">
! wget https<span class="token punctuation">:</span><span class="token operator">//</span>raw<span class="token punctuation">.</span>githubusercontent<span class="token punctuation">.</span>com<span class="token operator">/</span>mrdbourke<span class="token operator">/</span>tensorflow<span class="token operator">-</span>deep<span class="token operator">-</span>learning<span class="token operator">/</span>main<span class="token operator">/</span>images<span class="token operator">/</span><span class="token number">03</span><span class="token operator">-</span>steak<span class="token punctuation">.</span>jpeg
steak <span class="token operator">=</span> mpimg<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"03-steak.jpeg"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>steak<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">steak<span class="token punctuation">.</span>shape
<span class="token comment"># (4032, 3024, 3)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_and_pred_image</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> img_shape<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> tf<span class="token punctuation">.</span>io<span class="token punctuation">.</span>read_file<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
    img <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>decode_image<span class="token punctuation">(</span>img<span class="token punctuation">,</span> channels <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> size <span class="token operator">=</span> <span class="token punctuation">[</span>img_shape<span class="token punctuation">,</span> img_shape<span class="token punctuation">]</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> img <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">.</span>

    <span class="token keyword">return</span> img
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">steak <span class="token operator">=</span> load_and_pred_image<span class="token punctuation">(</span><span class="token string">"03-steak.jpeg"</span><span class="token punctuation">)</span>
steak<span class="token punctuation">,</span> steak<span class="token punctuation">.</span>shape
<span class="token comment"># (&lt;tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=</span>
<span class="token comment">#  array([[[0.6377451 , 0.6220588 , 0.57892156],</span>
<span class="token comment">#          [0.6504902 , 0.63186276, 0.5897059 ],</span>
<span class="token comment">#          [0.63186276, 0.60833335, 0.5612745 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.52156866, 0.05098039, 0.09019608],</span>
<span class="token comment">#          [0.49509802, 0.04215686, 0.07058824],</span>
<span class="token comment">#          [0.52843136, 0.07745098, 0.10490196]],</span>
<span class="token comment">#</span>
<span class="token comment">#         [[0.6617647 , 0.6460784 , 0.6107843 ],</span>
<span class="token comment">#          [0.6387255 , 0.6230392 , 0.57598037],</span>
<span class="token comment">#          [0.65588236, 0.63235295, 0.5852941 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.5352941 , 0.06862745, 0.09215686],</span>
<span class="token comment">#          [0.529902  , 0.05931373, 0.09460784],</span>
<span class="token comment">#          [0.5142157 , 0.05539216, 0.08676471]],</span>
<span class="token comment">#</span>
<span class="token comment">#         [[0.6519608 , 0.6362745 , 0.5892157 ],</span>
<span class="token comment">#          [0.6392157 , 0.6137255 , 0.56764704],</span>
<span class="token comment">#          [0.65637255, 0.6269608 , 0.5828431 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.53137255, 0.06470589, 0.08039216],</span>
<span class="token comment">#          [0.527451  , 0.06862745, 0.1       ],</span>
<span class="token comment">#          [0.52254903, 0.05196078, 0.0872549 ]],</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#          [0.65      , 0.5686275 , 0.44019607],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.6308824 , 0.6161765 , 0.5808824 ],</span>
<span class="token comment">#          [0.6519608 , 0.63186276, 0.5901961 ],</span>
<span class="token comment">#          [0.6338235 , 0.6259804 , 0.57892156]]], dtype=float32)>,</span>
<span class="token comment">#  TensorShape([224, 224, 3]))</span>

model_8<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>steak<span class="token punctuation">)</span>
<span class="token comment"># ValueError: in user code:</span>
<span class="token comment">#</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\training.py:1586 predict_function  *</span>
<span class="token comment">#         return step_function(self, iterator)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\training.py:1576 step_function  **</span>
<span class="token comment">#         outputs = model.distribute_strategy.run(run_step, args=(data,))</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1286 run</span>
<span class="token comment">#         return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2849 call_for_each_replica</span>
<span class="token comment">#         return self._call_for_each_replica(fn, args, kwargs)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:3632 _call_for_each_replica</span>
<span class="token comment">#         return fn(*args, **kwargs)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\training.py:1569 run_step  **</span>
<span class="token comment">#         outputs = model.predict_step(data)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\training.py:1537 predict_step</span>
<span class="token comment">#         return self(x, training=False)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\base_layer.py:1020 __call__</span>
<span class="token comment">#         input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)</span>
<span class="token comment">#     c:\20210822\venv_20210822\lib\site-packages\keras\engine\input_spec.py:229 assert_input_compatibility</span>
<span class="token comment">#         raise ValueError('Input ' + str(input_index) + ' of layer ' +</span>
<span class="token comment">#</span>
<span class="token comment">#     ValueError: Input 0 of layer sequential_3 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 224, 3)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> 에러가 발생한다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment">## 학습할 때 데이터의 형태 (batch_size, 224, 224, 3)</span>
<span class="token comment">## prediction의 경우 (224, 224, 3) -> (1, 224, 224, 3)의 형태가 되어야 한다!</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>steak<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
steak <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>steak<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>steak<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
steak

<span class="token comment"># (224, 224, 3)</span>
<span class="token comment"># (1, 224, 224, 3)</span>
<span class="token comment"># &lt;tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=</span>
<span class="token comment"># array([[[[0.6377451 , 0.6220588 , 0.57892156],</span>
<span class="token comment">#          [0.6504902 , 0.63186276, 0.5897059 ],</span>
<span class="token comment">#          [0.63186276, 0.60833335, 0.5612745 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.52156866, 0.05098039, 0.09019608],</span>
<span class="token comment">#          [0.49509802, 0.04215686, 0.07058824],</span>
<span class="token comment">#          [0.52843136, 0.07745098, 0.10490196]],</span>
<span class="token comment">#</span>
<span class="token comment">#         [[0.6617647 , 0.6460784 , 0.6107843 ],</span>
<span class="token comment">#          [0.6387255 , 0.6230392 , 0.57598037],</span>
<span class="token comment">#          [0.65588236, 0.63235295, 0.5852941 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.5352941 , 0.06862745, 0.09215686],</span>
<span class="token comment">#          [0.529902  , 0.05931373, 0.09460784],</span>
<span class="token comment">#          [0.5142157 , 0.05539216, 0.08676471]],</span>
<span class="token comment">#</span>
<span class="token comment">#         [[0.6519608 , 0.6362745 , 0.5892157 ],</span>
<span class="token comment">#          [0.6392157 , 0.6137255 , 0.56764704],</span>
<span class="token comment">#          [0.65637255, 0.6269608 , 0.5828431 ],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.53137255, 0.06470589, 0.08039216],</span>
<span class="token comment">#          [0.527451  , 0.06862745, 0.1       ],</span>
<span class="token comment">#          [0.52254903, 0.05196078, 0.0872549 ]],</span>
<span class="token comment"># show more (open the raw output data in a text editor) ...</span>
<span class="token comment">#</span>
<span class="token comment">#          [0.48333332, 0.40882352, 0.29117647],</span>
<span class="token comment">#          [0.65      , 0.5686275 , 0.44019607],</span>
<span class="token comment">#          ...,</span>
<span class="token comment">#          [0.6308824 , 0.6161765 , 0.5808824 ],</span>
<span class="token comment">#          [0.6519608 , 0.63186276, 0.5901961 ],</span>
<span class="token comment">#          [0.6338235 , 0.6259804 , 0.57892156]]]], dtype=float32)></span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">pred <span class="token operator">=</span> model_8<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>steak<span class="token punctuation">)</span>
pred
<span class="token comment"># array([[0.82531464]], dtype=float32)</span>

pred_class <span class="token operator">=</span> class_name<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
pred_class
<span class="token comment"># 'steak'</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pred_and_plot</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> class_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> load_and_pred_image<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>img<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    pred_class <span class="token operator">=</span> class_name<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prediction: </span><span class="token interpolation"><span class="token punctuation">{</span>pred_class<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

pred_and_plot<span class="token punctuation">(</span>model_8<span class="token punctuation">,</span> <span class="token string">"03-steak.jpeg"</span><span class="token punctuation">,</span> class_name<span class="token punctuation">)</span>
<span class="token comment"># steak로 예측</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">!wget https<span class="token punctuation">:</span><span class="token operator">//</span>raw<span class="token punctuation">.</span>githubusercontent<span class="token punctuation">.</span>com<span class="token operator">/</span>mrdbourke<span class="token operator">/</span>tensorflow<span class="token operator">-</span>deep<span class="token operator">-</span>learning<span class="token operator">/</span>main<span class="token operator">/</span>images<span class="token operator">/</span><span class="token number">03</span><span class="token operator">-</span>pizza<span class="token operator">-</span>dad<span class="token punctuation">.</span>jpeg
pred_and_plot<span class="token punctuation">(</span>model_8<span class="token punctuation">,</span> <span class="token string">"03-pizza-dad.jpeg"</span><span class="token punctuation">,</span> class_name<span class="token punctuation">)</span>
<span class="token comment"># pizza로 예측</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span></span></pre></div>
<hr>
<h4 id="multi-classification-cnn" style="position:relative;">multi-classification (CNN)<a href="#multi-classification-cnn" aria-label="multi classification cnn permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">!wget https<span class="token punctuation">:</span><span class="token operator">//</span>storage<span class="token punctuation">.</span>googleapis<span class="token punctuation">.</span>com<span class="token operator">/</span>ztm_tf_course<span class="token operator">/</span>food_vision<span class="token operator">/</span>10_food_classes_all_data<span class="token punctuation">.</span><span class="token builtin">zip</span>

<span class="token keyword">import</span> zipfile

zip_ref <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span><span class="token string">"10_food_classes_all_data.zip"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
zip_ref<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span><span class="token punctuation">)</span>
zip_ref<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> os

<span class="token keyword">for</span> dirpath<span class="token punctuation">,</span> dirnames<span class="token punctuation">,</span> filenames <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span><span class="token string">"10_food_classes_all_data"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>dirpath<span class="token punctuation">}</span></span><span class="token string">에는 </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dirnames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">개의 디렉토리와 </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>filenames<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">개의 파일이 존재합니다."</span></span><span class="token punctuation">)</span>
<span class="token comment"># 10_food_classes_all_data에는 2개의 디렉토리와 0개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test에는 10개의 디렉토리와 0개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\chicken_curry에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\chicken_wings에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\fried_rice에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\grilled_salmon에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\hamburger에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\ice_cream에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\pizza에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\ramen에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\steak에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\test\sushi에는 0개의 디렉토리와 250개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train에는 10개의 디렉토리와 0개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\chicken_curry에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\chicken_wings에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\fried_rice에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\grilled_salmon에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\hamburger에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\ice_cream에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\pizza에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\ramen에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\steak에는 0개의 디렉토리와 750개의 파일이 존재합니다.</span>
<span class="token comment"># 10_food_classes_all_data\train\sushi에는 0개의 디렉토리와 750개의 파일이 존재합니다.    </span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">train_dir <span class="token operator">=</span> <span class="token string">"10_food_classes_all_data/train/"</span>
test_dir <span class="token operator">=</span> <span class="token string">"10_food_classes_all_data/test/"</span>

<span class="token keyword">import</span> pathlib
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
data_dir <span class="token operator">=</span> pathlib<span class="token punctuation">.</span>Path<span class="token punctuation">(</span>train_dir<span class="token punctuation">)</span>
class_names <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">.</span>name <span class="token keyword">for</span> item <span class="token keyword">in</span> data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>class_names<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>class_names<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 'chicken_curry' 'chicken_wings' 'fried_rice' 'grilled_salmon' 'hamburger'</span>
<span class="token comment">#  'ice_cream' 'pizza' 'ramen' 'steak' 'sushi'] 10</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> random
img <span class="token operator">=</span> view_random_image<span class="token punctuation">(</span>
    target_dir <span class="token operator">=</span> train_dir<span class="token punctuation">,</span>
    target_class <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>class_names<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token comment"># Image shape: (512, 512, 3)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator

train_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>
test_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>

train_data <span class="token operator">=</span> train_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"categorical"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법    seed = 42</span>
<span class="token punctuation">)</span>

test_data <span class="token operator">=</span> test_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    test_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"categorical"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
<span class="token punctuation">)</span>

<span class="token comment"># Found 7500 images belonging to 10 classes.</span>
<span class="token comment"># Found 2500 images belonging to 10 classes.</span>
</code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span> MaxPool2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dense

model_9 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"softmax"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_9<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"categorical_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_9 <span class="token operator">=</span> model_9<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> test_data
<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 235/235 [==============================] - 290s 1s/step - loss: 2.1632 - accuracy: 0.2125 - val_loss: 1.9801 - val_accuracy: 0.2956</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 235/235 [==============================] - 336s 1s/step - loss: 1.9607 - accuracy: 0.3092 - val_loss: 1.9483 - val_accuracy: 0.3052</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 235/235 [==============================] - 341s 1s/step - loss: 1.7412 - accuracy: 0.4037 - val_loss: 1.9070 - val_accuracy: 0.3244</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 235/235 [==============================] - 345s 1s/step - loss: 1.2993 - accuracy: 0.5632 - val_loss: 2.1218 - val_accuracy: 0.3080</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 235/235 [==============================] - 327s 1s/step - loss: 0.7616 - accuracy: 0.7507 - val_loss: 2.7053 - val_accuracy: 0.2876</span>

plot_loss_curves<span class="token punctuation">(</span>history_9<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> overfitting으로 보인다.</p>
<p>overfitting을 막으려고 하는 것을 ==>  regularization 이라고 합니다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span> MaxPool2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dense

model_10 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    Conv2D<span class="token punctuation">(</span>
        filters <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span>
        kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
        strides <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
        padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span>
        activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
        input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Conv2D<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MaxPool2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">"softmax"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_10<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"categorical_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_10 <span class="token operator">=</span> model_10<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> test_data
<span class="token punctuation">)</span>
<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 235/235 [==============================] - 138s 584ms/step - loss: 2.2089 - accuracy: 0.2120 - val_loss: 2.0156 - val_accuracy: 0.2664</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 235/235 [==============================] - 149s 633ms/step - loss: 1.7792 - accuracy: 0.3865 - val_loss: 1.9952 - val_accuracy: 0.2952</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 235/235 [==============================] - 133s 567ms/step - loss: 1.3212 - accuracy: 0.5672 - val_loss: 2.0913 - val_accuracy: 0.2920</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 235/235 [==============================] - 149s 634ms/step - loss: 0.8389 - accuracy: 0.7439 - val_loss: 2.4251 - val_accuracy: 0.2820</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 235/235 [==============================] - 141s 600ms/step - loss: 0.4359 - accuracy: 0.8827 - val_loss: 3.0127 - val_accuracy: 0.2612</span>

plot_loss_curves<span class="token punctuation">(</span>history_10<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">train_datagenerator_augmented <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>
    rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span>
    rotation_range <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span>
    shear_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    zoom_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    width_shift_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    height_shift_range <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
    horizontal_flip <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token punctuation">)</span>

train_data_augmented <span class="token operator">=</span> train_datagenerator_augmented<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    train_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>   <span class="token comment"># 1번에 처리할 이미지의 갯수를 지정</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 이미지의 크기를 224, 244로 조정 (resize)</span>
    class_mode <span class="token operator">=</span> <span class="token string">"categorical"</span><span class="token punctuation">,</span> <span class="token comment"># 우리가 처리할 방법</span>
<span class="token punctuation">)</span>

<span class="token comment"># Found 7500 images belonging to 10 classes.</span>

model_11 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>clone_model<span class="token punctuation">(</span>model_10<span class="token punctuation">)</span>

model_11<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss <span class="token operator">=</span> <span class="token string">"categorical_crossentropy"</span><span class="token punctuation">,</span>
    optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    metrics <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

history_11 <span class="token operator">=</span> model_11<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data_augmented<span class="token punctuation">,</span>
    epochs <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
    validation_data <span class="token operator">=</span> test_data
<span class="token punctuation">)</span>

<span class="token comment"># Epoch 1/5</span>
<span class="token comment"># 235/235 [==============================] - 322s 1s/step - loss: 2.2189 - accuracy: 0.2039 - val_loss: 2.0249 - val_accuracy: 0.2740</span>
<span class="token comment"># Epoch 2/5</span>
<span class="token comment"># 235/235 [==============================] - 323s 1s/step - loss: 2.0510 - accuracy: 0.2707 - val_loss: 1.9377 - val_accuracy: 0.3184</span>
<span class="token comment"># Epoch 3/5</span>
<span class="token comment"># 235/235 [==============================] - 345s 1s/step - loss: 2.0235 - accuracy: 0.2903 - val_loss: 1.8703 - val_accuracy: 0.3364</span>
<span class="token comment"># Epoch 4/5</span>
<span class="token comment"># 235/235 [==============================] - 347s 1s/step - loss: 1.9982 - accuracy: 0.2991 - val_loss: 1.8494 - val_accuracy: 0.3676</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 235/235 [==============================] - 366s 2s/step - loss: 1.9751 - accuracy: 0.3169 - val_loss: 1.8192 - val_accuracy: 0.3508</span>

plot_loss_curves<span class="token punctuation">(</span>history_11<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<p>=> epochs가 부족해서 학습이 덜 된 것으로 보인다.</p>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">class_names

<span class="token comment"># array(['002_pytorch.ipynb', 'chicken_curry', 'chicken_wings',</span>
<span class="token comment">#        'fried_rice', 'grilled_salmon', 'hamburger', 'ice_cream', 'pizza',</span>
<span class="token comment">#        'ramen', 'steak', 'sushi'], dtype='&lt;U17')</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">pred_and_plot<span class="token punctuation">(</span>
model <span class="token operator">=</span> model_11<span class="token punctuation">,</span>
filename <span class="token operator">=</span> <span class="token string">"03-steak.jpeg"</span><span class="token punctuation">,</span>
class_names <span class="token operator">=</span> class_names
<span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">img <span class="token operator">=</span> load_and_pred_image<span class="token punctuation">(</span><span class="token string">"03-steak.jpeg"</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> model_11<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>img<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred
<span class="token comment"># array([[0.03453452, 0.03666642, 0.09922207, 0.25764412, 0.05572828,</span>
<span class="token comment">#         0.1552842 , 0.02415404, 0.10833126, 0.14857659, 0.07985856]],</span>
<span class="token comment">#       dtype=float32)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">pred_class <span class="token operator">=</span> class_names<span class="token punctuation">[</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
pred_class <span class="token comment"># 'fried_rice'</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>pred_class<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pred_and_plot_multi</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> classnames<span class="token punctuation">)</span><span class="token punctuation">:</span>
  img <span class="token operator">=</span> load_and_pred_image<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
  pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>img<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pred<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">:</span>
    pred_class <span class="token operator">=</span> class_names<span class="token punctuation">[</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    pred_class <span class="token operator">=</span> class_names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

  plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prediction: </span><span class="token interpolation"><span class="token punctuation">{</span>pred_class<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">pred_and_plot_multi<span class="token punctuation">(</span>model_11<span class="token punctuation">,</span> <span class="token string">"03-steak.jpeg"</span><span class="token punctuation">,</span> class_names<span class="token punctuation">)</span>

model_11<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"saved_trained_model_model11"</span><span class="token punctuation">)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span></span></pre></div>
<ul>
<li>03_CNN2.ipynb</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image <span class="token keyword">import</span> ImageDataGenerator

test_dir <span class="token operator">=</span> <span class="token string">"10_food_classes_all_data/test/"</span>

test_datagenerator <span class="token operator">=</span> ImageDataGenerator<span class="token punctuation">(</span>rescale <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">)</span>

test_data <span class="token operator">=</span> test_datagenerator<span class="token punctuation">.</span>flow_from_directory<span class="token punctuation">(</span>
    test_dir<span class="token punctuation">,</span>
    batch_size <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span>
    target_size <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    class_mode <span class="token operator">=</span> <span class="token string">"categorical"</span>
<span class="token punctuation">)</span>

load_model_11 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"saved_trained_model_model11"</span><span class="token punctuation">)</span>
load_model_11<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
<span class="token comment"># 79/79 [==============================] - 19s 229ms/step - loss: 1.8192 - accuracy: 0.3508</span>
<span class="token comment"># [1.819219946861267, 0.3508000075817108]</span>


<span class="token comment">## model11</span>
<span class="token comment"># Epoch 5/5</span>
<span class="token comment"># 235/235 [==============================] - 366s 2s/step - loss: 1.9751 - accuracy: 0.3169 - val_loss: 1.8192 - val_accuracy: 0.3508</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<hr>
<h4 id="pytorch-이어서" style="position:relative;">pytorch (이어서)<a href="#pytorch-%EC%9D%B4%EC%96%B4%EC%84%9C" aria-label="pytorch 이어서 permalink" class="custom-class after"><svg aria-hidden="true" height="20" version="1.1" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a></h4>
<ul>
<li>002_pytorch.ipynb</li>
</ul>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python"><span class="token comment">## 002_pytorch.ipynb</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
numpy_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token builtin">type</span><span class="token punctuation">(</span>numpy_data<span class="token punctuation">)</span><span class="token punctuation">,</span> numpy_data
<span class="token comment"># (numpy.ndarray,</span>
<span class="token comment">#  array([[0.03579957, 0.99645713, 0.68238137],</span>
<span class="token comment">#         [0.18713323, 0.27620823, 0.71559158]]))</span>
torch_numpy <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>numpy_data<span class="token punctuation">)</span>
torch_numpy
<span class="token comment"># tensor([[0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156]], dtype=torch.float64)</span>
tensor_numpy_direct <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_data<span class="token punctuation">)</span>
tensor_numpy_direct
<span class="token comment"># tensor([[0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156]], dtype=torch.float64)</span>

tensor_numpy_direct<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>tensor_numpy_direct<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># (array([[0.03579957, 0.99645713, 0.68238137],</span>
 <span class="token comment">#        [0.18713323, 0.27620823, 0.71559158]]),</span>
 <span class="token comment"># numpy.ndarray)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">numpy_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
numpy_data
<span class="token comment"># array([[0.60448534, 0.20705905, 0.24916817],</span>
<span class="token comment">#        [0.33687396, 0.80828289, 0.84353776]])</span>

my_tensor2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>numpy_data<span class="token punctuation">)</span>
my_tensor2
<span class="token comment"># tensor([[0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#         [0.3369, 0.8083, 0.8435]], dtype=torch.float64)</span>
my_tensor3 <span class="token operator">=</span> torch_numpy
my_tensor3
<span class="token comment"># tensor([[0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156]], dtype=torch.float64)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>my_tensor2<span class="token punctuation">,</span> my_tensor3<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.6045, 0.2071, 0.2492, 0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.3369, 0.8083, 0.8435, 0.1871, 0.2762, 0.7156]], dtype=torch.float64)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>my_tensor2<span class="token punctuation">,</span> my_tensor3<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#         [0.3369, 0.8083, 0.8435],</span>
<span class="token comment">#         [0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156]], dtype=torch.float64)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>my_tensor3<span class="token punctuation">,</span> my_tensor2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.0358, 0.9965, 0.6824, 0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156, 0.3369, 0.8083, 0.8435]], dtype=torch.float64)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>my_tensor3<span class="token punctuation">,</span> my_tensor2<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.0358, 0.9965, 0.6824],</span>
<span class="token comment">#         [0.1871, 0.2762, 0.7156],</span>
<span class="token comment">#         [0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#         [0.3369, 0.8083, 0.8435]], dtype=torch.float64)</span>
my_tensor2<span class="token punctuation">,</span> my_tensor2<span class="token punctuation">.</span>clip<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span>
<span class="token comment"># (tensor([[0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#          [0.3369, 0.8083, 0.8435]], dtype=torch.float64),</span>
<span class="token comment">#  tensor([[0.6045, 0.3000, 0.3000],</span>
<span class="token comment">#          [0.3369, 0.8000, 0.8000]], dtype=torch.float64))</span>
my_tensor2<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>my_tensor3<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.0216, 0.2063, 0.1700],</span>
<span class="token comment">#         [0.0630, 0.2233, 0.6036]], dtype=torch.float64)</span>
my_tensor2 <span class="token operator">*</span> my_tensor3
<span class="token comment"># tensor([[0.0216, 0.2063, 0.1700],</span>
<span class="token comment">#         [0.0630, 0.2233, 0.6036]], dtype=torch.float64)</span>
my_tensor2<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>my_tensor3<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.3980, 0.3486],</span>
<span class="token comment">#         [1.3931, 0.8899]], dtype=torch.float64)</span>
<span class="token punctuation">(</span>my_tensor2<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>my_tensor3<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.0847, 0.6954, 0.6536],</span>
<span class="token comment">#         [0.1587, 0.4296, 0.7197],</span>
<span class="token comment">#         [0.1668, 0.4813, 0.7737]], dtype=torch.float64)</span>
my_tensor2 @ my_tensor3<span class="token punctuation">.</span>T
<span class="token comment"># tensor([[0.3980, 0.3486],</span>
<span class="token comment">#         [1.3931, 0.8899]], dtype=torch.float64)</span>
my_tensor2<span class="token punctuation">.</span>T @ my_tensor3
<span class="token comment"># tensor([[0.0847, 0.6954, 0.6536],</span>
<span class="token comment">#         [0.1587, 0.4296, 0.7197],</span>
<span class="token comment">#         [0.1668, 0.4813, 0.7737]], dtype=torch.float64)</span>
my_tensor2_sum <span class="token operator">=</span> my_tensor2<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
my_tensor2<span class="token punctuation">,</span> my_tensor2_sum
<span class="token comment"># (tensor([[0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#          [0.3369, 0.8083, 0.8435]], dtype=torch.float64),</span>
<span class="token comment">#  tensor(3.0494, dtype=torch.float64))</span>
my_tensor2_sum<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
array<span class="token punctuation">(</span><span class="token number">3.04940718</span><span class="token punctuation">)</span>
<span class="token comment"># array(3.04940718)</span>
my_tensor2_sum<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>my_tensor2_sum<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># (3.0494071761345016, float)</span>
my_tensor2<span class="token punctuation">,</span> my_tensor2<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> my_tensor2<span class="token punctuation">.</span>T
<span class="token comment"># (tensor([[0.6045, 0.2071, 0.2492],</span>
<span class="token comment">#          [0.3369, 0.8083, 0.8435]], dtype=torch.float64),</span>
<span class="token comment">#  tensor([[0.6045, 0.2071],</span>
<span class="token comment">#          [0.2492, 0.3369],</span>
<span class="token comment">#          [0.8083, 0.8435]], dtype=torch.float64),</span>
<span class="token comment">#  tensor([[0.6045, 0.3369],</span>
<span class="token comment">#          [0.2071, 0.8083],</span>
<span class="token comment">#          [0.2492, 0.8435]], dtype=torch.float64))</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>
<div class="gatsby-highlight" data-language="python"><pre style="counter-reset: linenumber NaN" class="language-python line-numbers"><code class="language-python">matrix_A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
matrix_A
<span class="token comment"># tensor([[ 0.,  1.,  2.,  3.],</span>
<span class="token comment">#         [ 4.,  5.,  6.,  7.],</span>
<span class="token comment">#         [ 8.,  9., 10., 11.],</span>
<span class="token comment">#         [12., 13., 14., 15.],</span>
<span class="token comment">#         [16., 17., 18., 19.]])</span>
matrix_B <span class="token operator">=</span> matrix_A<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
matrix_B
<span class="token comment"># tensor([[ 0.,  1.,  2.,  3.],</span>
<span class="token comment">#         [ 4.,  5.,  6.,  7.],</span>
<span class="token comment">#         [ 8.,  9., 10., 11.],</span>
<span class="token comment">#         [12., 13., 14., 15.],</span>
<span class="token comment">#         [16., 17., 18., 19.]])</span>
matrix_A <span class="token operator">+</span> matrix_B
<span class="token comment"># tensor([[ 0.,  2.,  4.,  6.],</span>
<span class="token comment">#         [ 8., 10., 12., 14.],</span>
<span class="token comment">#         [16., 18., 20., 22.],</span>
<span class="token comment">#         [24., 26., 28., 30.],</span>
<span class="token comment">#         [32., 34., 36., 38.]])</span>

matrix_A
<span class="token comment"># tensor([[ 0.,  1.,  2.,  3.],</span>
<span class="token comment">#         [ 4.,  5.,  6.,  7.],</span>
<span class="token comment">#         [ 8.,  9., 10., 11.],</span>
<span class="token comment">#         [12., 13., 14., 15.],</span>
<span class="token comment">#         [16., 17., 18., 19.]])</span>
matrix_A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(9.5000)</span>
matrix_A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([ 8.,  9., 10., 11.])</span>

matrix_A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> matrix_A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># tensor([ 8.,  9., 10., 11.])</span>
matrix_A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(190.)</span>
matrix_A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># matrix_A.sum(axis = 0)</span>
matrix_A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([ 6., 22., 38., 54., 70.])</span>

matrix_A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> matrix_A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token comment"># (torch.Size([5, 4]), 5)</span></code><span aria-hidden="true" class="line-numbers-rows" style="white-space: normal; width: auto; left: 0;"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div></div></div></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/ai-이노베이션-스퀘어-언어-12일차/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-55ff3df016f1bf520dc3.js"],"app":["/app-f81057f30f7387c76463.js"],"component---src-pages-about-js":["/component---src-pages-about-js-01b4957cf3a65784e9dc.js"],"component---src-pages-contact-js":["/component---src-pages-contact-js-47c9a9e86f5834f6d116.js"],"component---src-pages-index-js":["/component---src-pages-index-js-dbf9480c3ca0918d5a04.js"],"component---src-pages-my-files-js":["/component---src-pages-my-files-js-f04405e2ce36edc47b27.js"],"component---src-pages-tags-js":["/component---src-pages-tags-js-6eaa04bdf1ac86b2d473.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-33322b93090050d5fb1b.js"]};/*]]>*/</script><script src="/polyfill-55ff3df016f1bf520dc3.js" nomodule=""></script><script src="/component---src-templates-blog-post-js-33322b93090050d5fb1b.js" async=""></script><script src="/e3fcc2076860498e4deed45a66207f3abfe77099-7463bcd7e6ea2ff920c3.js" async=""></script><script src="/commons-71b7b1d300b3ebc29573.js" async=""></script><script src="/app-f81057f30f7387c76463.js" async=""></script><script src="/framework-24ad6bf468f69b85cc4b.js" async=""></script><script src="/webpack-runtime-6ebff4c415c09dde9e8d.js" async=""></script></body></html>